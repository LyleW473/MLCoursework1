{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "from src.utils import get_kfold_data, convert_non_numeric_to_numeric, calculate_r2_score, calculate_metrics\n",
    "from src.normalisation import Normaliser\n",
    "from src.constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>...</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-26.701232</td>\n",
       "      <td>1.14</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.3</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7948</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168836</td>\n",
       "      <td>-0.273758</td>\n",
       "      <td>1.107832</td>\n",
       "      <td>1.247795</td>\n",
       "      <td>0.482344</td>\n",
       "      <td>0.489511</td>\n",
       "      <td>-0.321138</td>\n",
       "      <td>0.573382</td>\n",
       "      <td>0.446871</td>\n",
       "      <td>-1.990581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.548093</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>60.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>898</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.66</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256549</td>\n",
       "      <td>0.315373</td>\n",
       "      <td>-0.030326</td>\n",
       "      <td>-0.114335</td>\n",
       "      <td>-1.059588</td>\n",
       "      <td>-1.761360</td>\n",
       "      <td>-1.343951</td>\n",
       "      <td>-1.002550</td>\n",
       "      <td>-0.225030</td>\n",
       "      <td>-0.446653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.612562</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1351</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.193327</td>\n",
       "      <td>-0.657307</td>\n",
       "      <td>-0.591726</td>\n",
       "      <td>-0.446856</td>\n",
       "      <td>-0.765286</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>-1.397794</td>\n",
       "      <td>-0.477130</td>\n",
       "      <td>0.810509</td>\n",
       "      <td>1.725131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.073562</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2512</td>\n",
       "      <td>5.74</td>\n",
       "      <td>5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.740788</td>\n",
       "      <td>-1.778860</td>\n",
       "      <td>-0.825070</td>\n",
       "      <td>0.444932</td>\n",
       "      <td>1.173109</td>\n",
       "      <td>0.453606</td>\n",
       "      <td>-0.263440</td>\n",
       "      <td>0.246210</td>\n",
       "      <td>-0.850503</td>\n",
       "      <td>-0.412950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.436557</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2751</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859322</td>\n",
       "      <td>1.409268</td>\n",
       "      <td>0.861992</td>\n",
       "      <td>1.109063</td>\n",
       "      <td>-1.436722</td>\n",
       "      <td>-1.461618</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.258087</td>\n",
       "      <td>0.851146</td>\n",
       "      <td>2.204813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     outcome  carat        cut color clarity  depth  table  price     x     y  \\\n",
       "0 -26.701232   1.14      Ideal     G     VS1   62.3   56.0   7948  6.73  6.70   \n",
       "1   6.548093   0.38    Premium     H     VS2   60.5   59.0    898  4.69  4.66   \n",
       "2   6.612562   0.50  Very Good     E     SI1   60.7   58.0   1351  5.09  5.13   \n",
       "3  -5.073562   0.70    Premium     D     SI1   61.2   58.0   2512  5.74  5.70   \n",
       "4 -14.436557   0.83      Ideal     G     SI2   62.4   54.0   2751  6.01  6.08   \n",
       "\n",
       "   ...        a6        a7        a8        a9       a10        b6        b7  \\\n",
       "0  ...  0.168836 -0.273758  1.107832  1.247795  0.482344  0.489511 -0.321138   \n",
       "1  ... -0.256549  0.315373 -0.030326 -0.114335 -1.059588 -1.761360 -1.343951   \n",
       "2  ... -1.193327 -0.657307 -0.591726 -0.446856 -0.765286 -0.816544 -1.397794   \n",
       "3  ... -1.740788 -1.778860 -0.825070  0.444932  1.173109  0.453606 -0.263440   \n",
       "4  ... -0.859322  1.409268  0.861992  1.109063 -1.436722 -1.461618  0.081787   \n",
       "\n",
       "         b8        b9       b10  \n",
       "0  0.573382  0.446871 -1.990581  \n",
       "1 -1.002550 -0.225030 -0.446653  \n",
       "2 -0.477130  0.810509  1.725131  \n",
       "3  0.246210 -0.850503 -0.412950  \n",
       "4  0.258087  0.851146  2.204813  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['outcome', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z', 'a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5', 'a6', 'a7', 'a8', 'a9', 'a10', 'b6', 'b7', 'b8', 'b9', 'b10']\n",
      "['carat', 'depth', 'table', 'price', 'x', 'y', 'z', 'a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5', 'a6', 'a7', 'a8', 'a9', 'a10', 'b6', 'b7', 'b8', 'b9', 'b10']\n",
      "['cut', 'color', 'clarity']\n"
     ]
    }
   ],
   "source": [
    "# Find columns\n",
    "all_columns = data.columns.tolist()\n",
    "print(all_columns)\n",
    "\n",
    "numeric_columns = data.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "numeric_columns.remove(\"outcome\") # Remove the target column\n",
    "print(numeric_columns)\n",
    "\n",
    "non_numeric_columns = data.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "print(non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut\n",
      "Ideal        4040\n",
      "Premium      2439\n",
      "Very Good    2296\n",
      "Good          925\n",
      "Fair          300\n",
      "Name: count, dtype: int64\n",
      "color\n",
      "G    2120\n",
      "E    1873\n",
      "F    1746\n",
      "H    1506\n",
      "D    1246\n",
      "I     983\n",
      "J     526\n",
      "Name: count, dtype: int64\n",
      "clarity\n",
      "SI1     2408\n",
      "VS2     2256\n",
      "SI2     1743\n",
      "VS1     1503\n",
      "VVS2     951\n",
      "VVS1     675\n",
      "IF       318\n",
      "I1       146\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for non_numeric_column in non_numeric_columns:\n",
    "    print(data[non_numeric_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting non-numeric features to numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'E', 'F', 'H', 'D', 'I', 'J']\n",
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n",
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "data = convert_non_numeric_to_numeric(data=data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise data using each columns respective mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.14\n",
      "1       0.38\n",
      "2       0.50\n",
      "3       0.70\n",
      "4       0.83\n",
      "        ... \n",
      "9995    0.33\n",
      "9996    1.01\n",
      "9997    0.52\n",
      "9998    0.31\n",
      "9999    0.37\n",
      "Name: carat, Length: 10000, dtype: float64\n",
      "after 0       0.723643\n",
      "1      -0.886369\n",
      "2      -0.632156\n",
      "3      -0.208469\n",
      "4       0.066928\n",
      "          ...   \n",
      "9995   -0.992290\n",
      "9996    0.448246\n",
      "9997   -0.589788\n",
      "9998   -1.034659\n",
      "9999   -0.907553\n",
      "Name: carat, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "normaliser = Normaliser()\n",
    "for column in numeric_columns:\n",
    "    print(data[column])\n",
    "    data[column] = normaliser.standardise(data[column])\n",
    "    print(\"after\", data[column])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome     carat  cut  clarity  depth  table  price     x     y  \\\n",
      "0    -26.701232  0.723643    0        3   62.3   56.0   7948  6.73  6.70   \n",
      "1      6.548093 -0.886369    1        4   60.5   59.0    898  4.69  4.66   \n",
      "2      6.612562 -0.632156    2        5   60.7   58.0   1351  5.09  5.13   \n",
      "3     -5.073562 -0.208469    1        5   61.2   58.0   2512  5.74  5.70   \n",
      "4    -14.436557  0.066928    0        6   62.4   54.0   2751  6.01  6.08   \n",
      "...         ...       ...  ...      ...    ...    ...    ...   ...   ...   \n",
      "9995  10.718277 -0.992290    0        3   62.6   57.0   1002  4.42  4.40   \n",
      "9996 -12.246698  0.448246    4        5   69.5   55.0   4853  6.00  5.94   \n",
      "9997  11.122516 -0.589788    2        6   57.9   61.0   1273  5.28  5.33   \n",
      "9998 -24.730782 -1.034659    0        0   62.0   54.0    801  4.35  4.39   \n",
      "9999   8.735755 -0.907553    2        5   59.9   59.0    649  4.68  4.70   \n",
      "\n",
      "         z  ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     4.18  ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     2.83  ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     3.10  ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     3.50  ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     3.77  ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...    ...  ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  2.76  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  4.15  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  3.07  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  2.71  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  2.81  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 1/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 2/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 3/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 4/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold_data = get_kfold_data(data=data, k=NUM_FOLDS, reproducibility_seed=REPRODUCIBILITY_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define models and hyperparameter tuning objectives for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "        \"linear_regression\": LinearRegression,\n",
    "        \"lasso\": Lasso,\n",
    "        \"ridge\": Ridge,\n",
    "        # \"xgb\": xgb.XGBRegressor,\n",
    "        # \"random_forest\": RandomForestRegressor,\n",
    "        # \"gradient_boosting\": GradientBoostingRegressor,\n",
    "        # \"ada_boost\": AdaBoostRegressor,\n",
    "        # \"lgbm\": lgb.LGBMRegressor\n",
    "        }\n",
    "\n",
    "def objective(model_type, trial, x_train, y_train, x_val, y_val):\n",
    "    if model_type == LinearRegression:\n",
    "        parameters = {\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "        }\n",
    "    elif model_type == Lasso:\n",
    "        parameters = {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 0.1, log=True),\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "            \"selection\": trial.suggest_categorical(\"selection\", [\"cyclic\", \"random\"]),\n",
    "            \"warm_start\": trial.suggest_categorical(\"warm_start\", [True, False]),\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == Ridge:\n",
    "        parameters = {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 0.1, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]),\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "            \"positive\": False,\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == xgb.XGBRegressor:\n",
    "        parameters = {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"n_estimators\": 100,\n",
    "            \"eta\": trial.suggest_float(\"eta\", 1e-2, 0.2, log=True),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 10, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 6),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"seed\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == RandomForestRegressor:\n",
    "        parameters = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"absolute_error\", \"squared_error\"]),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"bootstrap\": True,\n",
    "            \"oob_score\": False,\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == GradientBoostingRegressor:\n",
    "        parameters = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"loss\": trial.suggest_categorical(\"loss\", [\"absolute_error\", \"squared_error\", \"huber\", \"quantile\"]),\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"friedman_mse\", \"squared_error\"]),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "            \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 2**10),\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == AdaBoostRegressor:\n",
    "        parameters = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 100),\n",
    "            \"loss\": trial.suggest_categorical(\"loss\", [\"linear\", \"square\", \"exponential\"]),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == lgb.LGBMRegressor:\n",
    "        parameters = {\n",
    "                    \"objective\": \"regression\",\n",
    "                    \"metric\": \"rmse\",\n",
    "                    \"n_estimators\": 100,\n",
    "                    \"verbosity\": -1,\n",
    "                    \"bagging_freq\": 1,\n",
    "                    \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "                    \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "                    \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "                    \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "                    \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "                    \"seed\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "\n",
    "    \n",
    "    model = model_type(**parameters) # Create the model\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_val)\n",
    "    metrics = calculate_metrics(targets=y_val, preds=predictions)\n",
    "    rmse = metrics[\"rmse\"]\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 15:54:25,363] A new study created in memory with name: no-name-1e73f171-c67b-4346-a959-15aae628298f\n",
      "[I 2025-02-16 15:54:25,371] Trial 0 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,377] Trial 1 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,384] Trial 2 finished with value: 10.913995409241357 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,391] Trial 3 finished with value: 10.913995409241357 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,399] Trial 4 finished with value: 10.913995409241357 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,406] Trial 5 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,412] Trial 6 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,419] Trial 7 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,432] Trial 8 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,439] Trial 9 finished with value: 10.913995409241357 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,447] Trial 10 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,455] Trial 11 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,461] Trial 12 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,466] Trial 13 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,473] Trial 14 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,479] Trial 15 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,486] Trial 16 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,492] Trial 17 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,499] Trial 18 finished with value: 10.913995409241357 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,505] Trial 19 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,511] Trial 20 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,517] Trial 21 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,523] Trial 22 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,530] Trial 23 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,535] Trial 24 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,541] Trial 25 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,547] Trial 26 finished with value: 10.913995409241357 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,553] Trial 27 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,560] Trial 28 finished with value: 10.913995409241268 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,566] Trial 29 finished with value: 10.913995409241357 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.913995409241268.\n",
      "[I 2025-02-16 15:54:25,572] A new study created in memory with name: no-name-4dfd43f6-a605-4827-8cc6-6641e6d9da26\n",
      "[I 2025-02-16 15:54:25,580] Trial 0 finished with value: 10.926487825178297 and parameters: {'alpha': 0.060266726762110104, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 0 with value: 10.926487825178297.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.867e+05, tolerance: 1.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:25,665] Trial 1 finished with value: 11.283690942266176 and parameters: {'alpha': 0.017861301737011556, 'fit_intercept': False, 'selection': 'random', 'warm_start': True}. Best is trial 0 with value: 10.926487825178297.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.864e+05, tolerance: 1.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:25,754] Trial 2 finished with value: 11.257657404993003 and parameters: {'alpha': 0.0012828468599947788, 'fit_intercept': False, 'selection': 'random', 'warm_start': True}. Best is trial 0 with value: 10.926487825178297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1/5\n",
      "Model name: linear_regression\n",
      "MAE: 8.775370267692598\n",
      "MSE: 119.11529579293946\n",
      "RMSE: 10.913995409241268\n",
      "PCC: 0.5463216691195159\n",
      "Spearman R: 0.5697531327160675\n",
      "R2 Score: 0.2980010974654729\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e+05, tolerance: 1.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:25,836] Trial 3 finished with value: 11.273323143647062 and parameters: {'alpha': 0.010615217101021172, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 0 with value: 10.926487825178297.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e+05, tolerance: 1.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:25,923] Trial 4 finished with value: 11.259462840279092 and parameters: {'alpha': 0.0015608258066222838, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 0 with value: 10.926487825178297.\n",
      "[I 2025-02-16 15:54:25,937] Trial 5 finished with value: 10.91831517727059 and parameters: {'alpha': 0.031499758267338536, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 5 with value: 10.91831517727059.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.872e+05, tolerance: 1.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:26,026] Trial 6 finished with value: 11.237570716345932 and parameters: {'alpha': 0.007701766042025606, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': True}. Best is trial 5 with value: 10.91831517727059.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.862e+05, tolerance: 1.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:26,109] Trial 7 finished with value: 11.269166826516287 and parameters: {'alpha': 0.005473780738297728, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 5 with value: 10.91831517727059.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.865e+05, tolerance: 1.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:26,194] Trial 8 finished with value: 11.257927237371343 and parameters: {'alpha': 0.0013305768355278155, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 5 with value: 10.91831517727059.\n",
      "[I 2025-02-16 15:54:26,203] Trial 9 finished with value: 10.920476316324542 and parameters: {'alpha': 0.04177585998888431, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 5 with value: 10.91831517727059.\n",
      "[I 2025-02-16 15:54:26,212] Trial 10 finished with value: 10.94061970453634 and parameters: {'alpha': 0.0951111044300748, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 5 with value: 10.91831517727059.\n",
      "[I 2025-02-16 15:54:26,222] Trial 11 finished with value: 10.918475473397336 and parameters: {'alpha': 0.03290259728678273, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 5 with value: 10.91831517727059.\n",
      "[I 2025-02-16 15:54:26,235] Trial 12 finished with value: 10.918272556874143 and parameters: {'alpha': 0.0251630281957173, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 12 with value: 10.918272556874143.\n",
      "[I 2025-02-16 15:54:26,251] Trial 13 finished with value: 10.916841928881665 and parameters: {'alpha': 0.019159794244556726, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 13 with value: 10.916841928881665.\n",
      "[I 2025-02-16 15:54:26,276] Trial 14 finished with value: 10.915779283144884 and parameters: {'alpha': 0.016348938735651374, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 14 with value: 10.915779283144884.\n",
      "[I 2025-02-16 15:54:26,309] Trial 15 finished with value: 10.913790625763585 and parameters: {'alpha': 0.0037232718636497695, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 15 with value: 10.913790625763585.\n",
      "[I 2025-02-16 15:54:26,336] Trial 16 finished with value: 10.913832254932975 and parameters: {'alpha': 0.003304143095650446, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 15 with value: 10.913790625763585.\n",
      "[I 2025-02-16 15:54:26,354] Trial 17 finished with value: 10.913856083581225 and parameters: {'alpha': 0.0030889442322131924, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 15 with value: 10.913790625763585.\n",
      "[I 2025-02-16 15:54:26,397] Trial 18 finished with value: 10.913865598877765 and parameters: {'alpha': 0.0030169456437118564, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 15 with value: 10.913790625763585.\n",
      "[I 2025-02-16 15:54:26,445] Trial 19 finished with value: 10.913890274476058 and parameters: {'alpha': 0.002822016651727413, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 15 with value: 10.913790625763585.\n",
      "[I 2025-02-16 15:54:26,477] Trial 20 finished with value: 10.913716496806934 and parameters: {'alpha': 0.004911286736038535, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 20 with value: 10.913716496806934.\n",
      "[I 2025-02-16 15:54:26,504] Trial 21 finished with value: 10.913715787378722 and parameters: {'alpha': 0.004931788969210062, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 21 with value: 10.913715787378722.\n",
      "[I 2025-02-16 15:54:26,536] Trial 22 finished with value: 10.913718073140084 and parameters: {'alpha': 0.0064828746945174275, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 21 with value: 10.913715787378722.\n",
      "[I 2025-02-16 15:54:26,569] Trial 23 finished with value: 10.913731018730298 and parameters: {'alpha': 0.006777915506142318, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 21 with value: 10.913715787378722.\n",
      "[I 2025-02-16 15:54:26,602] Trial 24 finished with value: 10.913708209817598 and parameters: {'alpha': 0.005203209503603122, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 24 with value: 10.913708209817598.\n",
      "[I 2025-02-16 15:54:26,664] Trial 25 finished with value: 10.913905192862702 and parameters: {'alpha': 0.002014276677084548, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 24 with value: 10.913708209817598.\n",
      "[I 2025-02-16 15:54:26,698] Trial 26 finished with value: 10.913729265201807 and parameters: {'alpha': 0.004607909347720385, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 24 with value: 10.913708209817598.\n",
      "[I 2025-02-16 15:54:26,727] Trial 27 finished with value: 10.914187591724192 and parameters: {'alpha': 0.011303400967002468, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 24 with value: 10.913708209817598.\n",
      "[I 2025-02-16 15:54:26,757] Trial 28 finished with value: 10.913762570763954 and parameters: {'alpha': 0.007974438127659167, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 24 with value: 10.913708209817598.\n",
      "[I 2025-02-16 15:54:26,820] Trial 29 finished with value: 10.913910352774375 and parameters: {'alpha': 0.0022784079877564644, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 24 with value: 10.913708209817598.\n",
      "[I 2025-02-16 15:54:26,845] A new study created in memory with name: no-name-9fadb8d7-0779-4b66-aabf-6f3533fcdbef\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1/5\n",
      "Model name: lasso\n",
      "MAE: 8.776322295049523\n",
      "MSE: 119.10902688904005\n",
      "RMSE: 10.913708209817598\n",
      "PCC: 0.546377000548236\n",
      "Spearman R: 0.5703277940733571\n",
      "R2 Score: 0.29803804287729585\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:27,764] Trial 0 finished with value: 12.926647637874595 and parameters: {'alpha': 0.004464436425327533, 'solver': 'sag', 'fit_intercept': False}. Best is trial 0 with value: 12.926647637874595.\n",
      "[I 2025-02-16 15:54:27,768] Trial 1 finished with value: 12.36509822201116 and parameters: {'alpha': 0.00407719208742347, 'solver': 'lsqr', 'fit_intercept': False}. Best is trial 1 with value: 12.36509822201116.\n",
      "[I 2025-02-16 15:54:27,772] Trial 2 finished with value: 10.914505138047922 and parameters: {'alpha': 0.0017320276276025978, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 2 with value: 10.914505138047922.\n",
      "[I 2025-02-16 15:54:27,781] Trial 3 finished with value: 10.934714164874391 and parameters: {'alpha': 0.03239891726246961, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.914505138047922.\n",
      "[I 2025-02-16 15:54:27,790] Trial 4 finished with value: 10.913995218126038 and parameters: {'alpha': 0.006818516909266874, 'solver': 'svd', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:27,794] Trial 5 finished with value: 12.007220084120844 and parameters: {'alpha': 0.010812528853323048, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:27,804] Trial 6 finished with value: 10.918579995946576 and parameters: {'alpha': 0.010506449469447838, 'solver': 'svd', 'fit_intercept': False}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:27,807] Trial 7 finished with value: 10.930466807174252 and parameters: {'alpha': 0.027208683225468183, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:27,812] Trial 8 finished with value: 10.91690906698706 and parameters: {'alpha': 0.016905278674331416, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:27,816] Trial 9 finished with value: 10.913995355913277 and parameters: {'alpha': 0.001901107275489981, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:28,840] Trial 10 finished with value: 12.948190323037922 and parameters: {'alpha': 0.09328221221265845, 'solver': 'saga', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:28,848] Trial 11 finished with value: 10.913995379405485 and parameters: {'alpha': 0.0010634825490348106, 'solver': 'auto', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:28,859] Trial 12 finished with value: 10.913995316632844 and parameters: {'alpha': 0.003302171349836687, 'solver': 'svd', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:28,870] Trial 13 finished with value: 10.913995294791224 and parameters: {'alpha': 0.0040814970249293285, 'solver': 'svd', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:28,882] Trial 14 finished with value: 10.91399522247265 and parameters: {'alpha': 0.006663274285197804, 'solver': 'svd', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:28,893] Trial 15 finished with value: 10.913995237518492 and parameters: {'alpha': 0.006125960117142929, 'solver': 'svd', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:28,900] Trial 16 finished with value: 10.91690944500139 and parameters: {'alpha': 0.007296065535294751, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:29,914] Trial 17 finished with value: 12.948190316417598 and parameters: {'alpha': 0.01746062330740555, 'solver': 'saga', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:30,824] Trial 18 finished with value: 12.874796960648462 and parameters: {'alpha': 0.04960893636982054, 'solver': 'sag', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:30,831] Trial 19 finished with value: 10.913995339822641 and parameters: {'alpha': 0.002474955737818281, 'solver': 'auto', 'fit_intercept': True}. Best is trial 4 with value: 10.913995218126038.\n",
      "[I 2025-02-16 15:54:30,842] Trial 20 finished with value: 10.913995199645319 and parameters: {'alpha': 0.007478656869832715, 'solver': 'svd', 'fit_intercept': True}. Best is trial 20 with value: 10.913995199645319.\n",
      "[I 2025-02-16 15:54:30,853] Trial 21 finished with value: 10.913995216574126 and parameters: {'alpha': 0.006873946463448591, 'solver': 'svd', 'fit_intercept': True}. Best is trial 20 with value: 10.913995199645319.\n",
      "[I 2025-02-16 15:54:30,865] Trial 22 finished with value: 10.913995044176435 and parameters: {'alpha': 0.013037643642222327, 'solver': 'svd', 'fit_intercept': True}. Best is trial 22 with value: 10.913995044176435.\n",
      "[I 2025-02-16 15:54:30,876] Trial 23 finished with value: 10.913994860750762 and parameters: {'alpha': 0.019609103510547763, 'solver': 'svd', 'fit_intercept': True}. Best is trial 23 with value: 10.913994860750762.\n",
      "[I 2025-02-16 15:54:30,887] Trial 24 finished with value: 10.913994974318655 and parameters: {'alpha': 0.015538744796933469, 'solver': 'svd', 'fit_intercept': True}. Best is trial 23 with value: 10.913994860750762.\n",
      "[I 2025-02-16 15:54:30,897] Trial 25 finished with value: 10.913994957260288 and parameters: {'alpha': 0.016149788212710348, 'solver': 'svd', 'fit_intercept': True}. Best is trial 23 with value: 10.913994860750762.\n",
      "[I 2025-02-16 15:54:30,909] Trial 26 finished with value: 10.91399471879334 and parameters: {'alpha': 0.024704505396567884, 'solver': 'svd', 'fit_intercept': True}. Best is trial 26 with value: 10.91399471879334.\n",
      "[I 2025-02-16 15:54:30,915] Trial 27 finished with value: 12.007220125302423 and parameters: {'alpha': 0.02680453289000095, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 26 with value: 10.91399471879334.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:31,908] Trial 28 finished with value: 12.948190318439742 and parameters: {'alpha': 0.040691596153396285, 'solver': 'saga', 'fit_intercept': True}. Best is trial 26 with value: 10.91399471879334.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:32,799] Trial 29 finished with value: 12.926647645324008 and parameters: {'alpha': 0.06644565300026264, 'solver': 'sag', 'fit_intercept': False}. Best is trial 26 with value: 10.91399471879334.\n",
      "[I 2025-02-16 15:54:32,809] A new study created in memory with name: no-name-d3ef92d8-8ad3-4807-b2b0-7d24062849a4\n",
      "[I 2025-02-16 15:54:32,816] Trial 0 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,822] Trial 1 finished with value: 10.754782903598144 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,828] Trial 2 finished with value: 10.754782903598144 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,834] Trial 3 finished with value: 10.754782903598144 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,839] Trial 4 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,846] Trial 5 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,852] Trial 6 finished with value: 10.754782903598144 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,858] Trial 7 finished with value: 10.754782903598144 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,864] Trial 8 finished with value: 10.754782903598144 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,870] Trial 9 finished with value: 10.754782903598144 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,876] Trial 10 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,882] Trial 11 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,888] Trial 12 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,895] Trial 13 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,901] Trial 14 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,907] Trial 15 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,913] Trial 16 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,919] Trial 17 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,926] Trial 18 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,932] Trial 19 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,938] Trial 20 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,944] Trial 21 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,951] Trial 22 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,957] Trial 23 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,964] Trial 24 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,971] Trial 25 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,977] Trial 26 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,984] Trial 27 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1/5\n",
      "Model name: ridge\n",
      "MAE: 8.77537228273293\n",
      "MSE: 119.1152807218489\n",
      "RMSE: 10.91399471879334\n",
      "PCC: 0.5463218156881958\n",
      "Spearman R: 0.5697613856489788\n",
      "R2 Score: 0.29800118628604766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 15:54:32,992] Trial 28 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:32,999] Trial 29 finished with value: 10.754782903597743 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.754782903597743.\n",
      "[I 2025-02-16 15:54:33,006] A new study created in memory with name: no-name-eb4dc196-deac-4fb3-9541-c46fdd7fc7ba\n",
      "[I 2025-02-16 15:54:33,036] Trial 0 finished with value: 10.748682053022623 and parameters: {'alpha': 0.00630166831761785, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 0 with value: 10.748682053022623.\n",
      "[I 2025-02-16 15:54:33,085] Trial 1 finished with value: 10.7494184876974 and parameters: {'alpha': 0.005083365314649645, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 0 with value: 10.748682053022623.\n",
      "[I 2025-02-16 15:54:33,106] Trial 2 finished with value: 10.744935519771332 and parameters: {'alpha': 0.016182173381867875, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 2 with value: 10.744935519771332.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.888e+05, tolerance: 1.190e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:33,191] Trial 3 finished with value: 11.18670643040493 and parameters: {'alpha': 0.002581192558791982, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 2 with value: 10.744935519771332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2/5\n",
      "Model name: linear_regression\n",
      "MAE: 8.572113483311412\n",
      "MSE: 115.66535530351831\n",
      "RMSE: 10.754782903597743\n",
      "PCC: 0.5251877646872718\n",
      "Spearman R: 0.5521546102166447\n",
      "R2 Score: 0.2750306342091805\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.941e+05, tolerance: 1.190e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:33,274] Trial 4 finished with value: 11.146336405419332 and parameters: {'alpha': 0.016083358002489254, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 2 with value: 10.744935519771332.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.911e+05, tolerance: 1.190e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:33,371] Trial 5 finished with value: 11.144222559257189 and parameters: {'alpha': 0.007775446883225886, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 2 with value: 10.744935519771332.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e+05, tolerance: 1.190e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:33,454] Trial 6 finished with value: 11.143987503510424 and parameters: {'alpha': 0.006819842722923458, 'fit_intercept': False, 'selection': 'random', 'warm_start': True}. Best is trial 2 with value: 10.744935519771332.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.905e+05, tolerance: 1.190e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:33,539] Trial 7 finished with value: 11.144206354260666 and parameters: {'alpha': 0.006007052240958241, 'fit_intercept': False, 'selection': 'random', 'warm_start': True}. Best is trial 2 with value: 10.744935519771332.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.565e+05, tolerance: 1.027e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:33,631] Trial 8 finished with value: 10.751384255271981 and parameters: {'alpha': 0.0027571351434717444, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 2 with value: 10.744935519771332.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.617e+05, tolerance: 1.027e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:33,724] Trial 9 finished with value: 10.751812868480847 and parameters: {'alpha': 0.0023875847082601384, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 2 with value: 10.744935519771332.\n",
      "[I 2025-02-16 15:54:33,731] Trial 10 finished with value: 10.739791429223366 and parameters: {'alpha': 0.0722235516883117, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 10 with value: 10.739791429223366.\n",
      "[I 2025-02-16 15:54:33,738] Trial 11 finished with value: 10.738578323493005 and parameters: {'alpha': 0.06696874676284725, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 11 with value: 10.738578323493005.\n",
      "[I 2025-02-16 15:54:33,746] Trial 12 finished with value: 10.744526411577132 and parameters: {'alpha': 0.08913840647334494, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 11 with value: 10.738578323493005.\n",
      "[I 2025-02-16 15:54:33,756] Trial 13 finished with value: 10.74342295740686 and parameters: {'alpha': 0.08537990337624297, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 11 with value: 10.738578323493005.\n",
      "[I 2025-02-16 15:54:33,763] Trial 14 finished with value: 10.737723313704665 and parameters: {'alpha': 0.037968358351847066, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 14 with value: 10.737723313704665.\n",
      "[I 2025-02-16 15:54:33,771] Trial 15 finished with value: 10.737615724873267 and parameters: {'alpha': 0.03865413966522837, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 15 with value: 10.737615724873267.\n",
      "[I 2025-02-16 15:54:33,782] Trial 16 finished with value: 10.737703006335906 and parameters: {'alpha': 0.03809587628662898, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 15 with value: 10.737615724873267.\n",
      "[I 2025-02-16 15:54:33,790] Trial 17 finished with value: 10.739225228392046 and parameters: {'alpha': 0.03171916074063237, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 15 with value: 10.737615724873267.\n",
      "[I 2025-02-16 15:54:33,856] Trial 18 finished with value: 10.753381469925374 and parameters: {'alpha': 0.0010818865518017636, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 15 with value: 10.737615724873267.\n",
      "[I 2025-02-16 15:54:33,864] Trial 19 finished with value: 10.737966180320363 and parameters: {'alpha': 0.03650057931796505, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 15 with value: 10.737615724873267.\n",
      "[I 2025-02-16 15:54:33,876] Trial 20 finished with value: 10.743601100084767 and parameters: {'alpha': 0.021857939652567278, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 15 with value: 10.737615724873267.\n",
      "[I 2025-02-16 15:54:33,883] Trial 21 finished with value: 10.736479647904758 and parameters: {'alpha': 0.048460238745937106, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 21 with value: 10.736479647904758.\n",
      "[I 2025-02-16 15:54:33,890] Trial 22 finished with value: 10.73676691675722 and parameters: {'alpha': 0.05446347894909183, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 21 with value: 10.736479647904758.\n",
      "[I 2025-02-16 15:54:33,898] Trial 23 finished with value: 10.736697971674229 and parameters: {'alpha': 0.053528757215012074, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 21 with value: 10.736479647904758.\n",
      "[I 2025-02-16 15:54:33,905] Trial 24 finished with value: 10.736710809039305 and parameters: {'alpha': 0.053709578937634284, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 21 with value: 10.736479647904758.\n",
      "[I 2025-02-16 15:54:33,916] Trial 25 finished with value: 10.742535700501637 and parameters: {'alpha': 0.023920649400514683, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 21 with value: 10.736479647904758.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.046e+05, tolerance: 1.190e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:33,982] Trial 26 finished with value: 11.17869669012517 and parameters: {'alpha': 0.04975898514678723, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 21 with value: 10.736479647904758.\n",
      "[I 2025-02-16 15:54:34,011] Trial 27 finished with value: 10.745621046941624 and parameters: {'alpha': 0.013602858687845195, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 21 with value: 10.736479647904758.\n",
      "[I 2025-02-16 15:54:34,019] Trial 28 finished with value: 10.747776213140858 and parameters: {'alpha': 0.09807417398707882, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 21 with value: 10.736479647904758.\n",
      "[I 2025-02-16 15:54:34,030] Trial 29 finished with value: 10.742636806452639 and parameters: {'alpha': 0.023719179133310897, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 21 with value: 10.736479647904758.\n",
      "[I 2025-02-16 15:54:34,036] A new study created in memory with name: no-name-28923ce5-73aa-4b8c-a375-41e13a54830d\n",
      "[I 2025-02-16 15:54:34,040] Trial 0 finished with value: 10.816479876762989 and parameters: {'alpha': 0.05197389369358308, 'solver': 'auto', 'fit_intercept': False}. Best is trial 0 with value: 10.816479876762989.\n",
      "[I 2025-02-16 15:54:34,043] Trial 1 finished with value: 11.993723912415737 and parameters: {'alpha': 0.020101383208506123, 'solver': 'sparse_cg', 'fit_intercept': False}. Best is trial 0 with value: 10.816479876762989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2/5\n",
      "Model name: lasso\n",
      "MAE: 8.532355126645285\n",
      "MSE: 115.2719952298731\n",
      "RMSE: 10.736479647904758\n",
      "PCC: 0.5269923506797608\n",
      "Spearman R: 0.5580363439595094\n",
      "R2 Score: 0.27749614345669615\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:35,015] Trial 2 finished with value: 12.549082601630632 and parameters: {'alpha': 0.003806235061098622, 'solver': 'saga', 'fit_intercept': True}. Best is trial 0 with value: 10.816479876762989.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:35,978] Trial 3 finished with value: 12.549082601478162 and parameters: {'alpha': 0.0018395697329813502, 'solver': 'saga', 'fit_intercept': True}. Best is trial 0 with value: 10.816479876762989.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:36,954] Trial 4 finished with value: 12.54908260142735 and parameters: {'alpha': 0.0011945875217069682, 'solver': 'saga', 'fit_intercept': True}. Best is trial 0 with value: 10.816479876762989.\n",
      "[I 2025-02-16 15:54:36,961] Trial 5 finished with value: 10.760339645316272 and parameters: {'alpha': 0.006448956294974857, 'solver': 'svd', 'fit_intercept': False}. Best is trial 5 with value: 10.760339645316272.\n",
      "[I 2025-02-16 15:54:36,966] Trial 6 finished with value: 11.799600693368497 and parameters: {'alpha': 0.08247465767023944, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 5 with value: 10.760339645316272.\n",
      "[I 2025-02-16 15:54:36,976] Trial 7 finished with value: 10.75478080536522 and parameters: {'alpha': 0.005764205110452747, 'solver': 'svd', 'fit_intercept': True}. Best is trial 7 with value: 10.75478080536522.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:37,881] Trial 8 finished with value: 12.529086449737132 and parameters: {'alpha': 0.009034082725821258, 'solver': 'sag', 'fit_intercept': False}. Best is trial 7 with value: 10.75478080536522.\n",
      "[I 2025-02-16 15:54:37,886] Trial 9 finished with value: 10.769137546440831 and parameters: {'alpha': 0.014569662756439386, 'solver': 'auto', 'fit_intercept': False}. Best is trial 7 with value: 10.75478080536522.\n",
      "[I 2025-02-16 15:54:37,896] Trial 10 finished with value: 10.754772578605582 and parameters: {'alpha': 0.028393001569720522, 'solver': 'svd', 'fit_intercept': True}. Best is trial 10 with value: 10.754772578605582.\n",
      "[I 2025-02-16 15:54:37,908] Trial 11 finished with value: 10.754770056742302 and parameters: {'alpha': 0.035338818333542216, 'solver': 'svd', 'fit_intercept': True}. Best is trial 11 with value: 10.754770056742302.\n",
      "[I 2025-02-16 15:54:37,914] Trial 12 finished with value: 10.75477174982247 and parameters: {'alpha': 0.030675197632952733, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 11 with value: 10.754770056742302.\n",
      "[I 2025-02-16 15:54:37,921] Trial 13 finished with value: 10.754768831785016 and parameters: {'alpha': 0.038714186110166166, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 13 with value: 10.754768831785016.\n",
      "[I 2025-02-16 15:54:37,927] Trial 14 finished with value: 10.75474933862375 and parameters: {'alpha': 0.09256348208680652, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 14 with value: 10.75474933862375.\n",
      "[I 2025-02-16 15:54:37,933] Trial 15 finished with value: 10.754747476085008 and parameters: {'alpha': 0.09772210269761235, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 15 with value: 10.754747476085008.\n",
      "[I 2025-02-16 15:54:37,940] Trial 16 finished with value: 10.75474721625226 and parameters: {'alpha': 0.09844194033237444, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:37,946] Trial 17 finished with value: 10.754760472987384 and parameters: {'alpha': 0.061773776931036015, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:37,952] Trial 18 finished with value: 10.754747926657947 and parameters: {'alpha': 0.09647394876472316, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:38,849] Trial 19 finished with value: 12.481907763329188 and parameters: {'alpha': 0.015136411387589293, 'solver': 'sag', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:38,856] Trial 20 finished with value: 10.758842035065614 and parameters: {'alpha': 0.05660911707940719, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:38,862] Trial 21 finished with value: 10.754749010014274 and parameters: {'alpha': 0.09347345218173682, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:38,869] Trial 22 finished with value: 10.754761829679031 and parameters: {'alpha': 0.05802784684702051, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:38,875] Trial 23 finished with value: 10.754751710579688 and parameters: {'alpha': 0.08599733439985144, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:38,881] Trial 24 finished with value: 11.7996008980804 and parameters: {'alpha': 0.046828193128041984, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:38,887] Trial 25 finished with value: 10.75477480313543 and parameters: {'alpha': 0.02226965707779518, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:38,892] Trial 26 finished with value: 10.83035423041544 and parameters: {'alpha': 0.06342114687293028, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 16 with value: 10.75474721625226.\n",
      "[I 2025-02-16 15:54:38,898] Trial 27 finished with value: 10.754747125234042 and parameters: {'alpha': 0.09869410693959833, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 27 with value: 10.754747125234042.\n",
      "[I 2025-02-16 15:54:38,904] Trial 28 finished with value: 10.754781727498665 and parameters: {'alpha': 0.003230582565105041, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 27 with value: 10.754747125234042.\n",
      "[I 2025-02-16 15:54:38,910] Trial 29 finished with value: 10.80672363623604 and parameters: {'alpha': 0.044227745455131175, 'solver': 'auto', 'fit_intercept': False}. Best is trial 27 with value: 10.754747125234042.\n",
      "[I 2025-02-16 15:54:38,915] A new study created in memory with name: no-name-df936789-13ca-4025-94fa-be4122f2b25e\n",
      "[I 2025-02-16 15:54:38,921] Trial 0 finished with value: 10.768618684495005 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.768618684495005.\n",
      "[I 2025-02-16 15:54:38,927] Trial 1 finished with value: 10.768618684495005 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.768618684495005.\n",
      "[I 2025-02-16 15:54:38,934] Trial 2 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,940] Trial 3 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,944] Trial 4 finished with value: 10.768618684495005 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,951] Trial 5 finished with value: 10.768618684495005 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,957] Trial 6 finished with value: 10.768618684495005 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,963] Trial 7 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,969] Trial 8 finished with value: 10.768618684495005 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,974] Trial 9 finished with value: 10.768618684495005 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,980] Trial 10 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,986] Trial 11 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,993] Trial 12 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:38,999] Trial 13 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,006] Trial 14 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,012] Trial 15 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,021] Trial 16 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,027] Trial 17 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,033] Trial 18 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,039] Trial 19 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,046] Trial 20 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,051] Trial 21 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,058] Trial 22 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,064] Trial 23 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,070] Trial 24 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,077] Trial 25 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,083] Trial 26 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,089] Trial 27 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,096] Trial 28 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n",
      "[I 2025-02-16 15:54:39,102] Trial 29 finished with value: 10.76861868449474 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.76861868449474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2/5\n",
      "Model name: ridge\n",
      "MAE: 8.572073084216392\n",
      "MSE: 115.6645857277299\n",
      "RMSE: 10.754747125234042\n",
      "PCC: 0.5251902059976251\n",
      "Spearman R: 0.5521689012378521\n",
      "R2 Score: 0.27503545776995886\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 15:54:39,109] A new study created in memory with name: no-name-21ad69d0-b375-442a-b5cd-a2b926404b51\n",
      "[I 2025-02-16 15:54:39,116] Trial 0 finished with value: 10.764415771474507 and parameters: {'alpha': 0.027636391818895118, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 0 with value: 10.764415771474507.\n",
      "[I 2025-02-16 15:54:39,130] Trial 1 finished with value: 10.763455326045946 and parameters: {'alpha': 0.017681260264199836, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 1 with value: 10.763455326045946.\n",
      "[I 2025-02-16 15:54:39,169] Trial 2 finished with value: 10.767935706364048 and parameters: {'alpha': 0.0010991473777676524, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': False}. Best is trial 1 with value: 10.763455326045946.\n",
      "[I 2025-02-16 15:54:39,194] Trial 3 finished with value: 10.763153987388407 and parameters: {'alpha': 0.01308257117025559, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.909e+05, tolerance: 1.180e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:39,264] Trial 4 finished with value: 11.044184643708322 and parameters: {'alpha': 0.011242676925045223, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 3 with value: 10.763153987388407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3/5\n",
      "Model name: linear_regression\n",
      "MAE: 8.636641879234567\n",
      "MSE: 115.96314837204922\n",
      "RMSE: 10.76861868449474\n",
      "PCC: 0.5387466191555833\n",
      "Spearman R: 0.5727311289965348\n",
      "R2 Score: 0.28899901278649087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.927e+05, tolerance: 1.180e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:39,330] Trial 5 finished with value: 11.13870126044481 and parameters: {'alpha': 0.016536315046074012, 'fit_intercept': False, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.874e+05, tolerance: 1.180e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:39,404] Trial 6 finished with value: 11.046066361028737 and parameters: {'alpha': 0.0010621967721780056, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.910e+05, tolerance: 1.180e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:39,475] Trial 7 finished with value: 11.131189248806646 and parameters: {'alpha': 0.00670802918692177, 'fit_intercept': False, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,487] Trial 8 finished with value: 10.764249662946579 and parameters: {'alpha': 0.023621048784266012, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,529] Trial 9 finished with value: 10.767295362425417 and parameters: {'alpha': 0.001962669234394213, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,537] Trial 10 finished with value: 10.774705595004956 and parameters: {'alpha': 0.08900666086063898, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,573] Trial 11 finished with value: 10.76516862348656 and parameters: {'alpha': 0.005316364256588589, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,584] Trial 12 finished with value: 10.76749850872398 and parameters: {'alpha': 0.05161443919349977, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,620] Trial 13 finished with value: 10.765488861599993 and parameters: {'alpha': 0.004750296403237322, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,635] Trial 14 finished with value: 10.764600354815348 and parameters: {'alpha': 0.030814391586488948, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,665] Trial 15 finished with value: 10.763271099283285 and parameters: {'alpha': 0.011549165158663041, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,697] Trial 16 finished with value: 10.763581753171465 and parameters: {'alpha': 0.00937498465269769, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,738] Trial 17 finished with value: 10.766508886898976 and parameters: {'alpha': 0.0031116409971309452, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.928e+05, tolerance: 1.180e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:39,808] Trial 18 finished with value: 11.135596898135253 and parameters: {'alpha': 0.012678744469796338, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,817] Trial 19 finished with value: 10.767445996622083 and parameters: {'alpha': 0.051195401158705425, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,856] Trial 20 finished with value: 10.766391397023432 and parameters: {'alpha': 0.003291154727918045, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,873] Trial 21 finished with value: 10.763533342379171 and parameters: {'alpha': 0.01837058987856197, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,905] Trial 22 finished with value: 10.764041319592907 and parameters: {'alpha': 0.007471706207245204, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 3 with value: 10.763153987388407.\n",
      "[I 2025-02-16 15:54:39,929] Trial 23 finished with value: 10.763127861550021 and parameters: {'alpha': 0.014959270791603706, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 23 with value: 10.763127861550021.\n",
      "[I 2025-02-16 15:54:39,939] Trial 24 finished with value: 10.766282206332184 and parameters: {'alpha': 0.04393544146479481, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 23 with value: 10.763127861550021.\n",
      "[I 2025-02-16 15:54:39,968] Trial 25 finished with value: 10.76330329739872 and parameters: {'alpha': 0.011250225668311463, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 23 with value: 10.763127861550021.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.921e+05, tolerance: 1.180e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:40,038] Trial 26 finished with value: 11.044840912376678 and parameters: {'alpha': 0.014688060907149752, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 23 with value: 10.763127861550021.\n",
      "[I 2025-02-16 15:54:40,071] Trial 27 finished with value: 10.763689350072301 and parameters: {'alpha': 0.008792287321841995, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 23 with value: 10.763127861550021.\n",
      "[I 2025-02-16 15:54:40,082] Trial 28 finished with value: 10.764697674976336 and parameters: {'alpha': 0.03403022156483855, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 23 with value: 10.763127861550021.\n",
      "[I 2025-02-16 15:54:40,097] Trial 29 finished with value: 10.764248442542952 and parameters: {'alpha': 0.023816081404497407, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 23 with value: 10.763127861550021.\n",
      "[I 2025-02-16 15:54:40,116] A new study created in memory with name: no-name-28315468-53d9-4821-953e-764fe94c9f45\n",
      "[I 2025-02-16 15:54:40,120] Trial 0 finished with value: 10.788035773651087 and parameters: {'alpha': 0.06181147752893861, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 0 with value: 10.788035773651087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3/5\n",
      "Model name: lasso\n",
      "MAE: 8.629635957833791\n",
      "MSE: 115.84479325926189\n",
      "RMSE: 10.763121910452464\n",
      "PCC: 0.5393426812191731\n",
      "Spearman R: 0.5747671629949856\n",
      "R2 Score: 0.2897246795454129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:41,123] Trial 1 finished with value: 12.69559181380868 and parameters: {'alpha': 0.00401502402438351, 'solver': 'saga', 'fit_intercept': True}. Best is trial 0 with value: 10.788035773651087.\n",
      "[I 2025-02-16 15:54:41,132] Trial 2 finished with value: 10.766283056516256 and parameters: {'alpha': 0.011714209075873483, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:41,136] Trial 3 finished with value: 10.767524659000987 and parameters: {'alpha': 0.020022996424731727, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:41,140] Trial 4 finished with value: 10.768617941094432 and parameters: {'alpha': 0.007226804397505677, 'solver': 'auto', 'fit_intercept': True}. Best is trial 2 with value: 10.766283056516256.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:42,057] Trial 5 finished with value: 12.622837205757598 and parameters: {'alpha': 0.08238515483462157, 'solver': 'sag', 'fit_intercept': True}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,062] Trial 6 finished with value: 10.768614067446624 and parameters: {'alpha': 0.044951440065332186, 'solver': 'auto', 'fit_intercept': True}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,067] Trial 7 finished with value: 11.139355099565051 and parameters: {'alpha': 0.0028264185464740915, 'solver': 'sparse_cg', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,078] Trial 8 finished with value: 10.768618520293971 and parameters: {'alpha': 0.0015958845236308953, 'solver': 'svd', 'fit_intercept': True}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,083] Trial 9 finished with value: 10.768614231034704 and parameters: {'alpha': 0.04335598119315623, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,105] Trial 10 finished with value: 10.766475921263616 and parameters: {'alpha': 0.014356340965461189, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,120] Trial 11 finished with value: 10.766477550667238 and parameters: {'alpha': 0.014370858346686095, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,126] Trial 12 finished with value: 12.092737784483843 and parameters: {'alpha': 0.009757605204230463, 'solver': 'lsqr', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,139] Trial 13 finished with value: 10.767593114041528 and parameters: {'alpha': 0.020292112121366564, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,150] Trial 14 finished with value: 10.766596596465364 and parameters: {'alpha': 0.006483090211656741, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,161] Trial 15 finished with value: 10.769603003955472 and parameters: {'alpha': 0.02662979748494706, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:42,167] Trial 16 finished with value: 11.139383259608477 and parameters: {'alpha': 0.004141785450987479, 'solver': 'sparse_cg', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:43,075] Trial 17 finished with value: 12.676363666076377 and parameters: {'alpha': 0.011460605311931837, 'solver': 'sag', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:44,060] Trial 18 finished with value: 12.717908966481374 and parameters: {'alpha': 0.0011010233157333145, 'solver': 'saga', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,065] Trial 19 finished with value: 12.092737830118882 and parameters: {'alpha': 0.029238753473736622, 'solver': 'lsqr', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,077] Trial 20 finished with value: 10.766608250847861 and parameters: {'alpha': 0.006411121361708044, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,087] Trial 21 finished with value: 10.766405908708682 and parameters: {'alpha': 0.013671579302423603, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,099] Trial 22 finished with value: 10.766456893655066 and parameters: {'alpha': 0.014182686239656959, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,109] Trial 23 finished with value: 10.766343151196123 and parameters: {'alpha': 0.00865764181649836, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,121] Trial 24 finished with value: 10.766340714458078 and parameters: {'alpha': 0.008690747265574289, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,133] Trial 25 finished with value: 10.767041719420945 and parameters: {'alpha': 0.004333167134465097, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,144] Trial 26 finished with value: 10.766345492096455 and parameters: {'alpha': 0.008626352158438827, 'solver': 'svd', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,150] Trial 27 finished with value: 10.767508947367427 and parameters: {'alpha': 0.0027408269251029196, 'solver': 'auto', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,156] Trial 28 finished with value: 12.092737772896117 and parameters: {'alpha': 0.004810877073856213, 'solver': 'lsqr', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,162] Trial 29 finished with value: 11.139424626359926 and parameters: {'alpha': 0.0027302003910044505, 'solver': 'sparse_cg', 'fit_intercept': False}. Best is trial 2 with value: 10.766283056516256.\n",
      "[I 2025-02-16 15:54:44,171] A new study created in memory with name: no-name-105c4ba3-6a0d-4c49-aade-b3c402ec10c9\n",
      "[I 2025-02-16 15:54:44,179] Trial 0 finished with value: 10.48065463772283 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 10.48065463772283.\n",
      "[I 2025-02-16 15:54:44,185] Trial 1 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,192] Trial 2 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,198] Trial 3 finished with value: 10.48065463772283 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,203] Trial 4 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,209] Trial 5 finished with value: 10.48065463772283 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,214] Trial 6 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,221] Trial 7 finished with value: 10.48065463772283 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,228] Trial 8 finished with value: 10.48065463772283 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,234] Trial 9 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,242] Trial 10 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,249] Trial 11 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,255] Trial 12 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,262] Trial 13 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,269] Trial 14 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,276] Trial 15 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,282] Trial 16 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,290] Trial 17 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,297] Trial 18 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,304] Trial 19 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,311] Trial 20 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,318] Trial 21 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,325] Trial 22 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,332] Trial 23 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,339] Trial 24 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,346] Trial 25 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3/5\n",
      "Model name: ridge\n",
      "MAE: 8.641102723901515\n",
      "MSE: 115.91285085302901\n",
      "RMSE: 10.766283056516256\n",
      "PCC: 0.5389940280227418\n",
      "Spearman R: 0.5711893891364802\n",
      "R2 Score: 0.2893074002887258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 15:54:44,353] Trial 26 finished with value: 10.48065463772283 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,360] Trial 27 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,367] Trial 28 finished with value: 10.480654637722795 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,374] Trial 29 finished with value: 10.48065463772283 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 10.480654637722795.\n",
      "[I 2025-02-16 15:54:44,380] A new study created in memory with name: no-name-bb6d31b2-fff6-4418-9be6-a248f2035e6d\n",
      "[I 2025-02-16 15:54:44,387] Trial 0 finished with value: 10.48050427976472 and parameters: {'alpha': 0.06150695887837334, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 0 with value: 10.48050427976472.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.755e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:44,476] Trial 1 finished with value: 10.476997175343003 and parameters: {'alpha': 0.001728438562427703, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 1 with value: 10.476997175343003.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.239e+05, tolerance: 1.203e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:44,538] Trial 2 finished with value: 11.036138529938121 and parameters: {'alpha': 0.07559944379209406, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 1 with value: 10.476997175343003.\n",
      "[I 2025-02-16 15:54:44,549] Trial 3 finished with value: 10.477779388748813 and parameters: {'alpha': 0.04836481875950436, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 1 with value: 10.476997175343003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4/5\n",
      "Model name: linear_regression\n",
      "MAE: 8.275292415766692\n",
      "MSE: 109.84412163522033\n",
      "RMSE: 10.480654637722795\n",
      "PCC: 0.5648315854058783\n",
      "Spearman R: 0.5899297343475526\n",
      "R2 Score: 0.3169390462193966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.204e+05, tolerance: 1.203e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:44,613] Trial 4 finished with value: 10.947201124049482 and parameters: {'alpha': 0.06286507945751717, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 1 with value: 10.476997175343003.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.029e+05, tolerance: 1.203e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:44,696] Trial 5 finished with value: 10.948464949470548 and parameters: {'alpha': 0.011861240987532481, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': True}. Best is trial 1 with value: 10.476997175343003.\n",
      "[I 2025-02-16 15:54:44,709] Trial 6 finished with value: 10.476819451899535 and parameters: {'alpha': 0.02991950664508554, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 6 with value: 10.476819451899535.\n",
      "[I 2025-02-16 15:54:44,720] Trial 7 finished with value: 10.477517203134166 and parameters: {'alpha': 0.046863640042950135, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 6 with value: 10.476819451899535.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.755e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:44,812] Trial 8 finished with value: 10.477339104645845 and parameters: {'alpha': 0.0014562061254810863, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 6 with value: 10.476819451899535.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.751e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:44,902] Trial 9 finished with value: 10.47597461510516 and parameters: {'alpha': 0.0028017879293991445, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 9 with value: 10.47597461510516.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.000e+05, tolerance: 1.203e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:44,988] Trial 10 finished with value: 10.956357598800912 and parameters: {'alpha': 0.004480768195123223, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': True}. Best is trial 9 with value: 10.47597461510516.\n",
      "[I 2025-02-16 15:54:45,020] Trial 11 finished with value: 10.476706195800606 and parameters: {'alpha': 0.01062176046025872, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 9 with value: 10.47597461510516.\n",
      "[I 2025-02-16 15:54:45,054] Trial 12 finished with value: 10.476706699456333 and parameters: {'alpha': 0.007162782352692217, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 9 with value: 10.47597461510516.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.739e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,144] Trial 13 finished with value: 10.475527665786341 and parameters: {'alpha': 0.00402395921607768, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.748e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,234] Trial 14 finished with value: 10.475757020261305 and parameters: {'alpha': 0.003142770065382897, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,324] Trial 15 finished with value: 10.477982518396098 and parameters: {'alpha': 0.0010009895343787224, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.743e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,421] Trial 16 finished with value: 10.475560536311367 and parameters: {'alpha': 0.003686502423772906, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "[I 2025-02-16 15:54:45,446] Trial 17 finished with value: 10.477396643143507 and parameters: {'alpha': 0.017413765493432723, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.004e+05, tolerance: 1.203e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,532] Trial 18 finished with value: 10.955410156020854 and parameters: {'alpha': 0.005479115775818482, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.750e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,624] Trial 19 finished with value: 10.475892590046271 and parameters: {'alpha': 0.0029211341449078302, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "[I 2025-02-16 15:54:45,648] Trial 20 finished with value: 10.477549424419047 and parameters: {'alpha': 0.01951749732763143, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.750e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,740] Trial 21 finished with value: 10.475875155886296 and parameters: {'alpha': 0.0029477298519736354, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.736e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,830] Trial 22 finished with value: 10.475531536379822 and parameters: {'alpha': 0.004215723782037924, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "[I 2025-02-16 15:54:45,864] Trial 23 finished with value: 10.476720740269855 and parameters: {'alpha': 0.006930120096811584, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:45,954] Trial 24 finished with value: 10.475534466848295 and parameters: {'alpha': 0.0038920291638305975, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.754e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:46,045] Trial 25 finished with value: 10.47661082311243 and parameters: {'alpha': 0.0020751925248874725, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.011e+05, tolerance: 1.203e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:46,129] Trial 26 finished with value: 10.953536364664249 and parameters: {'alpha': 0.007182449305264725, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:46,221] Trial 27 finished with value: 10.475715682048834 and parameters: {'alpha': 0.005008832162298712, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.754e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:46,313] Trial 28 finished with value: 10.476569005657593 and parameters: {'alpha': 0.00211595599046715, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 13 with value: 10.475527665786341.\n",
      "[I 2025-02-16 15:54:46,341] Trial 29 finished with value: 10.476891401324723 and parameters: {'alpha': 0.01339928056245184, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 13 with value: 10.475527665786341.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.619e+05, tolerance: 1.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:46,430] A new study created in memory with name: no-name-74b3b137-2eab-467f-a990-f1e1265ebb6b\n",
      "[I 2025-02-16 15:54:46,435] Trial 0 finished with value: 11.598384620926069 and parameters: {'alpha': 0.00852851421357851, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 0 with value: 11.598384620926069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4/5\n",
      "Model name: lasso\n",
      "MAE: 8.270180475511273\n",
      "MSE: 109.7365324627828\n",
      "RMSE: 10.475520629676732\n",
      "PCC: 0.565617986504019\n",
      "Spearman R: 0.5917646217830554\n",
      "R2 Score: 0.31760808486841685\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:47,433] Trial 1 finished with value: 12.633752085398742 and parameters: {'alpha': 0.0013444397185540108, 'solver': 'saga', 'fit_intercept': False}. Best is trial 0 with value: 11.598384620926069.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:48,404] Trial 2 finished with value: 12.63375208537849 and parameters: {'alpha': 0.0010097868923959231, 'solver': 'saga', 'fit_intercept': False}. Best is trial 0 with value: 11.598384620926069.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:49,295] Trial 3 finished with value: 12.542398070614338 and parameters: {'alpha': 0.006472396281908156, 'solver': 'sag', 'fit_intercept': True}. Best is trial 0 with value: 11.598384620926069.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:50,174] Trial 4 finished with value: 12.593633158193663 and parameters: {'alpha': 0.004455554746164249, 'solver': 'sag', 'fit_intercept': False}. Best is trial 0 with value: 11.598384620926069.\n",
      "[I 2025-02-16 15:54:50,178] Trial 5 finished with value: 10.606478810543761 and parameters: {'alpha': 0.06760990608273972, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 5 with value: 10.606478810543761.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:51,060] Trial 6 finished with value: 12.593633163479081 and parameters: {'alpha': 0.04739843919163662, 'solver': 'sag', 'fit_intercept': False}. Best is trial 5 with value: 10.606478810543761.\n",
      "[I 2025-02-16 15:54:51,064] Trial 7 finished with value: 12.002102483827846 and parameters: {'alpha': 0.01667257414496725, 'solver': 'lsqr', 'fit_intercept': False}. Best is trial 5 with value: 10.606478810543761.\n",
      "[I 2025-02-16 15:54:51,069] Trial 8 finished with value: 10.50644858944868 and parameters: {'alpha': 0.022303704210080197, 'solver': 'auto', 'fit_intercept': False}. Best is trial 8 with value: 10.50644858944868.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:52,046] Trial 9 finished with value: 12.615639702117871 and parameters: {'alpha': 0.011419087033680992, 'solver': 'saga', 'fit_intercept': True}. Best is trial 8 with value: 10.50644858944868.\n",
      "[I 2025-02-16 15:54:52,052] Trial 10 finished with value: 10.48062934986731 and parameters: {'alpha': 0.026125206585105563, 'solver': 'auto', 'fit_intercept': True}. Best is trial 10 with value: 10.48062934986731.\n",
      "[I 2025-02-16 15:54:52,059] Trial 11 finished with value: 10.48062685089384 and parameters: {'alpha': 0.028721868414551963, 'solver': 'auto', 'fit_intercept': True}. Best is trial 11 with value: 10.48062685089384.\n",
      "[I 2025-02-16 15:54:52,065] Trial 12 finished with value: 10.480613173906876 and parameters: {'alpha': 0.04298168211831778, 'solver': 'auto', 'fit_intercept': True}. Best is trial 12 with value: 10.480613173906876.\n",
      "[I 2025-02-16 15:54:52,076] Trial 13 finished with value: 10.480567472738672 and parameters: {'alpha': 0.09123203711784085, 'solver': 'svd', 'fit_intercept': True}. Best is trial 13 with value: 10.480567472738672.\n",
      "[I 2025-02-16 15:54:52,087] Trial 14 finished with value: 10.480559320718658 and parameters: {'alpha': 0.09993806740089928, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,098] Trial 15 finished with value: 10.480580747756994 and parameters: {'alpha': 0.07711980288088428, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,111] Trial 16 finished with value: 10.480561470449347 and parameters: {'alpha': 0.09763927785720038, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,118] Trial 17 finished with value: 10.48136251915142 and parameters: {'alpha': 0.0029754247445335693, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,130] Trial 18 finished with value: 10.480608618508827 and parameters: {'alpha': 0.047749396832623636, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,141] Trial 19 finished with value: 10.480565018457305 and parameters: {'alpha': 0.09384990295402021, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,151] Trial 20 finished with value: 10.480617890752919 and parameters: {'alpha': 0.03805460046430462, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,163] Trial 21 finished with value: 10.480562865501742 and parameters: {'alpha': 0.09614863207068626, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,173] Trial 22 finished with value: 10.480595415619812 and parameters: {'alpha': 0.061619476640613596, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,185] Trial 23 finished with value: 10.480560987914602 and parameters: {'alpha': 0.09815508566328839, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,193] Trial 24 finished with value: 10.481291320592947 and parameters: {'alpha': 0.05767730684776552, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,205] Trial 25 finished with value: 10.480622795452845 and parameters: {'alpha': 0.03294161407366411, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,211] Trial 26 finished with value: 10.480637868353115 and parameters: {'alpha': 0.017294011923029474, 'solver': 'cholesky', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,222] Trial 27 finished with value: 10.480585059002596 and parameters: {'alpha': 0.07255384104089131, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,234] Trial 28 finished with value: 10.480601051551034 and parameters: {'alpha': 0.0556892791928761, 'solver': 'svd', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,241] Trial 29 finished with value: 11.598384665845353 and parameters: {'alpha': 0.012461050928944315, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 14 with value: 10.480559320718658.\n",
      "[I 2025-02-16 15:54:52,251] A new study created in memory with name: no-name-c39a2a08-8c33-4e3f-a028-e1351120e783\n",
      "[I 2025-02-16 15:54:52,257] Trial 0 finished with value: 10.90594736718212 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.90594736718212.\n",
      "[I 2025-02-16 15:54:52,263] Trial 1 finished with value: 10.90594736718212 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 10.90594736718212.\n",
      "[I 2025-02-16 15:54:52,272] Trial 2 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,279] Trial 3 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,284] Trial 4 finished with value: 10.90594736718212 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,290] Trial 5 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,297] Trial 6 finished with value: 10.90594736718212 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,303] Trial 7 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,310] Trial 8 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,315] Trial 9 finished with value: 10.90594736718212 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,322] Trial 10 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,327] Trial 11 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,333] Trial 12 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,339] Trial 13 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,345] Trial 14 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,352] Trial 15 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,359] Trial 16 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,366] Trial 17 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,374] Trial 18 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,380] Trial 19 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,389] Trial 20 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,396] Trial 21 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,402] Trial 22 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,408] Trial 23 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,414] Trial 24 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,421] Trial 25 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,428] Trial 26 finished with value: 10.90594736718212 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.905947367180413.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4/5\n",
      "Model name: ridge\n",
      "MAE: 8.275262361784382\n",
      "MSE: 109.84212367510273\n",
      "RMSE: 10.480559320718658\n",
      "PCC: 0.5648473882152805\n",
      "Spearman R: 0.5899849706972542\n",
      "R2 Score: 0.3169514704485973\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 15:54:52,435] Trial 27 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,442] Trial 28 finished with value: 10.905947367180413 and parameters: {'fit_intercept': False}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,449] Trial 29 finished with value: 10.90594736718212 and parameters: {'fit_intercept': True}. Best is trial 2 with value: 10.905947367180413.\n",
      "[I 2025-02-16 15:54:52,456] A new study created in memory with name: no-name-3eca53f3-ef0d-4ebe-a56f-abe29992889a\n",
      "[I 2025-02-16 15:54:52,478] Trial 0 finished with value: 10.786997748895105 and parameters: {'alpha': 0.018142985322674953, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 0 with value: 10.786997748895105.\n",
      "[I 2025-02-16 15:54:52,499] Trial 1 finished with value: 10.790983265036012 and parameters: {'alpha': 0.011162518534834128, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 0 with value: 10.786997748895105.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.928e+05, tolerance: 1.194e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:52,571] Trial 2 finished with value: 11.13822135375349 and parameters: {'alpha': 0.0015561349203648868, 'fit_intercept': False, 'selection': 'random', 'warm_start': False}. Best is trial 0 with value: 10.786997748895105.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.169e+05, tolerance: 1.194e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:52,616] Trial 3 finished with value: 11.12428828986685 and parameters: {'alpha': 0.07994668262364889, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 0 with value: 10.786997748895105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5/5\n",
      "Model name: linear_regression\n",
      "MAE: 8.596058566883377\n",
      "MSE: 118.93968797570939\n",
      "RMSE: 10.905947367180413\n",
      "PCC: 0.5235762981647845\n",
      "Spearman R: 0.5555014425786886\n",
      "R2 Score: 0.2721068246878642\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.118e+05, tolerance: 1.194e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:52,667] Trial 4 finished with value: 11.174906823330469 and parameters: {'alpha': 0.06705168438753978, 'fit_intercept': False, 'selection': 'random', 'warm_start': True}. Best is trial 0 with value: 10.786997748895105.\n",
      "[I 2025-02-16 15:54:52,680] Trial 5 finished with value: 10.78163631608544 and parameters: {'alpha': 0.03392813672580918, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 5 with value: 10.78163631608544.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.894e+05, tolerance: 1.194e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:52,750] Trial 6 finished with value: 11.147062077250984 and parameters: {'alpha': 0.0022633043547888366, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 5 with value: 10.78163631608544.\n",
      "[I 2025-02-16 15:54:52,774] Trial 7 finished with value: 10.787642195397028 and parameters: {'alpha': 0.016827736515794327, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 5 with value: 10.78163631608544.\n",
      "[I 2025-02-16 15:54:52,796] Trial 8 finished with value: 10.786485679980771 and parameters: {'alpha': 0.019260826349551997, 'fit_intercept': True, 'selection': 'random', 'warm_start': False}. Best is trial 5 with value: 10.78163631608544.\n",
      "[I 2025-02-16 15:54:52,813] Trial 9 finished with value: 10.786176344931105 and parameters: {'alpha': 0.019938196081553394, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 5 with value: 10.78163631608544.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.672e+05, tolerance: 1.041e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:52,890] Trial 10 finished with value: 10.799757271397207 and parameters: {'alpha': 0.004210623080071494, 'fit_intercept': True, 'selection': 'random', 'warm_start': True}. Best is trial 5 with value: 10.78163631608544.\n",
      "[I 2025-02-16 15:54:52,900] Trial 11 finished with value: 10.780764240710065 and parameters: {'alpha': 0.036366829705056974, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 11 with value: 10.780764240710065.\n",
      "[I 2025-02-16 15:54:52,909] Trial 12 finished with value: 10.7798020133619 and parameters: {'alpha': 0.038825471871118435, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 12 with value: 10.7798020133619.\n",
      "[I 2025-02-16 15:54:52,922] Trial 13 finished with value: 10.778303174168592 and parameters: {'alpha': 0.04712187609195285, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 13 with value: 10.778303174168592.\n",
      "[I 2025-02-16 15:54:52,947] Trial 14 finished with value: 10.795835545576448 and parameters: {'alpha': 0.005660224224423826, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 13 with value: 10.778303174168592.\n",
      "[I 2025-02-16 15:54:52,957] Trial 15 finished with value: 10.779050563213652 and parameters: {'alpha': 0.04155245219303296, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 13 with value: 10.778303174168592.\n",
      "[I 2025-02-16 15:54:52,964] Trial 16 finished with value: 10.783435812418508 and parameters: {'alpha': 0.08895764270711888, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 13 with value: 10.778303174168592.\n",
      "[I 2025-02-16 15:54:52,972] Trial 17 finished with value: 10.778179247737228 and parameters: {'alpha': 0.051986254153917645, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 17 with value: 10.778179247737228.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.920e+05, tolerance: 1.194e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:53,042] Trial 18 finished with value: 11.138147739406554 and parameters: {'alpha': 0.007840616347563984, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': True}. Best is trial 17 with value: 10.778179247737228.\n",
      "[I 2025-02-16 15:54:53,051] Trial 19 finished with value: 10.778159204964616 and parameters: {'alpha': 0.05234073504089402, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,060] Trial 20 finished with value: 10.778252743029315 and parameters: {'alpha': 0.055601200947430776, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,069] Trial 21 finished with value: 10.778412417720103 and parameters: {'alpha': 0.05881227705823861, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,079] Trial 22 finished with value: 10.78278479256535 and parameters: {'alpha': 0.02937859915167599, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,088] Trial 23 finished with value: 10.783102431531404 and parameters: {'alpha': 0.0875905169007575, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,097] Trial 24 finished with value: 10.77829071856771 and parameters: {'alpha': 0.05651441130185509, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,108] Trial 25 finished with value: 10.78413927480762 and parameters: {'alpha': 0.025882930997113696, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.215e+05, tolerance: 1.194e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-02-16 15:54:53,155] Trial 26 finished with value: 11.151827910725538 and parameters: {'alpha': 0.0999063318078774, 'fit_intercept': False, 'selection': 'cyclic', 'warm_start': False}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,178] Trial 27 finished with value: 10.790909875084445 and parameters: {'alpha': 0.011274153806859252, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,186] Trial 28 finished with value: 10.778159866547393 and parameters: {'alpha': 0.052792281757166784, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,208] Trial 29 finished with value: 10.788112214402897 and parameters: {'alpha': 0.015909275439625836, 'fit_intercept': True, 'selection': 'cyclic', 'warm_start': True}. Best is trial 19 with value: 10.778159204964616.\n",
      "[I 2025-02-16 15:54:53,215] A new study created in memory with name: no-name-1cbbc6cf-5fd4-485a-8572-7a7322ecacee\n",
      "[I 2025-02-16 15:54:53,224] Trial 0 finished with value: 10.902418370052766 and parameters: {'alpha': 0.058289965184958034, 'solver': 'svd', 'fit_intercept': True}. Best is trial 0 with value: 10.902418370052766.\n",
      "[I 2025-02-16 15:54:53,227] Trial 1 finished with value: 11.76017258103147 and parameters: {'alpha': 0.008538360113097351, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 0 with value: 10.902418370052766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5/5\n",
      "Model name: lasso\n",
      "MAE: 8.548655948256824\n",
      "MSE: 116.16871584756348\n",
      "RMSE: 10.778159204964616\n",
      "PCC: 0.5377233628482976\n",
      "Spearman R: 0.5656504465431432\n",
      "R2 Score: 0.2890647613983546\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:54,204] Trial 2 finished with value: 12.701612236509364 and parameters: {'alpha': 0.0072948414253001985, 'solver': 'saga', 'fit_intercept': True}. Best is trial 0 with value: 10.902418370052766.\n",
      "[I 2025-02-16 15:54:54,208] Trial 3 finished with value: 10.82441652537743 and parameters: {'alpha': 0.022002739794985605, 'solver': 'auto', 'fit_intercept': False}. Best is trial 3 with value: 10.82441652537743.\n",
      "[I 2025-02-16 15:54:54,212] Trial 4 finished with value: 12.08914074400373 and parameters: {'alpha': 0.0011979886979986486, 'solver': 'lsqr', 'fit_intercept': False}. Best is trial 3 with value: 10.82441652537743.\n",
      "[I 2025-02-16 15:54:54,216] Trial 5 finished with value: 11.760172561865351 and parameters: {'alpha': 0.0027931935015299923, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 3 with value: 10.82441652537743.\n",
      "[I 2025-02-16 15:54:54,222] Trial 6 finished with value: 11.76017256193187 and parameters: {'alpha': 0.0028131337582876, 'solver': 'lsqr', 'fit_intercept': True}. Best is trial 3 with value: 10.82441652537743.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:55,205] Trial 7 finished with value: 12.701612235970998 and parameters: {'alpha': 0.001097999825534006, 'solver': 'saga', 'fit_intercept': True}. Best is trial 3 with value: 10.82441652537743.\n",
      "[I 2025-02-16 15:54:55,213] Trial 8 finished with value: 10.90585959293437 and parameters: {'alpha': 0.001413421949404443, 'solver': 'svd', 'fit_intercept': True}. Best is trial 3 with value: 10.82441652537743.\n",
      "[I 2025-02-16 15:54:55,218] Trial 9 finished with value: 10.800198150545029 and parameters: {'alpha': 0.012648000033435684, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 9 with value: 10.800198150545029.\n",
      "[I 2025-02-16 15:54:55,224] Trial 10 finished with value: 11.33129675311053 and parameters: {'alpha': 0.027313032704494353, 'solver': 'sparse_cg', 'fit_intercept': False}. Best is trial 9 with value: 10.800198150545029.\n",
      "[I 2025-02-16 15:54:55,230] Trial 11 finished with value: 10.82046958220674 and parameters: {'alpha': 0.021134551276581145, 'solver': 'auto', 'fit_intercept': False}. Best is trial 9 with value: 10.800198150545029.\n",
      "[I 2025-02-16 15:54:55,236] Trial 12 finished with value: 10.819602674225147 and parameters: {'alpha': 0.020937984289287937, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 9 with value: 10.800198150545029.\n",
      "[I 2025-02-16 15:54:55,243] Trial 13 finished with value: 11.187320961276335 and parameters: {'alpha': 0.0988543110628061, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 9 with value: 10.800198150545029.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:56,146] Trial 14 finished with value: 12.681232239021153 and parameters: {'alpha': 0.013088557851377348, 'solver': 'sag', 'fit_intercept': False}. Best is trial 9 with value: 10.800198150545029.\n",
      "[I 2025-02-16 15:54:56,152] Trial 15 finished with value: 10.920311495505688 and parameters: {'alpha': 0.03916037951866821, 'solver': 'cholesky', 'fit_intercept': False}. Best is trial 9 with value: 10.800198150545029.\n",
      "[I 2025-02-16 15:54:56,159] Trial 16 finished with value: 11.331309045383648 and parameters: {'alpha': 0.005241381086365025, 'solver': 'sparse_cg', 'fit_intercept': False}. Best is trial 9 with value: 10.800198150545029.\n",
      "[I 2025-02-16 15:54:56,166] Trial 17 finished with value: 10.800197835790861 and parameters: {'alpha': 0.01308239333286507, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 17 with value: 10.800197835790861.\n",
      "[I 2025-02-16 15:54:56,174] Trial 18 finished with value: 10.800197368193517 and parameters: {'alpha': 0.013995492366838596, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 18 with value: 10.800197368193517.\n",
      "[I 2025-02-16 15:54:56,181] Trial 19 finished with value: 10.800199313807147 and parameters: {'alpha': 0.0041264069075441405, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 18 with value: 10.800197368193517.\n",
      "[I 2025-02-16 15:54:56,189] Trial 20 finished with value: 10.800197900201251 and parameters: {'alpha': 0.013472278172447765, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 18 with value: 10.800197368193517.\n",
      "[I 2025-02-16 15:54:56,197] Trial 21 finished with value: 10.800197931009269 and parameters: {'alpha': 0.0138923639292795, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 18 with value: 10.800197368193517.\n",
      "[I 2025-02-16 15:54:56,204] Trial 22 finished with value: 10.80019887855055 and parameters: {'alpha': 0.007017558373556404, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 18 with value: 10.800197368193517.\n",
      "[I 2025-02-16 15:54:56,212] Trial 23 finished with value: 10.800194019979662 and parameters: {'alpha': 0.04220597045289045, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 23 with value: 10.800194019979662.\n",
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-02-16 15:54:57,108] Trial 24 finished with value: 12.626655139948067 and parameters: {'alpha': 0.05060012393840171, 'solver': 'sag', 'fit_intercept': True}. Best is trial 23 with value: 10.800194019979662.\n",
      "[I 2025-02-16 15:54:57,115] Trial 25 finished with value: 10.8001956188402 and parameters: {'alpha': 0.03318460513310372, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 23 with value: 10.800194019979662.\n",
      "[I 2025-02-16 15:54:57,122] Trial 26 finished with value: 10.800188205119289 and parameters: {'alpha': 0.08152851319785274, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 26 with value: 10.800188205119289.\n",
      "[I 2025-02-16 15:54:57,129] Trial 27 finished with value: 10.800187739603704 and parameters: {'alpha': 0.08671000219412894, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 27 with value: 10.800187739603704.\n",
      "[I 2025-02-16 15:54:57,136] Trial 28 finished with value: 10.80018615105876 and parameters: {'alpha': 0.09876655222324315, 'solver': 'sparse_cg', 'fit_intercept': True}. Best is trial 28 with value: 10.80018615105876.\n",
      "[I 2025-02-16 15:54:57,147] Trial 29 finished with value: 10.90054150359926 and parameters: {'alpha': 0.09056780409289653, 'solver': 'svd', 'fit_intercept': True}. Best is trial 28 with value: 10.80018615105876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5/5\n",
      "Model name: ridge\n",
      "MAE: 8.581201472894989\n",
      "MSE: 116.64402089752144\n",
      "RMSE: 10.80018615105876\n",
      "PCC: 0.5355512434348788\n",
      "Spearman R: 0.556710000667969\n",
      "R2 Score: 0.2861559652854334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train + Validate models\n",
    "metrics = [\"mae\", \"mse\", \"rmse\", \"pcc\", \"spearman_r\", \"r2_score\"]\n",
    "model_scores = {model_name: defaultdict(list) for model_name in models.keys()}\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    fold_data = kfold_data[fold]\n",
    "     \n",
    "    # Extract data\n",
    "    train_data = fold_data[\"train\"]\n",
    "    val_data = fold_data[\"val\"]\n",
    "    test_data = kfold_data[fold][\"test\"]\n",
    "\n",
    "    train_y = train_data[\"outcome\"]\n",
    "    val_y = val_data[\"outcome\"]\n",
    "    test_y = test_data[\"outcome\"]\n",
    "\n",
    "    train_x = train_data.drop(columns=[\"outcome\"])\n",
    "    val_x = val_data.drop(columns=[\"outcome\"])\n",
    "    test_x = test_data.drop(columns=[\"outcome\"])\n",
    "\n",
    "    # print(f\"Fold {fold+1}/{NUM_FOLDS}\")\n",
    "    # print(f\"Train data shape: {train_x.shape} | Train target shape: {train_y.shape}\")\n",
    "    # print(f\"Val data shape: {val_x.shape} | Val target shape: {val_y.shape}\")\n",
    "    # print(f\"Test data shape: {test_x.shape} | Test target shape: {test_y.shape}\")\n",
    "\n",
    "    # Train model\n",
    "    for model_name, model in models.items():\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(lambda trial: objective(trial=trial, \n",
    "                                               model_type=model, \n",
    "                                               x_train=train_x, \n",
    "                                               y_train=train_y, \n",
    "                                               x_val=val_x, \n",
    "                                               y_val=val_y\n",
    "                                               ), n_trials=30)\n",
    "        \n",
    "        # Train model with best hyperparameters\n",
    "        best_fold_params = study.best_params\n",
    "        model = model(**best_fold_params)\n",
    "        model.fit(train_x, train_y)\n",
    "        preds = model.predict(val_x)\n",
    "\n",
    "        metrics = calculate_metrics(targets=val_y, preds=preds)\n",
    "        mae = metrics[\"mae\"]\n",
    "        mse = metrics[\"mse\"]\n",
    "        rmse = metrics[\"rmse\"]\n",
    "        pcc = metrics[\"pcc\"]\n",
    "        spearman_r = metrics[\"spearman_r\"]\n",
    "        r2_score = metrics[\"r2_score\"]\n",
    "\n",
    "        for metric in metrics:\n",
    "            model_scores[model_name][metric].append(metrics[metric])\n",
    "\n",
    "        print(f\"Fold: {fold+1}/{NUM_FOLDS}\")\n",
    "        print(f\"Model name: {model_name}\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"PCC: {pcc}\")\n",
    "        print(f\"Spearman R: {spearman_r}\")\n",
    "        print(f\"R2 Score: {r2_score}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute average scores and rank models by R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_metrics in model_scores.items():\n",
    "    for metric, scores in model_metrics.items():\n",
    "        model_scores[model_name][metric] = sum(scores) / len(scores)\n",
    "    model_scores[model_name] = dict(model_scores[model_name])\n",
    "\n",
    "model_scores = dict(sorted(model_scores.items(), key=lambda x: x[1][\"r2_score\"], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.1 Model: lasso\n",
      "mae: 8.55142996065934\n",
      "mse: 115.22621273770429\n",
      "rmse: 10.733397920563233\n",
      "pcc: 0.5432106763598974\n",
      "spearman_r: 0.57210927387081\n",
      "r2_score: 0.2943863424292353\n",
      "\n",
      "No.2 Model: ridge\n",
      "mae: 8.569002385106042\n",
      "mse: 115.43577237504641\n",
      "rmse: 10.743154074464211\n",
      "pcc: 0.5421809362717445\n",
      "spearman_r: 0.567962929477707\n",
      "r2_score: 0.29309029601575254\n",
      "\n",
      "No.3 Model: linear_regression\n",
      "mae: 8.57109532257773\n",
      "mse: 115.90552181588734\n",
      "rmse: 10.764799800447392\n",
      "pcc: 0.5397327873066068\n",
      "spearman_r: 0.5680140097710977\n",
      "r2_score: 0.29021532307368103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for i, (model_name, model_metrics) in enumerate(model_scores.items()):\n",
    "    print(f\"No.{i+1} Model: {model_name}\")\n",
    "    for metric, score in model_metrics.items():\n",
    "        print(f\"{metric}: {score}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
