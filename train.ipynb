{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "from src.utils import get_kfold_data, convert_non_numeric_to_numeric, calculate_r2_score, calculate_metrics\n",
    "from src.normalisation import Normaliser\n",
    "from src.constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns\n",
    "all_columns = data.columns.tolist()\n",
    "print(all_columns)\n",
    "\n",
    "numeric_columns = data.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "numeric_columns.remove(\"outcome\") # Remove the target column\n",
    "print(numeric_columns)\n",
    "\n",
    "non_numeric_columns = data.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "print(non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for non_numeric_column in non_numeric_columns:\n",
    "    print(data[non_numeric_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting non-numeric features to numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_non_numeric_to_numeric(data=data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise data using each columns respective mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normaliser = Normaliser()\n",
    "for column in numeric_columns:\n",
    "    print(data[column])\n",
    "    data[column] = normaliser.standardise(data[column])\n",
    "    print(\"after\", data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_data = get_kfold_data(data=data, k=NUM_FOLDS, reproducibility_seed=REPRODUCIBILITY_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define models and hyperparameter tuning objectives for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "        \"linear_regression\": LinearRegression,\n",
    "        \"lasso\": Lasso,\n",
    "        \"ridge\": Ridge,\n",
    "        \"xgb\": xgb.XGBRegressor,\n",
    "        \"random_forest\": RandomForestRegressor,\n",
    "        \"gradient_boosting\": GradientBoostingRegressor,\n",
    "        \"ada_boost\": AdaBoostRegressor,\n",
    "        \"lgbm\": lgb.LGBMRegressor\n",
    "        }\n",
    "\n",
    "def objective(model_type, trial, x_train, y_train, x_val, y_val):\n",
    "    if model_type == LinearRegression:\n",
    "        parameters = {\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "        }\n",
    "    elif model_type == Lasso:\n",
    "        parameters = {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 0.1, log=True),\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "            \"selection\": trial.suggest_categorical(\"selection\", [\"cyclic\", \"random\"]),\n",
    "            \"warm_start\": trial.suggest_categorical(\"warm_start\", [True, False]),\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == Ridge:\n",
    "        parameters = {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 0.1, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]),\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "            \"positive\": False,\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == xgb.XGBRegressor:\n",
    "        parameters = {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"n_estimators\": 100,\n",
    "            \"eta\": trial.suggest_float(\"eta\", 1e-2, 0.2, log=True),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 10, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 6),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"seed\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == RandomForestRegressor:\n",
    "        parameters = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"absolute_error\", \"squared_error\"]),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"bootstrap\": True,\n",
    "            \"oob_score\": False,\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == GradientBoostingRegressor:\n",
    "        parameters = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"loss\": trial.suggest_categorical(\"loss\", [\"absolute_error\", \"squared_error\", \"huber\", \"quantile\"]),\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"friedman_mse\", \"squared_error\"]),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "            \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 2**10),\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == AdaBoostRegressor:\n",
    "        parameters = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 100),\n",
    "            \"loss\": trial.suggest_categorical(\"loss\", [\"linear\", \"square\", \"exponential\"]),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"random_state\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "    elif model_type == lgb.LGBMRegressor:\n",
    "        parameters = {\n",
    "                    \"objective\": \"regression\",\n",
    "                    \"metric\": \"rmse\",\n",
    "                    \"n_estimators\": 100,\n",
    "                    \"verbosity\": -1,\n",
    "                    \"bagging_freq\": 1,\n",
    "                    \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "                    \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "                    \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "                    \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "                    \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "                    \"seed\": REPRODUCIBILITY_SEED\n",
    "        }\n",
    "\n",
    "    \n",
    "    model = model_type(**parameters) # Create the model\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_val)\n",
    "    metrics = calculate_metrics(targets=y_val, preds=predictions)\n",
    "    rmse = metrics[\"rmse\"]\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train + Validate models\n",
    "metrics = [\"mae\", \"mse\", \"rmse\", \"pcc\", \"spearman_r\", \"r2_score\"]\n",
    "model_scores = {model_name: defaultdict(list) for model_name in models.keys()}\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    fold_data = kfold_data[fold]\n",
    "     \n",
    "    # Extract data\n",
    "    train_data = fold_data[\"train\"]\n",
    "    val_data = fold_data[\"val\"]\n",
    "    test_data = kfold_data[fold][\"test\"]\n",
    "\n",
    "    train_y = train_data[\"outcome\"]\n",
    "    val_y = val_data[\"outcome\"]\n",
    "    test_y = test_data[\"outcome\"]\n",
    "\n",
    "    train_x = train_data.drop(columns=[\"outcome\"])\n",
    "    val_x = val_data.drop(columns=[\"outcome\"])\n",
    "    test_x = test_data.drop(columns=[\"outcome\"])\n",
    "\n",
    "    # print(f\"Fold {fold+1}/{NUM_FOLDS}\")\n",
    "    # print(f\"Train data shape: {train_x.shape} | Train target shape: {train_y.shape}\")\n",
    "    # print(f\"Val data shape: {val_x.shape} | Val target shape: {val_y.shape}\")\n",
    "    # print(f\"Test data shape: {test_x.shape} | Test target shape: {test_y.shape}\")\n",
    "\n",
    "    # Train model\n",
    "    for model_name, model in models.items():\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(lambda trial: objective(trial=trial, \n",
    "                                               model_type=model, \n",
    "                                               x_train=train_x, \n",
    "                                               y_train=train_y, \n",
    "                                               x_val=val_x, \n",
    "                                               y_val=val_y\n",
    "                                               ), n_trials=N_TRIALS)\n",
    "        \n",
    "        # Train model with best hyperparameters\n",
    "        best_fold_params = study.best_params\n",
    "        model = model(**best_fold_params)\n",
    "        model.fit(train_x, train_y)\n",
    "        preds = model.predict(val_x)\n",
    "\n",
    "        metrics = calculate_metrics(targets=val_y, preds=preds)\n",
    "        mae = metrics[\"mae\"]\n",
    "        mse = metrics[\"mse\"]\n",
    "        rmse = metrics[\"rmse\"]\n",
    "        pcc = metrics[\"pcc\"]\n",
    "        spearman_r = metrics[\"spearman_r\"]\n",
    "        r2_score = metrics[\"r2_score\"]\n",
    "\n",
    "        for metric in metrics:\n",
    "            model_scores[model_name][metric].append(metrics[metric])\n",
    "\n",
    "        print(f\"Fold: {fold+1}/{NUM_FOLDS}\")\n",
    "        print(f\"Model name: {model_name}\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"PCC: {pcc}\")\n",
    "        print(f\"Spearman R: {spearman_r}\")\n",
    "        print(f\"R2 Score: {r2_score}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute average scores and rank models by R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_metrics in model_scores.items():\n",
    "    for metric, scores in model_metrics.items():\n",
    "        model_scores[model_name][metric] = sum(scores) / len(scores)\n",
    "    model_scores[model_name] = dict(model_scores[model_name])\n",
    "\n",
    "model_scores = dict(sorted(model_scores.items(), key=lambda x: x[1][\"r2_score\"], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "for i, (model_name, model_metrics) in enumerate(model_scores.items()):\n",
    "    print(f\"No.{i+1} Model: {model_name}\")\n",
    "    for metric, score in model_metrics.items():\n",
    "        print(f\"{metric}: {score}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
