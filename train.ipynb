{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "from src.utils import get_kfold_data, convert_non_numeric_to_numeric, calculate_r2_score, calculate_metrics\n",
    "from src.normalisation import Normaliser\n",
    "from src.constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>...</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-26.701232</td>\n",
       "      <td>1.14</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.3</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7948</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168836</td>\n",
       "      <td>-0.273758</td>\n",
       "      <td>1.107832</td>\n",
       "      <td>1.247795</td>\n",
       "      <td>0.482344</td>\n",
       "      <td>0.489511</td>\n",
       "      <td>-0.321138</td>\n",
       "      <td>0.573382</td>\n",
       "      <td>0.446871</td>\n",
       "      <td>-1.990581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.548093</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>60.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>898</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.66</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256549</td>\n",
       "      <td>0.315373</td>\n",
       "      <td>-0.030326</td>\n",
       "      <td>-0.114335</td>\n",
       "      <td>-1.059588</td>\n",
       "      <td>-1.761360</td>\n",
       "      <td>-1.343951</td>\n",
       "      <td>-1.002550</td>\n",
       "      <td>-0.225030</td>\n",
       "      <td>-0.446653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.612562</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1351</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.193327</td>\n",
       "      <td>-0.657307</td>\n",
       "      <td>-0.591726</td>\n",
       "      <td>-0.446856</td>\n",
       "      <td>-0.765286</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>-1.397794</td>\n",
       "      <td>-0.477130</td>\n",
       "      <td>0.810509</td>\n",
       "      <td>1.725131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.073562</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2512</td>\n",
       "      <td>5.74</td>\n",
       "      <td>5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.740788</td>\n",
       "      <td>-1.778860</td>\n",
       "      <td>-0.825070</td>\n",
       "      <td>0.444932</td>\n",
       "      <td>1.173109</td>\n",
       "      <td>0.453606</td>\n",
       "      <td>-0.263440</td>\n",
       "      <td>0.246210</td>\n",
       "      <td>-0.850503</td>\n",
       "      <td>-0.412950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.436557</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2751</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859322</td>\n",
       "      <td>1.409268</td>\n",
       "      <td>0.861992</td>\n",
       "      <td>1.109063</td>\n",
       "      <td>-1.436722</td>\n",
       "      <td>-1.461618</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.258087</td>\n",
       "      <td>0.851146</td>\n",
       "      <td>2.204813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     outcome  carat        cut color clarity  depth  table  price     x     y  \\\n",
       "0 -26.701232   1.14      Ideal     G     VS1   62.3   56.0   7948  6.73  6.70   \n",
       "1   6.548093   0.38    Premium     H     VS2   60.5   59.0    898  4.69  4.66   \n",
       "2   6.612562   0.50  Very Good     E     SI1   60.7   58.0   1351  5.09  5.13   \n",
       "3  -5.073562   0.70    Premium     D     SI1   61.2   58.0   2512  5.74  5.70   \n",
       "4 -14.436557   0.83      Ideal     G     SI2   62.4   54.0   2751  6.01  6.08   \n",
       "\n",
       "   ...        a6        a7        a8        a9       a10        b6        b7  \\\n",
       "0  ...  0.168836 -0.273758  1.107832  1.247795  0.482344  0.489511 -0.321138   \n",
       "1  ... -0.256549  0.315373 -0.030326 -0.114335 -1.059588 -1.761360 -1.343951   \n",
       "2  ... -1.193327 -0.657307 -0.591726 -0.446856 -0.765286 -0.816544 -1.397794   \n",
       "3  ... -1.740788 -1.778860 -0.825070  0.444932  1.173109  0.453606 -0.263440   \n",
       "4  ... -0.859322  1.409268  0.861992  1.109063 -1.436722 -1.461618  0.081787   \n",
       "\n",
       "         b8        b9       b10  \n",
       "0  0.573382  0.446871 -1.990581  \n",
       "1 -1.002550 -0.225030 -0.446653  \n",
       "2 -0.477130  0.810509  1.725131  \n",
       "3  0.246210 -0.850503 -0.412950  \n",
       "4  0.258087  0.851146  2.204813  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['outcome', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z', 'a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5', 'a6', 'a7', 'a8', 'a9', 'a10', 'b6', 'b7', 'b8', 'b9', 'b10']\n",
      "['carat', 'depth', 'table', 'price', 'x', 'y', 'z', 'a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5', 'a6', 'a7', 'a8', 'a9', 'a10', 'b6', 'b7', 'b8', 'b9', 'b10']\n",
      "['cut', 'color', 'clarity']\n"
     ]
    }
   ],
   "source": [
    "# Find columns\n",
    "all_columns = data.columns.tolist()\n",
    "print(all_columns)\n",
    "\n",
    "numeric_columns = data.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "numeric_columns.remove(\"outcome\") # Remove the target column\n",
    "print(numeric_columns)\n",
    "\n",
    "non_numeric_columns = data.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "print(non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut\n",
      "Ideal        4040\n",
      "Premium      2439\n",
      "Very Good    2296\n",
      "Good          925\n",
      "Fair          300\n",
      "Name: count, dtype: int64\n",
      "color\n",
      "G    2120\n",
      "E    1873\n",
      "F    1746\n",
      "H    1506\n",
      "D    1246\n",
      "I     983\n",
      "J     526\n",
      "Name: count, dtype: int64\n",
      "clarity\n",
      "SI1     2408\n",
      "VS2     2256\n",
      "SI2     1743\n",
      "VS1     1503\n",
      "VVS2     951\n",
      "VVS1     675\n",
      "IF       318\n",
      "I1       146\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for non_numeric_column in non_numeric_columns:\n",
    "    print(data[non_numeric_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting non-numeric features to numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'E', 'F', 'H', 'D', 'I', 'J']\n",
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n",
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "data = convert_non_numeric_to_numeric(data=data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise data using each columns respective mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.14\n",
      "1       0.38\n",
      "2       0.50\n",
      "3       0.70\n",
      "4       0.83\n",
      "        ... \n",
      "9995    0.33\n",
      "9996    1.01\n",
      "9997    0.52\n",
      "9998    0.31\n",
      "9999    0.37\n",
      "Name: carat, Length: 10000, dtype: float64\n",
      "after 0       0.723643\n",
      "1      -0.886369\n",
      "2      -0.632156\n",
      "3      -0.208469\n",
      "4       0.066928\n",
      "          ...   \n",
      "9995   -0.992290\n",
      "9996    0.448246\n",
      "9997   -0.589788\n",
      "9998   -1.034659\n",
      "9999   -0.907553\n",
      "Name: carat, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "normaliser = Normaliser()\n",
    "for column in numeric_columns:\n",
    "    print(data[column])\n",
    "    data[column] = normaliser.standardise(data[column])\n",
    "    print(\"after\", data[column])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome     carat  cut  clarity  depth  table  price     x     y  \\\n",
      "0    -26.701232  0.723643    0        3   62.3   56.0   7948  6.73  6.70   \n",
      "1      6.548093 -0.886369    1        4   60.5   59.0    898  4.69  4.66   \n",
      "2      6.612562 -0.632156    2        5   60.7   58.0   1351  5.09  5.13   \n",
      "3     -5.073562 -0.208469    1        5   61.2   58.0   2512  5.74  5.70   \n",
      "4    -14.436557  0.066928    0        6   62.4   54.0   2751  6.01  6.08   \n",
      "...         ...       ...  ...      ...    ...    ...    ...   ...   ...   \n",
      "9995  10.718277 -0.992290    0        3   62.6   57.0   1002  4.42  4.40   \n",
      "9996 -12.246698  0.448246    4        5   69.5   55.0   4853  6.00  5.94   \n",
      "9997  11.122516 -0.589788    2        6   57.9   61.0   1273  5.28  5.33   \n",
      "9998 -24.730782 -1.034659    0        0   62.0   54.0    801  4.35  4.39   \n",
      "9999   8.735755 -0.907553    2        5   59.9   59.0    649  4.68  4.70   \n",
      "\n",
      "         z  ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     4.18  ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     2.83  ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     3.10  ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     3.50  ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     3.77  ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...    ...  ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  2.76  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  4.15  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  3.07  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  2.71  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  2.81  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 1/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 2/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 3/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 4/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold_data = get_kfold_data(data=data, k=NUM_FOLDS, reproducibility_seed=REPRODUCIBILITY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_HYPERPARAMETERS = {}\n",
    "def objective(model_type, trial, x_train, y_train, x_val, y_val):\n",
    "    parameters = {\n",
    "                \"objective\": \"regression\",\n",
    "                \"metric\": \"rmse\",\n",
    "                \"n_estimators\": 100,\n",
    "                \"verbosity\": -1,\n",
    "                \"bagging_freq\": 1,\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "                \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "                \"seed\": REPRODUCIBILITY_SEED\n",
    "    }\n",
    "    model = model_type(**parameters) # Create the model\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_val)\n",
    "    metrics = calculate_metrics(targets=y_val, preds=predictions)\n",
    "    rmse = metrics[\"rmse\"]\n",
    "    return rmse\n",
    "\n",
    "models = {\n",
    "        # \"linear_regression\": LinearRegression(),\n",
    "        # \"xgb\": xgb.XGBRegressor(**HYPERPARAMETERS),\n",
    "        # \"random_forest\": RandomForestRegressor(**HYPERPARAMETERS_2),\n",
    "        # \"gradient_boosting\": GradientBoostingRegressor(**HYPERPARAMETERS_2),\n",
    "        # \"ada_boost\": AdaBoostRegressor(),\n",
    "        # \"ridge\": Ridge(),\n",
    "        # \"lasso\": Lasso(),\n",
    "        \"lgbm\": lgb.LGBMRegressor\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:21:05,607] A new study created in memory with name: no-name-6176972c-5041-4f4d-b3f0-0514b657d7e3\n",
      "[I 2025-02-15 17:21:06,123] Trial 0 finished with value: 10.18700823953429 and parameters: {'learning_rate': 0.010189995331802646, 'num_leaves': 391, 'subsample': 0.5892217846230112, 'colsample_bytree': 0.9559705783330241, 'min_data_in_leaf': 9}. Best is trial 0 with value: 10.18700823953429.\n",
      "[I 2025-02-15 17:21:06,216] Trial 1 finished with value: 10.746510496106202 and parameters: {'learning_rate': 0.009671618757552724, 'num_leaves': 422, 'subsample': 0.24239284176361803, 'colsample_bytree': 0.5692963443366592, 'min_data_in_leaf': 25}. Best is trial 0 with value: 10.18700823953429.\n",
      "[I 2025-02-15 17:21:07,401] Trial 2 finished with value: 11.577166473093701 and parameters: {'learning_rate': 0.004528753361754807, 'num_leaves': 749, 'subsample': 0.9907126354739891, 'colsample_bytree': 0.644209399646421, 'min_data_in_leaf': 5}. Best is trial 0 with value: 10.18700823953429.\n",
      "[I 2025-02-15 17:21:07,517] Trial 3 finished with value: 9.656720329155162 and parameters: {'learning_rate': 0.06524414074325431, 'num_leaves': 65, 'subsample': 0.8245989104607433, 'colsample_bytree': 0.5295446277976107, 'min_data_in_leaf': 8}. Best is trial 3 with value: 9.656720329155162.\n",
      "[I 2025-02-15 17:21:07,593] Trial 4 finished with value: 12.081893270877975 and parameters: {'learning_rate': 0.0022139778989841634, 'num_leaves': 998, 'subsample': 0.1874555468375857, 'colsample_bytree': 0.8577785371791381, 'min_data_in_leaf': 48}. Best is trial 3 with value: 9.656720329155162.\n",
      "[I 2025-02-15 17:21:07,646] Trial 5 finished with value: 9.694827118074569 and parameters: {'learning_rate': 0.04880112070696896, 'num_leaves': 779, 'subsample': 0.1679543392692771, 'colsample_bytree': 0.337181097796178, 'min_data_in_leaf': 71}. Best is trial 3 with value: 9.656720329155162.\n",
      "[I 2025-02-15 17:21:07,741] Trial 6 finished with value: 12.930158519166923 and parameters: {'learning_rate': 0.0017675709089914025, 'num_leaves': 448, 'subsample': 0.7581439685476713, 'colsample_bytree': 0.07114021991816324, 'min_data_in_leaf': 61}. Best is trial 3 with value: 9.656720329155162.\n",
      "[I 2025-02-15 17:21:08,156] Trial 7 finished with value: 10.932476080606564 and parameters: {'learning_rate': 0.04078883011339946, 'num_leaves': 930, 'subsample': 0.7398971868796829, 'colsample_bytree': 0.21417629262955795, 'min_data_in_leaf': 13}. Best is trial 3 with value: 9.656720329155162.\n",
      "[I 2025-02-15 17:21:08,485] Trial 8 finished with value: 12.780719546913021 and parameters: {'learning_rate': 0.002719782520217097, 'num_leaves': 678, 'subsample': 0.7248241373429981, 'colsample_bytree': 0.16557403387154446, 'min_data_in_leaf': 15}. Best is trial 3 with value: 9.656720329155162.\n",
      "[I 2025-02-15 17:21:08,540] Trial 9 finished with value: 12.713171321589696 and parameters: {'learning_rate': 0.0011841179658693497, 'num_leaves': 434, 'subsample': 0.1768534240696814, 'colsample_bytree': 0.4384960335421899, 'min_data_in_leaf': 56}. Best is trial 3 with value: 9.656720329155162.\n",
      "[I 2025-02-15 17:21:08,614] Trial 10 finished with value: 9.550055630461312 and parameters: {'learning_rate': 0.08521394983858793, 'num_leaves': 24, 'subsample': 0.9970357739170566, 'colsample_bytree': 0.7422264172729842, 'min_data_in_leaf': 94}. Best is trial 10 with value: 9.550055630461312.\n",
      "[I 2025-02-15 17:21:08,650] Trial 11 finished with value: 9.507433685987964 and parameters: {'learning_rate': 0.07721096242468686, 'num_leaves': 4, 'subsample': 0.9833914459626628, 'colsample_bytree': 0.7504634054947269, 'min_data_in_leaf': 96}. Best is trial 11 with value: 9.507433685987964.\n",
      "[I 2025-02-15 17:21:08,715] Trial 12 finished with value: 9.544388942516058 and parameters: {'learning_rate': 0.09765764406530959, 'num_leaves': 23, 'subsample': 0.9600921594263506, 'colsample_bytree': 0.7448394347959097, 'min_data_in_leaf': 97}. Best is trial 11 with value: 9.507433685987964.\n",
      "[I 2025-02-15 17:21:08,781] Trial 13 finished with value: 9.570444133819924 and parameters: {'learning_rate': 0.028306307505030576, 'num_leaves': 219, 'subsample': 0.4272734582404144, 'colsample_bytree': 0.7587999338325484, 'min_data_in_leaf': 99}. Best is trial 11 with value: 9.507433685987964.\n",
      "[I 2025-02-15 17:21:08,887] Trial 14 finished with value: 9.608967254423762 and parameters: {'learning_rate': 0.02093593806651237, 'num_leaves': 197, 'subsample': 0.8831602173044026, 'colsample_bytree': 0.9527347846321337, 'min_data_in_leaf': 81}. Best is trial 11 with value: 9.507433685987964.\n",
      "[I 2025-02-15 17:21:08,973] Trial 15 finished with value: 9.540981849519534 and parameters: {'learning_rate': 0.08634071693123287, 'num_leaves': 242, 'subsample': 0.5860533417185907, 'colsample_bytree': 0.7123916246399536, 'min_data_in_leaf': 84}. Best is trial 11 with value: 9.507433685987964.\n",
      "[I 2025-02-15 17:21:09,038] Trial 16 finished with value: 9.952326882490699 and parameters: {'learning_rate': 0.016919996079606894, 'num_leaves': 220, 'subsample': 0.42974695853949657, 'colsample_bytree': 0.6317208162911501, 'min_data_in_leaf': 81}. Best is trial 11 with value: 9.507433685987964.\n",
      "[I 2025-02-15 17:21:09,124] Trial 17 finished with value: 9.505105250543089 and parameters: {'learning_rate': 0.03906339883235951, 'num_leaves': 300, 'subsample': 0.5788825942235735, 'colsample_bytree': 0.8446518768026151, 'min_data_in_leaf': 83}. Best is trial 17 with value: 9.505105250543089.\n",
      "[I 2025-02-15 17:21:09,229] Trial 18 finished with value: 9.58687679064208 and parameters: {'learning_rate': 0.037657037500935665, 'num_leaves': 578, 'subsample': 0.3171704785707382, 'colsample_bytree': 0.8303354570241137, 'min_data_in_leaf': 34}. Best is trial 17 with value: 9.505105250543089.\n",
      "[I 2025-02-15 17:21:09,279] Trial 19 finished with value: 10.231505377975797 and parameters: {'learning_rate': 0.013600374365459484, 'num_leaves': 310, 'subsample': 0.08007118660242474, 'colsample_bytree': 0.8730017886910023, 'min_data_in_leaf': 71}. Best is trial 17 with value: 9.505105250543089.\n",
      "[I 2025-02-15 17:21:09,395] Trial 20 finished with value: 9.630325429524271 and parameters: {'learning_rate': 0.05576586368821131, 'num_leaves': 151, 'subsample': 0.6350806319994251, 'colsample_bytree': 0.45448135028474296, 'min_data_in_leaf': 43}. Best is trial 17 with value: 9.505105250543089.\n",
      "[I 2025-02-15 17:21:09,468] Trial 21 finished with value: 9.590021729263228 and parameters: {'learning_rate': 0.09707831522169322, 'num_leaves': 310, 'subsample': 0.48188963300367954, 'colsample_bytree': 0.7012860025011934, 'min_data_in_leaf': 86}. Best is trial 17 with value: 9.505105250543089.\n",
      "[I 2025-02-15 17:21:09,560] Trial 22 finished with value: 9.495940051796596 and parameters: {'learning_rate': 0.033406553061261446, 'num_leaves': 122, 'subsample': 0.5979806459357466, 'colsample_bytree': 0.8390499394146742, 'min_data_in_leaf': 68}. Best is trial 22 with value: 9.495940051796596.\n",
      "[I 2025-02-15 17:21:09,649] Trial 23 finished with value: 9.531774389877064 and parameters: {'learning_rate': 0.028968446498902768, 'num_leaves': 118, 'subsample': 0.66740276958188, 'colsample_bytree': 0.8416627829863925, 'min_data_in_leaf': 69}. Best is trial 22 with value: 9.495940051796596.\n",
      "[I 2025-02-15 17:21:09,723] Trial 24 finished with value: 9.524013401472555 and parameters: {'learning_rate': 0.029822311589557837, 'num_leaves': 128, 'subsample': 0.5418341172677277, 'colsample_bytree': 0.9803533718539734, 'min_data_in_leaf': 90}. Best is trial 22 with value: 9.495940051796596.\n",
      "[I 2025-02-15 17:21:09,785] Trial 25 finished with value: 10.733680365957975 and parameters: {'learning_rate': 0.006895504276044136, 'num_leaves': 320, 'subsample': 0.3512483566676233, 'colsample_bytree': 0.9037980175231464, 'min_data_in_leaf': 77}. Best is trial 22 with value: 9.495940051796596.\n",
      "[I 2025-02-15 17:21:09,899] Trial 26 finished with value: 9.581643102392 and parameters: {'learning_rate': 0.059715351058926606, 'num_leaves': 101, 'subsample': 0.8325951415857229, 'colsample_bytree': 0.803144667078412, 'min_data_in_leaf': 63}. Best is trial 22 with value: 9.495940051796596.\n",
      "[I 2025-02-15 17:21:10,006] Trial 27 finished with value: 9.907773476206009 and parameters: {'learning_rate': 0.01711476949401281, 'num_leaves': 544, 'subsample': 0.903465055444445, 'colsample_bytree': 0.6567400388973511, 'min_data_in_leaf': 91}. Best is trial 22 with value: 9.495940051796596.\n",
      "[I 2025-02-15 17:21:10,077] Trial 28 finished with value: 9.552656450788616 and parameters: {'learning_rate': 0.023244598689414205, 'num_leaves': 30, 'subsample': 0.4991260842226623, 'colsample_bytree': 0.9974827332493829, 'min_data_in_leaf': 76}. Best is trial 22 with value: 9.495940051796596.\n",
      "[I 2025-02-15 17:21:10,184] Trial 29 finished with value: 9.500837220394343 and parameters: {'learning_rate': 0.03925181123065567, 'num_leaves': 322, 'subsample': 0.6561912620125774, 'colsample_bytree': 0.9125744784199137, 'min_data_in_leaf': 63}. Best is trial 22 with value: 9.495940051796596.\n",
      "[I 2025-02-15 17:21:10,291] A new study created in memory with name: no-name-e5d792a8-e569-4a2b-bf14-a8c38d49e920\n",
      "[I 2025-02-15 17:21:10,370] Trial 0 finished with value: 12.541645907507574 and parameters: {'learning_rate': 0.0011082313253225249, 'num_leaves': 543, 'subsample': 0.782995813919734, 'colsample_bytree': 0.15489908515324857, 'min_data_in_leaf': 87}. Best is trial 0 with value: 12.541645907507574.\n",
      "[I 2025-02-15 17:21:10,434] Trial 1 finished with value: 9.500092824301982 and parameters: {'learning_rate': 0.08529264213569007, 'num_leaves': 544, 'subsample': 0.35664372156638074, 'colsample_bytree': 0.4017755342537987, 'min_data_in_leaf': 68}. Best is trial 1 with value: 9.500092824301982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1/5\n",
      "Model name: lgbm\n",
      "MAE: 7.615133125852176\n",
      "MSE: 92.37879532204774\n",
      "RMSE: 9.611388834192889\n",
      "PCC: 0.6766691231773101\n",
      "Spearman R: 0.6832468479479876\n",
      "R2 Score: 0.45557107085332715\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:21:10,513] Trial 2 finished with value: 11.497248762697764 and parameters: {'learning_rate': 0.002551398505941641, 'num_leaves': 469, 'subsample': 0.47059037983252866, 'colsample_bytree': 0.9586585260576883, 'min_data_in_leaf': 64}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:10,563] Trial 3 finished with value: 12.24611536414159 and parameters: {'learning_rate': 0.001716379565192663, 'num_leaves': 904, 'subsample': 0.0946895503438889, 'colsample_bytree': 0.4279193240556114, 'min_data_in_leaf': 95}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:10,773] Trial 4 finished with value: 9.558030393714436 and parameters: {'learning_rate': 0.025027135255399145, 'num_leaves': 970, 'subsample': 0.18571071394348676, 'colsample_bytree': 0.6839745562364398, 'min_data_in_leaf': 8}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:10,856] Trial 5 finished with value: 11.294305395185969 and parameters: {'learning_rate': 0.012025773484940574, 'num_leaves': 50, 'subsample': 0.7583515904834535, 'colsample_bytree': 0.1848422684421583, 'min_data_in_leaf': 10}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:10,884] Trial 6 finished with value: 9.504438022939441 and parameters: {'learning_rate': 0.028265553460765522, 'num_leaves': 280, 'subsample': 0.0712446731405348, 'colsample_bytree': 0.7881782595622944, 'min_data_in_leaf': 67}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:10,935] Trial 7 finished with value: 11.370005249528466 and parameters: {'learning_rate': 0.004040917178423954, 'num_leaves': 290, 'subsample': 0.27681697895768526, 'colsample_bytree': 0.6275280064574427, 'min_data_in_leaf': 67}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:10,973] Trial 8 finished with value: 11.991058630261774 and parameters: {'learning_rate': 0.0019674012290694927, 'num_leaves': 521, 'subsample': 0.10215179546138438, 'colsample_bytree': 0.5853872140178109, 'min_data_in_leaf': 41}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:12,417] Trial 9 finished with value: 9.693632396866414 and parameters: {'learning_rate': 0.07797102251181455, 'num_leaves': 895, 'subsample': 0.9864247411558795, 'colsample_bytree': 0.8381369633990493, 'min_data_in_leaf': 5}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:12,530] Trial 10 finished with value: 9.704310897013825 and parameters: {'learning_rate': 0.09685997875326158, 'num_leaves': 725, 'subsample': 0.4243953938018667, 'colsample_bytree': 0.3361825296311495, 'min_data_in_leaf': 38}. Best is trial 1 with value: 9.500092824301982.\n",
      "[I 2025-02-15 17:21:12,586] Trial 11 finished with value: 9.355142908895134 and parameters: {'learning_rate': 0.03478823421233701, 'num_leaves': 245, 'subsample': 0.3087884346855583, 'colsample_bytree': 0.75819895298248, 'min_data_in_leaf': 72}. Best is trial 11 with value: 9.355142908895134.\n",
      "[I 2025-02-15 17:21:12,620] Trial 12 finished with value: 9.459047373675526 and parameters: {'learning_rate': 0.04606487050301524, 'num_leaves': 4, 'subsample': 0.33798843150043584, 'colsample_bytree': 0.4196021276709282, 'min_data_in_leaf': 79}. Best is trial 11 with value: 9.355142908895134.\n",
      "[I 2025-02-15 17:21:12,696] Trial 13 finished with value: 9.452512246674509 and parameters: {'learning_rate': 0.03414281532797487, 'num_leaves': 42, 'subsample': 0.6368551210410198, 'colsample_bytree': 0.49830524920805924, 'min_data_in_leaf': 84}. Best is trial 11 with value: 9.355142908895134.\n",
      "[I 2025-02-15 17:21:12,806] Trial 14 finished with value: 9.937257764107045 and parameters: {'learning_rate': 0.012377316413777154, 'num_leaves': 197, 'subsample': 0.6732775232711578, 'colsample_bytree': 0.7322071769409841, 'min_data_in_leaf': 49}. Best is trial 11 with value: 9.355142908895134.\n",
      "[I 2025-02-15 17:21:12,877] Trial 15 finished with value: 9.386049313906195 and parameters: {'learning_rate': 0.025841632242751628, 'num_leaves': 148, 'subsample': 0.5303549205530637, 'colsample_bytree': 0.9154408407063324, 'min_data_in_leaf': 83}. Best is trial 11 with value: 9.355142908895134.\n",
      "[I 2025-02-15 17:21:12,946] Trial 16 finished with value: 10.415108542049259 and parameters: {'learning_rate': 0.006694826091828157, 'num_leaves': 191, 'subsample': 0.5512469329910822, 'colsample_bytree': 0.9787368952682154, 'min_data_in_leaf': 97}. Best is trial 11 with value: 9.355142908895134.\n",
      "[I 2025-02-15 17:21:13,050] Trial 17 finished with value: 9.497030333102668 and parameters: {'learning_rate': 0.01928897013708841, 'num_leaves': 373, 'subsample': 0.5443179775162356, 'colsample_bytree': 0.8696220162312739, 'min_data_in_leaf': 55}. Best is trial 11 with value: 9.355142908895134.\n",
      "[I 2025-02-15 17:21:13,102] Trial 18 finished with value: 9.330732958629048 and parameters: {'learning_rate': 0.0499980422889491, 'num_leaves': 136, 'subsample': 0.23154491692503448, 'colsample_bytree': 0.8822857329988588, 'min_data_in_leaf': 78}. Best is trial 18 with value: 9.330732958629048.\n",
      "[I 2025-02-15 17:21:13,156] Trial 19 finished with value: 9.363583787176271 and parameters: {'learning_rate': 0.05074739851567802, 'num_leaves': 368, 'subsample': 0.20965115612487495, 'colsample_bytree': 0.7661238125617876, 'min_data_in_leaf': 75}. Best is trial 18 with value: 9.330732958629048.\n",
      "[I 2025-02-15 17:21:13,248] Trial 20 finished with value: 9.70784639744447 and parameters: {'learning_rate': 0.01710916524218344, 'num_leaves': 161, 'subsample': 0.2326684146458005, 'colsample_bytree': 0.6601754267198658, 'min_data_in_leaf': 23}. Best is trial 18 with value: 9.330732958629048.\n",
      "[I 2025-02-15 17:21:13,307] Trial 21 finished with value: 9.349784161523546 and parameters: {'learning_rate': 0.050220195392697946, 'num_leaves': 371, 'subsample': 0.19162236028981686, 'colsample_bytree': 0.8081895959010446, 'min_data_in_leaf': 74}. Best is trial 18 with value: 9.330732958629048.\n",
      "[I 2025-02-15 17:21:13,384] Trial 22 finished with value: 9.384788073375528 and parameters: {'learning_rate': 0.05277334249565615, 'num_leaves': 409, 'subsample': 0.3438339201093538, 'colsample_bytree': 0.8309525534859301, 'min_data_in_leaf': 57}. Best is trial 18 with value: 9.330732958629048.\n",
      "[I 2025-02-15 17:21:13,432] Trial 23 finished with value: 9.350776852020308 and parameters: {'learning_rate': 0.040826019582661244, 'num_leaves': 283, 'subsample': 0.16517517225799294, 'colsample_bytree': 0.9012070357989489, 'min_data_in_leaf': 74}. Best is trial 18 with value: 9.330732958629048.\n",
      "[I 2025-02-15 17:21:13,481] Trial 24 finished with value: 9.310518918698197 and parameters: {'learning_rate': 0.06158858082272398, 'num_leaves': 651, 'subsample': 0.1584075718222258, 'colsample_bytree': 0.9039044478697613, 'min_data_in_leaf': 92}. Best is trial 24 with value: 9.310518918698197.\n",
      "[I 2025-02-15 17:21:13,532] Trial 25 finished with value: 9.330746982001523 and parameters: {'learning_rate': 0.0688526141007658, 'num_leaves': 644, 'subsample': 0.1629326593082226, 'colsample_bytree': 0.9764669244736869, 'min_data_in_leaf': 90}. Best is trial 24 with value: 9.310518918698197.\n",
      "[I 2025-02-15 17:21:13,573] Trial 26 finished with value: 9.33966447239822 and parameters: {'learning_rate': 0.06936368040403841, 'num_leaves': 665, 'subsample': 0.13157158188070336, 'colsample_bytree': 0.9655055729884037, 'min_data_in_leaf': 100}. Best is trial 24 with value: 9.310518918698197.\n",
      "[I 2025-02-15 17:21:13,630] Trial 27 finished with value: 9.383057476495395 and parameters: {'learning_rate': 0.06879237357853174, 'num_leaves': 690, 'subsample': 0.2548875265314613, 'colsample_bytree': 0.9004303491831098, 'min_data_in_leaf': 90}. Best is trial 24 with value: 9.310518918698197.\n",
      "[I 2025-02-15 17:21:13,691] Trial 28 finished with value: 11.744357209646845 and parameters: {'learning_rate': 0.01974936542333954, 'num_leaves': 650, 'subsample': 0.4079659051559198, 'colsample_bytree': 0.07862021176234157, 'min_data_in_leaf': 93}. Best is trial 24 with value: 9.310518918698197.\n",
      "[I 2025-02-15 17:21:13,734] Trial 29 finished with value: 11.138279016860643 and parameters: {'learning_rate': 0.005340373859943959, 'num_leaves': 826, 'subsample': 0.05159813433361295, 'colsample_bytree': 0.9853109822669894, 'min_data_in_leaf': 87}. Best is trial 24 with value: 9.310518918698197.\n",
      "[I 2025-02-15 17:21:13,831] A new study created in memory with name: no-name-c2debf9f-49d4-4201-974d-9595ab0aad3c\n",
      "[I 2025-02-15 17:21:13,885] Trial 0 finished with value: 10.024157584459223 and parameters: {'learning_rate': 0.012799061017614377, 'num_leaves': 650, 'subsample': 0.3721649135123406, 'colsample_bytree': 0.6624929910086192, 'min_data_in_leaf': 85}. Best is trial 0 with value: 10.024157584459223.\n",
      "[I 2025-02-15 17:21:13,950] Trial 1 finished with value: 9.398637587422417 and parameters: {'learning_rate': 0.08080726933367131, 'num_leaves': 631, 'subsample': 0.40665264732708994, 'colsample_bytree': 0.9802574723025589, 'min_data_in_leaf': 66}. Best is trial 1 with value: 9.398637587422417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2/5\n",
      "Model name: lgbm\n",
      "MAE: 7.520245138462494\n",
      "MSE: 89.96175074254137\n",
      "RMSE: 9.484816853400037\n",
      "PCC: 0.6613465613191365\n",
      "Spearman R: 0.6596221346180213\n",
      "R2 Score: 0.4361361428397553\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:21:14,118] Trial 2 finished with value: 10.392323452957175 and parameters: {'learning_rate': 0.00872029754123045, 'num_leaves': 824, 'subsample': 0.6788189134697208, 'colsample_bytree': 0.7311446367166055, 'min_data_in_leaf': 39}. Best is trial 1 with value: 9.398637587422417.\n",
      "[I 2025-02-15 17:21:14,204] Trial 3 finished with value: 9.967203275919477 and parameters: {'learning_rate': 0.055842940638435305, 'num_leaves': 904, 'subsample': 0.743521495812892, 'colsample_bytree': 0.2868838598201913, 'min_data_in_leaf': 100}. Best is trial 1 with value: 9.398637587422417.\n",
      "[I 2025-02-15 17:21:14,258] Trial 4 finished with value: 11.587124880350903 and parameters: {'learning_rate': 0.014895365772439358, 'num_leaves': 435, 'subsample': 0.5011196348969157, 'colsample_bytree': 0.14793329345483386, 'min_data_in_leaf': 78}. Best is trial 1 with value: 9.398637587422417.\n",
      "[I 2025-02-15 17:21:14,313] Trial 5 finished with value: 9.474029591072805 and parameters: {'learning_rate': 0.020773371372624992, 'num_leaves': 382, 'subsample': 0.2970689770828407, 'colsample_bytree': 0.7750412812012839, 'min_data_in_leaf': 62}. Best is trial 1 with value: 9.398637587422417.\n",
      "[I 2025-02-15 17:21:14,377] Trial 6 finished with value: 9.322691034641117 and parameters: {'learning_rate': 0.036650361591984024, 'num_leaves': 304, 'subsample': 0.5917988925301032, 'colsample_bytree': 0.6522927767516429, 'min_data_in_leaf': 80}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:14,463] Trial 7 finished with value: 11.849658852024598 and parameters: {'learning_rate': 0.008088658367110823, 'num_leaves': 295, 'subsample': 0.9246281990915254, 'colsample_bytree': 0.2881199645046824, 'min_data_in_leaf': 79}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:14,557] Trial 8 finished with value: 11.400564125187122 and parameters: {'learning_rate': 0.049871619036190105, 'num_leaves': 177, 'subsample': 0.13434470203641302, 'colsample_bytree': 0.08601582215827179, 'min_data_in_leaf': 8}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:14,672] Trial 9 finished with value: 9.843978868614423 and parameters: {'learning_rate': 0.011080602815901001, 'num_leaves': 788, 'subsample': 0.8015142116221434, 'colsample_bytree': 0.9382157280439585, 'min_data_in_leaf': 63}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:14,755] Trial 10 finished with value: 12.264935642766797 and parameters: {'learning_rate': 0.0017447481615333832, 'num_leaves': 39, 'subsample': 0.6132936453375402, 'colsample_bytree': 0.48231195962081963, 'min_data_in_leaf': 35}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:14,846] Trial 11 finished with value: 9.425372019065481 and parameters: {'learning_rate': 0.0859352246970206, 'num_leaves': 596, 'subsample': 0.46195893446727665, 'colsample_bytree': 0.9381310097426315, 'min_data_in_leaf': 56}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:14,896] Trial 12 finished with value: 9.404725111490965 and parameters: {'learning_rate': 0.033302633460564536, 'num_leaves': 547, 'subsample': 0.2306047332747365, 'colsample_bytree': 0.5371228472906381, 'min_data_in_leaf': 96}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:14,980] Trial 13 finished with value: 9.360775254596017 and parameters: {'learning_rate': 0.09857544411459301, 'num_leaves': 265, 'subsample': 0.559046388504832, 'colsample_bytree': 0.9924950768458438, 'min_data_in_leaf': 71}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:15,091] Trial 14 finished with value: 11.560454113722503 and parameters: {'learning_rate': 0.003138642789908045, 'num_leaves': 180, 'subsample': 0.5856591931395063, 'colsample_bytree': 0.7927041158813554, 'min_data_in_leaf': 44}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:15,294] Trial 15 finished with value: 9.486166477947876 and parameters: {'learning_rate': 0.03136022240599771, 'num_leaves': 236, 'subsample': 0.8677047739973895, 'colsample_bytree': 0.561954515941043, 'min_data_in_leaf': 27}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:15,352] Trial 16 finished with value: 9.327669294382549 and parameters: {'learning_rate': 0.09565615632057632, 'num_leaves': 23, 'subsample': 0.9889195364960853, 'colsample_bytree': 0.3944504265398111, 'min_data_in_leaf': 73}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:15,424] Trial 17 finished with value: 9.54110088275334 and parameters: {'learning_rate': 0.03459164578502081, 'num_leaves': 37, 'subsample': 0.9955401536960684, 'colsample_bytree': 0.38165602397551446, 'min_data_in_leaf': 91}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:15,459] Trial 18 finished with value: 11.876878691654248 and parameters: {'learning_rate': 0.005336527545631, 'num_leaves': 2, 'subsample': 0.7303262625337821, 'colsample_bytree': 0.4006641722738445, 'min_data_in_leaf': 50}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:15,489] Trial 19 finished with value: 9.33735139475536 and parameters: {'learning_rate': 0.05363378547932981, 'num_leaves': 129, 'subsample': 0.09046047563173432, 'colsample_bytree': 0.6210799835614444, 'min_data_in_leaf': 76}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:15,577] Trial 20 finished with value: 10.900772018539966 and parameters: {'learning_rate': 0.02356648859033591, 'num_leaves': 477, 'subsample': 0.848995704299952, 'colsample_bytree': 0.23188346127679754, 'min_data_in_leaf': 88}. Best is trial 6 with value: 9.322691034641117.\n",
      "[I 2025-02-15 17:21:15,606] Trial 21 finished with value: 9.320043981107611 and parameters: {'learning_rate': 0.05134724941383507, 'num_leaves': 130, 'subsample': 0.07291519265559049, 'colsample_bytree': 0.6343081879604927, 'min_data_in_leaf': 75}. Best is trial 21 with value: 9.320043981107611.\n",
      "[I 2025-02-15 17:21:15,660] Trial 22 finished with value: 9.316072180243147 and parameters: {'learning_rate': 0.0579209252749718, 'num_leaves': 349, 'subsample': 0.23677805051436962, 'colsample_bytree': 0.4424238225069285, 'min_data_in_leaf': 71}. Best is trial 22 with value: 9.316072180243147.\n",
      "[I 2025-02-15 17:21:15,718] Trial 23 finished with value: 9.264046388686277 and parameters: {'learning_rate': 0.05074382959377413, 'num_leaves': 330, 'subsample': 0.1996734978875827, 'colsample_bytree': 0.6756334445313884, 'min_data_in_leaf': 56}. Best is trial 23 with value: 9.264046388686277.\n",
      "[I 2025-02-15 17:21:15,770] Trial 24 finished with value: 9.858119496129337 and parameters: {'learning_rate': 0.01970972422734824, 'num_leaves': 378, 'subsample': 0.17714363802186636, 'colsample_bytree': 0.4746219359511107, 'min_data_in_leaf': 57}. Best is trial 23 with value: 9.264046388686277.\n",
      "[I 2025-02-15 17:21:15,816] Trial 25 finished with value: 9.467010221576048 and parameters: {'learning_rate': 0.060226353401975095, 'num_leaves': 383, 'subsample': 0.05559461549287928, 'colsample_bytree': 0.5893194906373319, 'min_data_in_leaf': 25}. Best is trial 23 with value: 9.264046388686277.\n",
      "[I 2025-02-15 17:21:15,877] Trial 26 finished with value: 9.30405036245105 and parameters: {'learning_rate': 0.057046793611493174, 'num_leaves': 183, 'subsample': 0.26706760438635047, 'colsample_bytree': 0.7142752173343373, 'min_data_in_leaf': 52}. Best is trial 23 with value: 9.264046388686277.\n",
      "[I 2025-02-15 17:21:15,943] Trial 27 finished with value: 12.31015908623465 and parameters: {'learning_rate': 0.0010367684393427278, 'num_leaves': 310, 'subsample': 0.2824321685212165, 'colsample_bytree': 0.8399056404658922, 'min_data_in_leaf': 52}. Best is trial 23 with value: 9.264046388686277.\n",
      "[I 2025-02-15 17:21:16,039] Trial 28 finished with value: 9.443703771506543 and parameters: {'learning_rate': 0.06792483445426396, 'num_leaves': 503, 'subsample': 0.3195198083705564, 'colsample_bytree': 0.7133792171015417, 'min_data_in_leaf': 45}. Best is trial 23 with value: 9.264046388686277.\n",
      "[I 2025-02-15 17:21:16,127] Trial 29 finished with value: 9.585030663655026 and parameters: {'learning_rate': 0.01607897881072298, 'num_leaves': 715, 'subsample': 0.21567205479098941, 'colsample_bytree': 0.8584364763934649, 'min_data_in_leaf': 30}. Best is trial 23 with value: 9.264046388686277.\n",
      "[I 2025-02-15 17:21:16,245] A new study created in memory with name: no-name-357f0ea0-5e69-4919-ab24-639412b92199\n",
      "[I 2025-02-15 17:21:16,384] Trial 0 finished with value: 9.261296100908147 and parameters: {'learning_rate': 0.04186495801573537, 'num_leaves': 611, 'subsample': 0.9914428270858063, 'colsample_bytree': 0.7694073851501594, 'min_data_in_leaf': 57}. Best is trial 0 with value: 9.261296100908147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3/5\n",
      "Model name: lgbm\n",
      "MAE: 7.514019959218259\n",
      "MSE: 88.05133524557328\n",
      "RMSE: 9.383567298505046\n",
      "PCC: 0.6795822830295064\n",
      "Spearman R: 0.6886895766365534\n",
      "R2 Score: 0.46013378246498227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:21:16,441] Trial 1 finished with value: 9.256572940070344 and parameters: {'learning_rate': 0.026815684176390683, 'num_leaves': 116, 'subsample': 0.5076026293872129, 'colsample_bytree': 0.7044988394819608, 'min_data_in_leaf': 81}. Best is trial 1 with value: 9.256572940070344.\n",
      "[I 2025-02-15 17:21:16,475] Trial 2 finished with value: 10.445879597285524 and parameters: {'learning_rate': 0.009416969881549839, 'num_leaves': 8, 'subsample': 0.6922391971446707, 'colsample_bytree': 0.6179212173620314, 'min_data_in_leaf': 53}. Best is trial 1 with value: 9.256572940070344.\n",
      "[I 2025-02-15 17:21:16,513] Trial 3 finished with value: 12.580185363684485 and parameters: {'learning_rate': 0.0016951120262445709, 'num_leaves': 704, 'subsample': 0.15521807368110488, 'colsample_bytree': 0.1593610993874979, 'min_data_in_leaf': 66}. Best is trial 1 with value: 9.256572940070344.\n",
      "[I 2025-02-15 17:21:16,613] Trial 4 finished with value: 9.177793993523814 and parameters: {'learning_rate': 0.033313637146627155, 'num_leaves': 971, 'subsample': 0.6872601309126799, 'colsample_bytree': 0.7853091228237052, 'min_data_in_leaf': 78}. Best is trial 4 with value: 9.177793993523814.\n",
      "[I 2025-02-15 17:21:16,886] Trial 5 finished with value: 12.246208704366328 and parameters: {'learning_rate': 0.0018938056718342936, 'num_leaves': 413, 'subsample': 0.15268533168208165, 'colsample_bytree': 0.3827076044166346, 'min_data_in_leaf': 4}. Best is trial 4 with value: 9.177793993523814.\n",
      "[I 2025-02-15 17:21:16,923] Trial 6 finished with value: 11.285521669355855 and parameters: {'learning_rate': 0.004665167539757385, 'num_leaves': 275, 'subsample': 0.09472549756604656, 'colsample_bytree': 0.6072998449507965, 'min_data_in_leaf': 44}. Best is trial 4 with value: 9.177793993523814.\n",
      "[I 2025-02-15 17:21:16,948] Trial 7 finished with value: 12.474111753249087 and parameters: {'learning_rate': 0.001078802673485295, 'num_leaves': 80, 'subsample': 0.1388145093004881, 'colsample_bytree': 0.3351065140252505, 'min_data_in_leaf': 97}. Best is trial 4 with value: 9.177793993523814.\n",
      "[I 2025-02-15 17:21:17,081] Trial 8 finished with value: 9.36167606434098 and parameters: {'learning_rate': 0.07972828077167468, 'num_leaves': 323, 'subsample': 0.9885147867491914, 'colsample_bytree': 0.6592984928342004, 'min_data_in_leaf': 51}. Best is trial 4 with value: 9.177793993523814.\n",
      "[I 2025-02-15 17:21:18,825] Trial 9 finished with value: 10.085906170909318 and parameters: {'learning_rate': 0.011986591573960204, 'num_leaves': 968, 'subsample': 0.9967211765842496, 'colsample_bytree': 0.7147551138300068, 'min_data_in_leaf': 2}. Best is trial 4 with value: 9.177793993523814.\n",
      "[I 2025-02-15 17:21:19,047] Trial 10 finished with value: 9.509692766698706 and parameters: {'learning_rate': 0.09900820208849331, 'num_leaves': 1002, 'subsample': 0.6126252706483248, 'colsample_bytree': 0.995402572503427, 'min_data_in_leaf': 26}. Best is trial 4 with value: 9.177793993523814.\n",
      "[I 2025-02-15 17:21:19,119] Trial 11 finished with value: 9.217712303071075 and parameters: {'learning_rate': 0.025741487295921447, 'num_leaves': 759, 'subsample': 0.43636544168136976, 'colsample_bytree': 0.8996517409152691, 'min_data_in_leaf': 89}. Best is trial 4 with value: 9.177793993523814.\n",
      "[I 2025-02-15 17:21:19,189] Trial 12 finished with value: 9.171910655873777 and parameters: {'learning_rate': 0.025790397437325502, 'num_leaves': 798, 'subsample': 0.40462486109185236, 'colsample_bytree': 0.9466459359232451, 'min_data_in_leaf': 100}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:19,260] Trial 13 finished with value: 9.590159253422652 and parameters: {'learning_rate': 0.014077745028697857, 'num_leaves': 866, 'subsample': 0.3639545245820342, 'colsample_bytree': 0.8622544920225601, 'min_data_in_leaf': 78}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:19,358] Trial 14 finished with value: 9.203965008244106 and parameters: {'learning_rate': 0.04673151195820419, 'num_leaves': 844, 'subsample': 0.7641717199616461, 'colsample_bytree': 0.9952269279175425, 'min_data_in_leaf': 95}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:19,418] Trial 15 finished with value: 11.088177774865914 and parameters: {'learning_rate': 0.006414319480301704, 'num_leaves': 532, 'subsample': 0.32252121991089777, 'colsample_bytree': 0.49002400780659366, 'min_data_in_leaf': 73}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:19,517] Trial 16 finished with value: 9.293862930725531 and parameters: {'learning_rate': 0.022360733241311867, 'num_leaves': 857, 'subsample': 0.8678396688797365, 'colsample_bytree': 0.8383080032304151, 'min_data_in_leaf': 100}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:19,599] Trial 17 finished with value: 9.207471171422366 and parameters: {'learning_rate': 0.05480256925637165, 'num_leaves': 653, 'subsample': 0.5832789364939105, 'colsample_bytree': 0.8090595478458342, 'min_data_in_leaf': 85}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:19,666] Trial 18 finished with value: 11.811611276392998 and parameters: {'learning_rate': 0.01999901548526558, 'num_leaves': 946, 'subsample': 0.2715648621152015, 'colsample_bytree': 0.08899834238617488, 'min_data_in_leaf': 66}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:19,836] Trial 19 finished with value: 10.984632023398294 and parameters: {'learning_rate': 0.004129050676805978, 'num_leaves': 779, 'subsample': 0.7694280541414613, 'colsample_bytree': 0.9119598098593921, 'min_data_in_leaf': 38}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:19,929] Trial 20 finished with value: 9.242739343019025 and parameters: {'learning_rate': 0.036612943414594985, 'num_leaves': 1022, 'subsample': 0.490225426600043, 'colsample_bytree': 0.5377032913168742, 'min_data_in_leaf': 68}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:20,028] Trial 21 finished with value: 9.210224362119106 and parameters: {'learning_rate': 0.05551094020452263, 'num_leaves': 860, 'subsample': 0.7771107527084593, 'colsample_bytree': 0.9871424521612591, 'min_data_in_leaf': 92}. Best is trial 12 with value: 9.171910655873777.\n",
      "[I 2025-02-15 17:21:20,117] Trial 22 finished with value: 9.16295449059316 and parameters: {'learning_rate': 0.0353806855768728, 'num_leaves': 801, 'subsample': 0.657774312526716, 'colsample_bytree': 0.9429977744226482, 'min_data_in_leaf': 89}. Best is trial 22 with value: 9.16295449059316.\n",
      "[I 2025-02-15 17:21:20,207] Trial 23 finished with value: 9.439284286272889 and parameters: {'learning_rate': 0.015358576811872322, 'num_leaves': 568, 'subsample': 0.6322469492364476, 'colsample_bytree': 0.9080724556153534, 'min_data_in_leaf': 83}. Best is trial 22 with value: 9.16295449059316.\n",
      "[I 2025-02-15 17:21:20,274] Trial 24 finished with value: 9.166835576368825 and parameters: {'learning_rate': 0.03431178937396771, 'num_leaves': 735, 'subsample': 0.4285205360881615, 'colsample_bytree': 0.7734130913125024, 'min_data_in_leaf': 100}. Best is trial 22 with value: 9.16295449059316.\n",
      "[I 2025-02-15 17:21:20,342] Trial 25 finished with value: 9.201506271258177 and parameters: {'learning_rate': 0.06945176365174059, 'num_leaves': 701, 'subsample': 0.4176807440891523, 'colsample_bytree': 0.9262348803442925, 'min_data_in_leaf': 100}. Best is trial 22 with value: 9.16295449059316.\n",
      "[I 2025-02-15 17:21:20,396] Trial 26 finished with value: 10.428026736093914 and parameters: {'learning_rate': 0.008358275118224304, 'num_leaves': 771, 'subsample': 0.22746099861270752, 'colsample_bytree': 0.7141522275145525, 'min_data_in_leaf': 90}. Best is trial 22 with value: 9.16295449059316.\n",
      "[I 2025-02-15 17:21:20,466] Trial 27 finished with value: 9.499471972028038 and parameters: {'learning_rate': 0.016728526076331064, 'num_leaves': 463, 'subsample': 0.5377710475148321, 'colsample_bytree': 0.7826521583340642, 'min_data_in_leaf': 91}. Best is trial 22 with value: 9.16295449059316.\n",
      "[I 2025-02-15 17:21:20,622] Trial 28 finished with value: 9.197147600916548 and parameters: {'learning_rate': 0.030804510821302793, 'num_leaves': 646, 'subsample': 0.3942626612117516, 'colsample_bytree': 0.8582224263138569, 'min_data_in_leaf': 21}. Best is trial 22 with value: 9.16295449059316.\n",
      "[I 2025-02-15 17:21:20,720] Trial 29 finished with value: 9.174797263246953 and parameters: {'learning_rate': 0.04227992702093133, 'num_leaves': 606, 'subsample': 0.46752147231118923, 'colsample_bytree': 0.9388690775024294, 'min_data_in_leaf': 62}. Best is trial 22 with value: 9.16295449059316.\n",
      "[I 2025-02-15 17:21:20,833] A new study created in memory with name: no-name-9b19897a-4456-467c-9ea1-49175a9ac330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4/5\n",
      "Model name: lgbm\n",
      "MAE: 7.300039392402758\n",
      "MSE: 85.58068728135056\n",
      "RMSE: 9.2509830440527\n",
      "PCC: 0.6841195646092426\n",
      "Spearman R: 0.6896842088610191\n",
      "R2 Score: 0.4678201708988373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:21:21,032] Trial 0 finished with value: 9.322319834341558 and parameters: {'learning_rate': 0.03630077647479287, 'num_leaves': 803, 'subsample': 0.6784746525868471, 'colsample_bytree': 0.7365705493897426, 'min_data_in_leaf': 27}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,065] Trial 1 finished with value: 11.916840660816568 and parameters: {'learning_rate': 0.0022273472307791416, 'num_leaves': 263, 'subsample': 0.18951803581644394, 'colsample_bytree': 0.8014142491165548, 'min_data_in_leaf': 89}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,200] Trial 2 finished with value: 9.857618714886254 and parameters: {'learning_rate': 0.014849976195494849, 'num_leaves': 582, 'subsample': 0.9586413403246937, 'colsample_bytree': 0.5966498595464209, 'min_data_in_leaf': 52}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,260] Trial 3 finished with value: 12.190261289093675 and parameters: {'learning_rate': 0.0015503691281858543, 'num_leaves': 305, 'subsample': 0.474213727076102, 'colsample_bytree': 0.7008589506971521, 'min_data_in_leaf': 82}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,367] Trial 4 finished with value: 9.405442578838421 and parameters: {'learning_rate': 0.09807266851525835, 'num_leaves': 954, 'subsample': 0.9811656928794273, 'colsample_bytree': 0.35437088418750023, 'min_data_in_leaf': 79}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,457] Trial 5 finished with value: 10.73775274515872 and parameters: {'learning_rate': 0.0071939820402958125, 'num_leaves': 445, 'subsample': 0.08028942909572509, 'colsample_bytree': 0.6848334117016207, 'min_data_in_leaf': 7}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,487] Trial 6 finished with value: 10.554414056997361 and parameters: {'learning_rate': 0.009875612221776587, 'num_leaves': 719, 'subsample': 0.08293805922505734, 'colsample_bytree': 0.5761800762064968, 'min_data_in_leaf': 68}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,551] Trial 7 finished with value: 11.853436441230485 and parameters: {'learning_rate': 0.004915793948758496, 'num_leaves': 289, 'subsample': 0.17990968962552195, 'colsample_bytree': 0.31593894185317045, 'min_data_in_leaf': 22}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,809] Trial 8 finished with value: 10.254930385269434 and parameters: {'learning_rate': 0.01006528209576759, 'num_leaves': 843, 'subsample': 0.6162830210396758, 'colsample_bytree': 0.6789358236498866, 'min_data_in_leaf': 20}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:21,858] Trial 9 finished with value: 11.629951475794698 and parameters: {'learning_rate': 0.0025538756601707997, 'num_leaves': 287, 'subsample': 0.2618829011416498, 'colsample_bytree': 0.9333824552745629, 'min_data_in_leaf': 56}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:22,018] Trial 10 finished with value: 11.693271610150864 and parameters: {'learning_rate': 0.041858298251101815, 'num_leaves': 1018, 'subsample': 0.7351859621505197, 'colsample_bytree': 0.06449877053197861, 'min_data_in_leaf': 35}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:22,124] Trial 11 finished with value: 9.351137715862324 and parameters: {'learning_rate': 0.09711605623578896, 'num_leaves': 1010, 'subsample': 0.9506352759331369, 'colsample_bytree': 0.36903479005631873, 'min_data_in_leaf': 97}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:22,164] Trial 12 finished with value: 9.396663957194749 and parameters: {'learning_rate': 0.039244732019523304, 'num_leaves': 9, 'subsample': 0.8023156365351196, 'colsample_bytree': 0.40455265315423783, 'min_data_in_leaf': 36}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:22,231] Trial 13 finished with value: 9.59037403368508 and parameters: {'learning_rate': 0.09958141747792079, 'num_leaves': 786, 'subsample': 0.457621178896599, 'colsample_bytree': 0.14445637508799428, 'min_data_in_leaf': 97}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:22,406] Trial 14 finished with value: 9.468826950210115 and parameters: {'learning_rate': 0.03784095548596002, 'num_leaves': 900, 'subsample': 0.818148085157832, 'colsample_bytree': 0.4494105069980932, 'min_data_in_leaf': 38}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:23,684] Trial 15 finished with value: 9.48292855507785 and parameters: {'learning_rate': 0.02493573706878181, 'num_leaves': 678, 'subsample': 0.6637804405805607, 'colsample_bytree': 0.9897303782965756, 'min_data_in_leaf': 1}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:23,809] Trial 16 finished with value: 9.556563168618881 and parameters: {'learning_rate': 0.06300562236948609, 'num_leaves': 1009, 'subsample': 0.8981166214495861, 'colsample_bytree': 0.25089045602385296, 'min_data_in_leaf': 68}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:24,035] Trial 17 finished with value: 9.432240134552753 and parameters: {'learning_rate': 0.018751897146048257, 'num_leaves': 588, 'subsample': 0.5671251996453885, 'colsample_bytree': 0.8910659999440286, 'min_data_in_leaf': 20}. Best is trial 0 with value: 9.322319834341558.\n",
      "[I 2025-02-15 17:21:24,091] Trial 18 finished with value: 9.288305705840274 and parameters: {'learning_rate': 0.057647289185477936, 'num_leaves': 801, 'subsample': 0.34821041586819035, 'colsample_bytree': 0.4750478290975143, 'min_data_in_leaf': 99}. Best is trial 18 with value: 9.288305705840274.\n",
      "[I 2025-02-15 17:21:24,165] Trial 19 finished with value: 9.450445591252715 and parameters: {'learning_rate': 0.02872800447773052, 'num_leaves': 749, 'subsample': 0.39103209003443007, 'colsample_bytree': 0.49828902040683276, 'min_data_in_leaf': 64}. Best is trial 18 with value: 9.288305705840274.\n",
      "[I 2025-02-15 17:21:24,248] Trial 20 finished with value: 9.3523655365667 and parameters: {'learning_rate': 0.06907466744699371, 'num_leaves': 461, 'subsample': 0.3469984973249417, 'colsample_bytree': 0.7722408511213976, 'min_data_in_leaf': 44}. Best is trial 18 with value: 9.288305705840274.\n",
      "[I 2025-02-15 17:21:24,332] Trial 21 finished with value: 9.511947706225424 and parameters: {'learning_rate': 0.05997179284370845, 'num_leaves': 888, 'subsample': 0.7371772438838595, 'colsample_bytree': 0.2590762886909511, 'min_data_in_leaf': 96}. Best is trial 18 with value: 9.288305705840274.\n",
      "[I 2025-02-15 17:21:24,403] Trial 22 finished with value: 9.312757882260247 and parameters: {'learning_rate': 0.05598277346162058, 'num_leaves': 829, 'subsample': 0.35027603991661643, 'colsample_bytree': 0.5362310922395318, 'min_data_in_leaf': 81}. Best is trial 18 with value: 9.288305705840274.\n",
      "[I 2025-02-15 17:21:24,465] Trial 23 finished with value: 9.212070674298383 and parameters: {'learning_rate': 0.051103839569444705, 'num_leaves': 641, 'subsample': 0.33165764101827755, 'colsample_bytree': 0.5821532568177911, 'min_data_in_leaf': 89}. Best is trial 23 with value: 9.212070674298383.\n",
      "[I 2025-02-15 17:21:24,529] Trial 24 finished with value: 9.286912851053104 and parameters: {'learning_rate': 0.056291594381976555, 'num_leaves': 642, 'subsample': 0.3294097607976695, 'colsample_bytree': 0.5651599771826706, 'min_data_in_leaf': 79}. Best is trial 23 with value: 9.212070674298383.\n",
      "[I 2025-02-15 17:21:24,581] Trial 25 finished with value: 9.569660073337575 and parameters: {'learning_rate': 0.020232479268449996, 'num_leaves': 594, 'subsample': 0.25885658283863755, 'colsample_bytree': 0.6174286457488875, 'min_data_in_leaf': 87}. Best is trial 23 with value: 9.212070674298383.\n",
      "[I 2025-02-15 17:21:24,651] Trial 26 finished with value: 9.31764918443679 and parameters: {'learning_rate': 0.05206310421257579, 'num_leaves': 664, 'subsample': 0.28354238283031, 'colsample_bytree': 0.5139160680110882, 'min_data_in_leaf': 75}. Best is trial 23 with value: 9.212070674298383.\n",
      "[I 2025-02-15 17:21:24,725] Trial 27 finished with value: 9.552538857530331 and parameters: {'learning_rate': 0.027616826766186254, 'num_leaves': 517, 'subsample': 0.44093044197868386, 'colsample_bytree': 0.4531718103896216, 'min_data_in_leaf': 91}. Best is trial 23 with value: 9.212070674298383.\n",
      "[I 2025-02-15 17:21:24,798] Trial 28 finished with value: 9.946817519703734 and parameters: {'learning_rate': 0.013187641347942125, 'num_leaves': 390, 'subsample': 0.5338040691684287, 'colsample_bytree': 0.6251354024629423, 'min_data_in_leaf': 100}. Best is trial 23 with value: 9.212070674298383.\n",
      "[I 2025-02-15 17:21:24,847] Trial 29 finished with value: 9.367212948953268 and parameters: {'learning_rate': 0.07627704448293544, 'num_leaves': 645, 'subsample': 0.19574845742416078, 'colsample_bytree': 0.8223628707583039, 'min_data_in_leaf': 73}. Best is trial 23 with value: 9.212070674298383.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5/5\n",
      "Model name: lgbm\n",
      "MAE: 7.429355896703385\n",
      "MSE: 86.11879352370295\n",
      "RMSE: 9.280021202761498\n",
      "PCC: 0.6894866692689603\n",
      "Spearman R: 0.6916739332710677\n",
      "R2 Score: 0.47296581032884233\n",
      "\n",
      "{'lgbm': {'mae': 7.475758702527815, 'mse': 88.41827242304318, 'rmse': 9.402155446582434, 'pcc': 0.6782408402808312, 'spearman_r': 0.6825833402669299, 'r2_score': 0.4585253954771488}}\n"
     ]
    }
   ],
   "source": [
    "# Train + Validate models\n",
    "metrics = [\"mae\", \"mse\", \"rmse\", \"pcc\", \"spearman_r\", \"r2_score\"]\n",
    "model_scores = {model_name: defaultdict(list) for model_name in models.keys()}\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    fold_data = kfold_data[fold]\n",
    "     \n",
    "    # Extract data\n",
    "    train_data = fold_data[\"train\"]\n",
    "    val_data = fold_data[\"val\"]\n",
    "    test_data = kfold_data[fold][\"test\"]\n",
    "\n",
    "    train_y = train_data[\"outcome\"]\n",
    "    val_y = val_data[\"outcome\"]\n",
    "    test_y = test_data[\"outcome\"]\n",
    "\n",
    "    train_x = train_data.drop(columns=[\"outcome\"])\n",
    "    val_x = val_data.drop(columns=[\"outcome\"])\n",
    "    test_x = test_data.drop(columns=[\"outcome\"])\n",
    "\n",
    "    # print(f\"Fold {fold+1}/{NUM_FOLDS}\")\n",
    "    # print(f\"Train data shape: {train_x.shape} | Train target shape: {train_y.shape}\")\n",
    "    # print(f\"Val data shape: {val_x.shape} | Val target shape: {val_y.shape}\")\n",
    "    # print(f\"Test data shape: {test_x.shape} | Test target shape: {test_y.shape}\")\n",
    "\n",
    "    # Train model\n",
    "    for model_name, model in models.items():\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(lambda trial: objective(trial=trial, \n",
    "                                               model_type=model, \n",
    "                                               x_train=train_x, \n",
    "                                               y_train=train_y, \n",
    "                                               x_val=val_x, \n",
    "                                               y_val=val_y\n",
    "                                               ), n_trials=30)\n",
    "        \n",
    "        # Train model with best hyperparameters\n",
    "        best_fold_params = study.best_params\n",
    "        model = model(**best_fold_params)\n",
    "        model.fit(train_x, train_y)\n",
    "        preds = model.predict(val_x)\n",
    "\n",
    "        metrics = calculate_metrics(targets=val_y, preds=preds)\n",
    "        mae = metrics[\"mae\"]\n",
    "        mse = metrics[\"mse\"]\n",
    "        rmse = metrics[\"rmse\"]\n",
    "        pcc = metrics[\"pcc\"]\n",
    "        spearman_r = metrics[\"spearman_r\"]\n",
    "        r2_score = metrics[\"r2_score\"]\n",
    "\n",
    "        for metric in metrics:\n",
    "            model_scores[model_name][metric].append(metrics[metric])\n",
    "\n",
    "        print(f\"Fold: {fold+1}/{NUM_FOLDS}\")\n",
    "        print(f\"Model name: {model_name}\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"PCC: {pcc}\")\n",
    "        print(f\"Spearman R: {spearman_r}\")\n",
    "        print(f\"R2 Score: {r2_score}\")\n",
    "        print()\n",
    "\n",
    "# Compute average scores\n",
    "for model_name, model_metrics in model_scores.items():\n",
    "    for metric, scores in model_metrics.items():\n",
    "        model_scores[model_name][metric] = sum(scores) / len(scores)\n",
    "    model_scores[model_name] = dict(model_scores[model_name])\n",
    "print(model_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
