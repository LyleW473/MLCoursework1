{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wlyle\\Desktop\\DataScienceDataChallenge\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "from src.utils import get_kfold_data, convert_non_numeric_to_numeric, calculate_r2_score, calculate_metrics\n",
    "from src.normalisation import Normaliser\n",
    "from src.constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>...</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-26.701232</td>\n",
       "      <td>1.14</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.3</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7948</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168836</td>\n",
       "      <td>-0.273758</td>\n",
       "      <td>1.107832</td>\n",
       "      <td>1.247795</td>\n",
       "      <td>0.482344</td>\n",
       "      <td>0.489511</td>\n",
       "      <td>-0.321138</td>\n",
       "      <td>0.573382</td>\n",
       "      <td>0.446871</td>\n",
       "      <td>-1.990581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.548093</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>60.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>898</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.66</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256549</td>\n",
       "      <td>0.315373</td>\n",
       "      <td>-0.030326</td>\n",
       "      <td>-0.114335</td>\n",
       "      <td>-1.059588</td>\n",
       "      <td>-1.761360</td>\n",
       "      <td>-1.343951</td>\n",
       "      <td>-1.002550</td>\n",
       "      <td>-0.225030</td>\n",
       "      <td>-0.446653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.612562</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1351</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.193327</td>\n",
       "      <td>-0.657307</td>\n",
       "      <td>-0.591726</td>\n",
       "      <td>-0.446856</td>\n",
       "      <td>-0.765286</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>-1.397794</td>\n",
       "      <td>-0.477130</td>\n",
       "      <td>0.810509</td>\n",
       "      <td>1.725131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.073562</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2512</td>\n",
       "      <td>5.74</td>\n",
       "      <td>5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.740788</td>\n",
       "      <td>-1.778860</td>\n",
       "      <td>-0.825070</td>\n",
       "      <td>0.444932</td>\n",
       "      <td>1.173109</td>\n",
       "      <td>0.453606</td>\n",
       "      <td>-0.263440</td>\n",
       "      <td>0.246210</td>\n",
       "      <td>-0.850503</td>\n",
       "      <td>-0.412950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.436557</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2751</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859322</td>\n",
       "      <td>1.409268</td>\n",
       "      <td>0.861992</td>\n",
       "      <td>1.109063</td>\n",
       "      <td>-1.436722</td>\n",
       "      <td>-1.461618</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.258087</td>\n",
       "      <td>0.851146</td>\n",
       "      <td>2.204813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     outcome  carat        cut color clarity  depth  table  price     x     y  \\\n",
       "0 -26.701232   1.14      Ideal     G     VS1   62.3   56.0   7948  6.73  6.70   \n",
       "1   6.548093   0.38    Premium     H     VS2   60.5   59.0    898  4.69  4.66   \n",
       "2   6.612562   0.50  Very Good     E     SI1   60.7   58.0   1351  5.09  5.13   \n",
       "3  -5.073562   0.70    Premium     D     SI1   61.2   58.0   2512  5.74  5.70   \n",
       "4 -14.436557   0.83      Ideal     G     SI2   62.4   54.0   2751  6.01  6.08   \n",
       "\n",
       "   ...        a6        a7        a8        a9       a10        b6        b7  \\\n",
       "0  ...  0.168836 -0.273758  1.107832  1.247795  0.482344  0.489511 -0.321138   \n",
       "1  ... -0.256549  0.315373 -0.030326 -0.114335 -1.059588 -1.761360 -1.343951   \n",
       "2  ... -1.193327 -0.657307 -0.591726 -0.446856 -0.765286 -0.816544 -1.397794   \n",
       "3  ... -1.740788 -1.778860 -0.825070  0.444932  1.173109  0.453606 -0.263440   \n",
       "4  ... -0.859322  1.409268  0.861992  1.109063 -1.436722 -1.461618  0.081787   \n",
       "\n",
       "         b8        b9       b10  \n",
       "0  0.573382  0.446871 -1.990581  \n",
       "1 -1.002550 -0.225030 -0.446653  \n",
       "2 -0.477130  0.810509  1.725131  \n",
       "3  0.246210 -0.850503 -0.412950  \n",
       "4  0.258087  0.851146  2.204813  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['outcome', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z', 'a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5', 'a6', 'a7', 'a8', 'a9', 'a10', 'b6', 'b7', 'b8', 'b9', 'b10']\n",
      "['carat', 'depth', 'table', 'price', 'x', 'y', 'z', 'a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5', 'a6', 'a7', 'a8', 'a9', 'a10', 'b6', 'b7', 'b8', 'b9', 'b10']\n",
      "['cut', 'color', 'clarity']\n"
     ]
    }
   ],
   "source": [
    "# Find columns\n",
    "all_columns = data.columns.tolist()\n",
    "print(all_columns)\n",
    "\n",
    "numeric_columns = data.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "numeric_columns.remove(\"outcome\") # Remove the target column\n",
    "print(numeric_columns)\n",
    "\n",
    "non_numeric_columns = data.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "print(non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut\n",
      "Ideal        4040\n",
      "Premium      2439\n",
      "Very Good    2296\n",
      "Good          925\n",
      "Fair          300\n",
      "Name: count, dtype: int64\n",
      "color\n",
      "G    2120\n",
      "E    1873\n",
      "F    1746\n",
      "H    1506\n",
      "D    1246\n",
      "I     983\n",
      "J     526\n",
      "Name: count, dtype: int64\n",
      "clarity\n",
      "SI1     2408\n",
      "VS2     2256\n",
      "SI2     1743\n",
      "VS1     1503\n",
      "VVS2     951\n",
      "VVS1     675\n",
      "IF       318\n",
      "I1       146\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for non_numeric_column in non_numeric_columns:\n",
    "    print(data[non_numeric_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting non-numeric features to numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'E', 'F', 'H', 'D', 'I', 'J']\n",
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n",
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "data = convert_non_numeric_to_numeric(data=data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise data using each columns respective mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome  carat  cut  clarity  depth  table  price     x     y     z  \\\n",
      "0    -26.701232   1.14    0        3   62.3   56.0   7948  6.73  6.70  4.18   \n",
      "1      6.548093   0.38    1        4   60.5   59.0    898  4.69  4.66  2.83   \n",
      "2      6.612562   0.50    2        5   60.7   58.0   1351  5.09  5.13  3.10   \n",
      "3     -5.073562   0.70    1        5   61.2   58.0   2512  5.74  5.70  3.50   \n",
      "4    -14.436557   0.83    0        6   62.4   54.0   2751  6.01  6.08  3.77   \n",
      "...         ...    ...  ...      ...    ...    ...    ...   ...   ...   ...   \n",
      "9995  10.718277   0.33    0        3   62.6   57.0   1002  4.42  4.40  2.76   \n",
      "9996 -12.246698   1.01    4        5   69.5   55.0   4853  6.00  5.94  4.15   \n",
      "9997  11.122516   0.52    2        6   57.9   61.0   1273  5.28  5.33  3.07   \n",
      "9998 -24.730782   0.31    0        0   62.0   54.0    801  4.35  4.39  2.71   \n",
      "9999   8.735755   0.37    2        5   59.9   59.0    649  4.68  4.70  2.81   \n",
      "\n",
      "      ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.14\n",
      "1       0.38\n",
      "2       0.50\n",
      "3       0.70\n",
      "4       0.83\n",
      "        ... \n",
      "9995    0.33\n",
      "9996    1.01\n",
      "9997    0.52\n",
      "9998    0.31\n",
      "9999    0.37\n",
      "Name: carat, Length: 10000, dtype: float64\n",
      "after 0       0.723643\n",
      "1      -0.886369\n",
      "2      -0.632156\n",
      "3      -0.208469\n",
      "4       0.066928\n",
      "          ...   \n",
      "9995   -0.992290\n",
      "9996    0.448246\n",
      "9997   -0.589788\n",
      "9998   -1.034659\n",
      "9999   -0.907553\n",
      "Name: carat, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "normaliser = Normaliser()\n",
    "for column in numeric_columns:\n",
    "    print(data[column])\n",
    "    data[column] = normaliser.standardise(data[column])\n",
    "    print(\"after\", data[column])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome     carat  cut  clarity  depth  table  price     x     y  \\\n",
      "0    -26.701232  0.723643    0        3   62.3   56.0   7948  6.73  6.70   \n",
      "1      6.548093 -0.886369    1        4   60.5   59.0    898  4.69  4.66   \n",
      "2      6.612562 -0.632156    2        5   60.7   58.0   1351  5.09  5.13   \n",
      "3     -5.073562 -0.208469    1        5   61.2   58.0   2512  5.74  5.70   \n",
      "4    -14.436557  0.066928    0        6   62.4   54.0   2751  6.01  6.08   \n",
      "...         ...       ...  ...      ...    ...    ...    ...   ...   ...   \n",
      "9995  10.718277 -0.992290    0        3   62.6   57.0   1002  4.42  4.40   \n",
      "9996 -12.246698  0.448246    4        5   69.5   55.0   4853  6.00  5.94   \n",
      "9997  11.122516 -0.589788    2        6   57.9   61.0   1273  5.28  5.33   \n",
      "9998 -24.730782 -1.034659    0        0   62.0   54.0    801  4.35  4.39   \n",
      "9999   8.735755 -0.907553    2        5   59.9   59.0    649  4.68  4.70   \n",
      "\n",
      "         z  ...        b8        b9       b10  colour_G  colour_E  colour_F  \\\n",
      "0     4.18  ...  0.573382  0.446871 -1.990581         1         0         0   \n",
      "1     2.83  ... -1.002550 -0.225030 -0.446653         0         0         0   \n",
      "2     3.10  ... -0.477130  0.810509  1.725131         0         1         0   \n",
      "3     3.50  ...  0.246210 -0.850503 -0.412950         0         0         0   \n",
      "4     3.77  ...  0.258087  0.851146  2.204813         1         0         0   \n",
      "...    ...  ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  2.76  ... -1.981229 -0.805800  1.051560         0         1         0   \n",
      "9996  4.15  ...  0.114660  0.856687  0.923238         0         1         0   \n",
      "9997  3.07  ...  1.022618  1.193452 -0.035714         0         0         1   \n",
      "9998  2.71  ... -0.713252  0.133960 -1.547468         1         0         0   \n",
      "9999  2.81  ... -0.201825 -0.484968  0.065408         0         1         0   \n",
      "\n",
      "      colour_H  colour_D  colour_I  colour_J  \n",
      "0            0         0         0         0  \n",
      "1            1         0         0         0  \n",
      "2            0         0         0         0  \n",
      "3            0         1         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         0         0         0         0  \n",
      "9996         0         0         0         0  \n",
      "9997         0         0         0         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 1/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 2/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 3/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n",
      "Fold: 4/5\n",
      "Train shape: (6400, 37) | 64.00%\n",
      "Validation shape: (1600, 37) | 16.00%\n",
      "Test shape: (2000, 37) | 20.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold_data = get_kfold_data(data=data, k=NUM_FOLDS, reproducibility_seed=REPRODUCIBILITY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_HYPERPARAMETERS = {}\n",
    "def objective(model_type, trial, x_train, y_train, x_val, y_val):\n",
    "    parameters = {\n",
    "                \"objective\": \"regression\",\n",
    "                \"metric\": \"rmse\",\n",
    "                \"n_estimators\": 100,\n",
    "                \"verbosity\": -1,\n",
    "                \"bagging_freq\": 1,\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "                \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "                \"seed\": REPRODUCIBILITY_SEED\n",
    "    }\n",
    "    model = model_type(**parameters) # Create the model\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_val)\n",
    "    metrics = calculate_metrics(targets=y_val, preds=predictions)\n",
    "    rmse = metrics[\"rmse\"]\n",
    "    return rmse\n",
    "\n",
    "models = {\n",
    "        # \"linear_regression\": LinearRegression(),\n",
    "        # \"xgb\": xgb.XGBRegressor(**HYPERPARAMETERS),\n",
    "        # \"random_forest\": RandomForestRegressor(**HYPERPARAMETERS_2),\n",
    "        # \"gradient_boosting\": GradientBoostingRegressor(**HYPERPARAMETERS_2),\n",
    "        # \"ada_boost\": AdaBoostRegressor(),\n",
    "        # \"ridge\": Ridge(),\n",
    "        # \"lasso\": Lasso(),\n",
    "        \"lgbm\": lgb.LGBMRegressor\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:16:45,260] A new study created in memory with name: no-name-57748008-9dd0-47c2-9d70-6287b61d686b\n",
      "[I 2025-02-15 17:16:45,472] Trial 0 finished with value: 9.66091751248437 and parameters: {'learning_rate': 0.04837879783536925, 'num_leaves': 95, 'subsample': 0.6533217483563118, 'colsample_bytree': 0.5450235211296038, 'min_data_in_leaf': 20}. Best is trial 0 with value: 9.66091751248437.\n",
      "[I 2025-02-15 17:16:45,564] Trial 1 finished with value: 12.705619774881564 and parameters: {'learning_rate': 0.0015092169799046456, 'num_leaves': 81, 'subsample': 0.9554045793555976, 'colsample_bytree': 0.31754719081678673, 'min_data_in_leaf': 73}. Best is trial 0 with value: 9.66091751248437.\n",
      "[I 2025-02-15 17:16:45,625] Trial 2 finished with value: 9.506766505453466 and parameters: {'learning_rate': 0.05408267670836075, 'num_leaves': 264, 'subsample': 0.3749267473807775, 'colsample_bytree': 0.5151647099713695, 'min_data_in_leaf': 83}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:45,750] Trial 3 finished with value: 12.466826786139467 and parameters: {'learning_rate': 0.0013763072178993728, 'num_leaves': 658, 'subsample': 0.6345133420916979, 'colsample_bytree': 0.7168373915298527, 'min_data_in_leaf': 53}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:45,887] Trial 4 finished with value: 10.499835630333457 and parameters: {'learning_rate': 0.007760712510718404, 'num_leaves': 225, 'subsample': 0.988239398731494, 'colsample_bytree': 0.9853795401902894, 'min_data_in_leaf': 56}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:45,931] Trial 5 finished with value: 11.855796274302032 and parameters: {'learning_rate': 0.0030513569350926447, 'num_leaves': 419, 'subsample': 0.09864068372568513, 'colsample_bytree': 0.8251909246944311, 'min_data_in_leaf': 44}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:46,066] Trial 6 finished with value: 9.569229042537216 and parameters: {'learning_rate': 0.052276657896425806, 'num_leaves': 404, 'subsample': 0.5664744436247307, 'colsample_bytree': 0.940844089747121, 'min_data_in_leaf': 37}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:46,098] Trial 7 finished with value: 12.039154214997158 and parameters: {'learning_rate': 0.0031715145150861103, 'num_leaves': 5, 'subsample': 0.5264587531829461, 'colsample_bytree': 0.6641051314318652, 'min_data_in_leaf': 41}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:46,188] Trial 8 finished with value: 12.045507039138752 and parameters: {'learning_rate': 0.002763270888483347, 'num_leaves': 117, 'subsample': 0.6829703372711968, 'colsample_bytree': 0.6490491329615221, 'min_data_in_leaf': 62}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:46,380] Trial 9 finished with value: 9.649970857519172 and parameters: {'learning_rate': 0.029017510872457974, 'num_leaves': 709, 'subsample': 0.7496224324132245, 'colsample_bytree': 0.7819925328744168, 'min_data_in_leaf': 35}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:46,460] Trial 10 finished with value: 10.419235051669244 and parameters: {'learning_rate': 0.09348453332962048, 'num_leaves': 959, 'subsample': 0.2697654523181505, 'colsample_bytree': 0.16173022683579147, 'min_data_in_leaf': 97}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:46,901] Trial 11 finished with value: 10.524349706088998 and parameters: {'learning_rate': 0.019239830141297435, 'num_leaves': 373, 'subsample': 0.34494192962815673, 'colsample_bytree': 0.3899067650453424, 'min_data_in_leaf': 5}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:46,973] Trial 12 finished with value: 9.611962859507095 and parameters: {'learning_rate': 0.09825748852505564, 'num_leaves': 320, 'subsample': 0.3816531980846775, 'colsample_bytree': 0.960920068835871, 'min_data_in_leaf': 84}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,064] Trial 13 finished with value: 10.63571647426367 and parameters: {'learning_rate': 0.013413060994181299, 'num_leaves': 532, 'subsample': 0.18130666022001252, 'colsample_bytree': 0.44110609668204115, 'min_data_in_leaf': 26}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,142] Trial 14 finished with value: 10.498334953326413 and parameters: {'learning_rate': 0.0427408271297094, 'num_leaves': 555, 'subsample': 0.49712645897643315, 'colsample_bytree': 0.2649958929444901, 'min_data_in_leaf': 100}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,216] Trial 15 finished with value: 12.757286624792448 and parameters: {'learning_rate': 0.007550359952761783, 'num_leaves': 278, 'subsample': 0.47941628863391333, 'colsample_bytree': 0.05165314370908963, 'min_data_in_leaf': 71}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,303] Trial 16 finished with value: 9.529200249981809 and parameters: {'learning_rate': 0.05323381256239874, 'num_leaves': 824, 'subsample': 0.3706442030259549, 'colsample_bytree': 0.5575226524608884, 'min_data_in_leaf': 81}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,397] Trial 17 finished with value: 9.836295230920673 and parameters: {'learning_rate': 0.02313649484206793, 'num_leaves': 920, 'subsample': 0.37722957040301275, 'colsample_bytree': 0.5222738200247536, 'min_data_in_leaf': 83}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,470] Trial 18 finished with value: 9.508204069691004 and parameters: {'learning_rate': 0.06460210544495676, 'num_leaves': 839, 'subsample': 0.24079675729206468, 'colsample_bytree': 0.5609938316140962, 'min_data_in_leaf': 90}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,523] Trial 19 finished with value: 11.113162219715688 and parameters: {'learning_rate': 0.012747078317193027, 'num_leaves': 795, 'subsample': 0.05615073498675577, 'colsample_bytree': 0.4295791649158491, 'min_data_in_leaf': 91}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,604] Trial 20 finished with value: 9.553796543548314 and parameters: {'learning_rate': 0.07796671929365413, 'num_leaves': 1016, 'subsample': 0.21472332495812083, 'colsample_bytree': 0.6031789922126686, 'min_data_in_leaf': 71}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,669] Trial 21 finished with value: 9.622573260486066 and parameters: {'learning_rate': 0.03512870871713972, 'num_leaves': 854, 'subsample': 0.2853695096962786, 'colsample_bytree': 0.5378060467366432, 'min_data_in_leaf': 86}. Best is trial 2 with value: 9.506766505453466.\n",
      "[I 2025-02-15 17:16:47,739] Trial 22 finished with value: 9.482182289704118 and parameters: {'learning_rate': 0.058549688079170555, 'num_leaves': 692, 'subsample': 0.41557768459295763, 'colsample_bytree': 0.48156433181750224, 'min_data_in_leaf': 74}. Best is trial 22 with value: 9.482182289704118.\n",
      "[I 2025-02-15 17:16:47,832] Trial 23 finished with value: 9.555077656564162 and parameters: {'learning_rate': 0.06546986509296457, 'num_leaves': 654, 'subsample': 0.44040643273936314, 'colsample_bytree': 0.4682123712391898, 'min_data_in_leaf': 62}. Best is trial 22 with value: 9.482182289704118.\n",
      "[I 2025-02-15 17:16:47,899] Trial 24 finished with value: 10.089366107402984 and parameters: {'learning_rate': 0.028711313862642775, 'num_leaves': 744, 'subsample': 0.1702555952210905, 'colsample_bytree': 0.33180763900563703, 'min_data_in_leaf': 77}. Best is trial 22 with value: 9.482182289704118.\n",
      "[I 2025-02-15 17:16:47,966] Trial 25 finished with value: 9.719754338865338 and parameters: {'learning_rate': 0.06082045584913104, 'num_leaves': 621, 'subsample': 0.28746095028050456, 'colsample_bytree': 0.2543529012774435, 'min_data_in_leaf': 95}. Best is trial 22 with value: 9.482182289704118.\n",
      "[I 2025-02-15 17:16:48,071] Trial 26 finished with value: 9.656254501425613 and parameters: {'learning_rate': 0.021963347083067134, 'num_leaves': 902, 'subsample': 0.4281220773973338, 'colsample_bytree': 0.7726532376628231, 'min_data_in_leaf': 64}. Best is trial 22 with value: 9.482182289704118.\n",
      "[I 2025-02-15 17:16:48,193] Trial 27 finished with value: 9.51795001134663 and parameters: {'learning_rate': 0.0361143617698746, 'num_leaves': 751, 'subsample': 0.8450115832501113, 'colsample_bytree': 0.6309618915893105, 'min_data_in_leaf': 87}. Best is trial 22 with value: 9.482182289704118.\n",
      "[I 2025-02-15 17:16:48,266] Trial 28 finished with value: 9.501721064859789 and parameters: {'learning_rate': 0.0677475621281277, 'num_leaves': 475, 'subsample': 0.566768523996322, 'colsample_bytree': 0.4713880706890726, 'min_data_in_leaf': 92}. Best is trial 22 with value: 9.482182289704118.\n",
      "[I 2025-02-15 17:16:48,348] Trial 29 finished with value: 10.634645857226595 and parameters: {'learning_rate': 0.015346980423701449, 'num_leaves': 476, 'subsample': 0.5889033825240141, 'colsample_bytree': 0.3834359211842058, 'min_data_in_leaf': 75}. Best is trial 22 with value: 9.482182289704118.\n",
      "[I 2025-02-15 17:16:48,451] A new study created in memory with name: no-name-4e7859c6-a4b7-43b0-8e47-27a26d2f15c7\n",
      "[I 2025-02-15 17:16:48,575] Trial 0 finished with value: 12.026188860193429 and parameters: {'learning_rate': 0.0014638094954286455, 'num_leaves': 945, 'subsample': 0.7162260792001419, 'colsample_bytree': 0.8171735657440787, 'min_data_in_leaf': 69}. Best is trial 0 with value: 12.026188860193429.\n",
      "[I 2025-02-15 17:16:48,632] Trial 1 finished with value: 12.119597987671012 and parameters: {'learning_rate': 0.0012640756268209876, 'num_leaves': 404, 'subsample': 0.2527532361106249, 'colsample_bytree': 0.7783196693458543, 'min_data_in_leaf': 77}. Best is trial 0 with value: 12.026188860193429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1/5\n",
      "Model name: lgbm\n",
      "MAE: 7.6101446877814025\n",
      "MSE: 92.45324711182039\n",
      "RMSE: 9.615261156714382\n",
      "PCC: 0.6770140206066725\n",
      "Spearman R: 0.6849947001932424\n",
      "R2 Score: 0.455132293663847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:16:48,696] Trial 2 finished with value: 12.452674063113282 and parameters: {'learning_rate': 0.0014637980546462442, 'num_leaves': 172, 'subsample': 0.44700284745856034, 'colsample_bytree': 0.278320238976223, 'min_data_in_leaf': 65}. Best is trial 0 with value: 12.026188860193429.\n",
      "[I 2025-02-15 17:16:48,781] Trial 3 finished with value: 9.435843111563091 and parameters: {'learning_rate': 0.05474901989152316, 'num_leaves': 749, 'subsample': 0.4826904897242237, 'colsample_bytree': 0.8415347660457623, 'min_data_in_leaf': 60}. Best is trial 3 with value: 9.435843111563091.\n",
      "[I 2025-02-15 17:16:48,840] Trial 4 finished with value: 9.57754235621555 and parameters: {'learning_rate': 0.07821833651325703, 'num_leaves': 248, 'subsample': 0.3542704820976694, 'colsample_bytree': 0.3142091836145441, 'min_data_in_leaf': 56}. Best is trial 3 with value: 9.435843111563091.\n",
      "[I 2025-02-15 17:16:48,919] Trial 5 finished with value: 9.50623490340372 and parameters: {'learning_rate': 0.07707521073630938, 'num_leaves': 536, 'subsample': 0.573239005618131, 'colsample_bytree': 0.8403338736423104, 'min_data_in_leaf': 73}. Best is trial 3 with value: 9.435843111563091.\n",
      "[I 2025-02-15 17:16:48,944] Trial 6 finished with value: 10.792597138278145 and parameters: {'learning_rate': 0.014412557187093828, 'num_leaves': 326, 'subsample': 0.058701572456664124, 'colsample_bytree': 0.3026040191479108, 'min_data_in_leaf': 82}. Best is trial 3 with value: 9.435843111563091.\n",
      "[I 2025-02-15 17:16:49,028] Trial 7 finished with value: 9.807807084023743 and parameters: {'learning_rate': 0.08362807514617958, 'num_leaves': 196, 'subsample': 0.4369081481642557, 'colsample_bytree': 0.2059667917846993, 'min_data_in_leaf': 33}. Best is trial 3 with value: 9.435843111563091.\n",
      "[I 2025-02-15 17:16:49,194] Trial 8 finished with value: 9.814082201287645 and parameters: {'learning_rate': 0.01588522324233313, 'num_leaves': 248, 'subsample': 0.5582187136193775, 'colsample_bytree': 0.6567362090594004, 'min_data_in_leaf': 22}. Best is trial 3 with value: 9.435843111563091.\n",
      "[I 2025-02-15 17:16:49,275] Trial 9 finished with value: 10.52705788806598 and parameters: {'learning_rate': 0.05395557560985615, 'num_leaves': 748, 'subsample': 0.8900679980499813, 'colsample_bytree': 0.1613427903055626, 'min_data_in_leaf': 97}. Best is trial 3 with value: 9.435843111563091.\n",
      "[I 2025-02-15 17:16:49,491] Trial 10 finished with value: 10.287887292837683 and parameters: {'learning_rate': 0.007336435811354954, 'num_leaves': 634, 'subsample': 0.9994469229597421, 'colsample_bytree': 0.9824911757229348, 'min_data_in_leaf': 39}. Best is trial 3 with value: 9.435843111563091.\n",
      "[I 2025-02-15 17:16:49,616] Trial 11 finished with value: 9.430026819189326 and parameters: {'learning_rate': 0.0321477509950414, 'num_leaves': 561, 'subsample': 0.6319893475375702, 'colsample_bytree': 0.5786993850757947, 'min_data_in_leaf': 47}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:50,637] Trial 12 finished with value: 9.83497955196151 and parameters: {'learning_rate': 0.030374959563183437, 'num_leaves': 850, 'subsample': 0.7001063457986645, 'colsample_bytree': 0.4951369649785496, 'min_data_in_leaf': 5}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:50,766] Trial 13 finished with value: 9.480127252695107 and parameters: {'learning_rate': 0.03569932452794041, 'num_leaves': 698, 'subsample': 0.7163801021155476, 'colsample_bytree': 0.5341339512178764, 'min_data_in_leaf': 48}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:50,832] Trial 14 finished with value: 11.324209817373593 and parameters: {'learning_rate': 0.004970898131709706, 'num_leaves': 491, 'subsample': 0.2491464274506889, 'colsample_bytree': 0.5260317538631372, 'min_data_in_leaf': 52}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:50,868] Trial 15 finished with value: 9.726487328434342 and parameters: {'learning_rate': 0.029251665018906966, 'num_leaves': 3, 'subsample': 0.6383941569782967, 'colsample_bytree': 0.6898641109887722, 'min_data_in_leaf': 23}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:50,991] Trial 16 finished with value: 9.490768269114314 and parameters: {'learning_rate': 0.01800109847132378, 'num_leaves': 1020, 'subsample': 0.8227333176215726, 'colsample_bytree': 0.9788655661348304, 'min_data_in_leaf': 87}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:51,078] Trial 17 finished with value: 11.879032163494909 and parameters: {'learning_rate': 0.0032303997638538588, 'num_leaves': 806, 'subsample': 0.4243948217358455, 'colsample_bytree': 0.42351262279370283, 'min_data_in_leaf': 59}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:51,141] Trial 18 finished with value: 11.451324216163247 and parameters: {'learning_rate': 0.04781177200262568, 'num_leaves': 583, 'subsample': 0.2880937244043146, 'colsample_bytree': 0.06367675270383033, 'min_data_in_leaf': 43}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:51,247] Trial 19 finished with value: 9.671700460044859 and parameters: {'learning_rate': 0.02196767530095893, 'num_leaves': 445, 'subsample': 0.09836356678734115, 'colsample_bytree': 0.6225179252625213, 'min_data_in_leaf': 8}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:51,453] Trial 20 finished with value: 9.982885766414112 and parameters: {'learning_rate': 0.009789418355149982, 'num_leaves': 633, 'subsample': 0.8120550923997983, 'colsample_bytree': 0.9006939589693327, 'min_data_in_leaf': 30}. Best is trial 11 with value: 9.430026819189326.\n",
      "[I 2025-02-15 17:16:51,578] Trial 21 finished with value: 9.382554793461098 and parameters: {'learning_rate': 0.04242071729746847, 'num_leaves': 715, 'subsample': 0.6221446246691552, 'colsample_bytree': 0.558187454347088, 'min_data_in_leaf': 46}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:51,684] Trial 22 finished with value: 9.436997734147923 and parameters: {'learning_rate': 0.0484256659398039, 'num_leaves': 856, 'subsample': 0.5203710634294274, 'colsample_bytree': 0.719691633938669, 'min_data_in_leaf': 61}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:51,804] Trial 23 finished with value: 9.476366302566928 and parameters: {'learning_rate': 0.04938900973835323, 'num_leaves': 717, 'subsample': 0.6221481564334784, 'colsample_bytree': 0.43753802308511486, 'min_data_in_leaf': 46}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:51,932] Trial 24 finished with value: 9.688505158523196 and parameters: {'learning_rate': 0.0971115239900309, 'num_leaves': 919, 'subsample': 0.48300306367930024, 'colsample_bytree': 0.5994376226241468, 'min_data_in_leaf': 37}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:52,046] Trial 25 finished with value: 9.79708103762825 and parameters: {'learning_rate': 0.024126025533977323, 'num_leaves': 651, 'subsample': 0.6418971779538313, 'colsample_bytree': 0.4033814237383799, 'min_data_in_leaf': 52}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:52,189] Trial 26 finished with value: 9.469002003333602 and parameters: {'learning_rate': 0.03507658162378842, 'num_leaves': 800, 'subsample': 0.35858496190535294, 'colsample_bytree': 0.7458360060267064, 'min_data_in_leaf': 22}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:52,306] Trial 27 finished with value: 9.499244004522941 and parameters: {'learning_rate': 0.06238843256974418, 'num_leaves': 594, 'subsample': 0.764979126589221, 'colsample_bytree': 0.5825354930584266, 'min_data_in_leaf': 62}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:52,450] Trial 28 finished with value: 11.028733570448287 and parameters: {'learning_rate': 0.009164857381178686, 'num_leaves': 753, 'subsample': 0.5752386566032952, 'colsample_bytree': 0.3635360199344964, 'min_data_in_leaf': 30}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:52,565] Trial 29 finished with value: 9.808293397035444 and parameters: {'learning_rate': 0.013407263266803846, 'num_leaves': 957, 'subsample': 0.6839227970933889, 'colsample_bytree': 0.7721088937494995, 'min_data_in_leaf': 69}. Best is trial 21 with value: 9.382554793461098.\n",
      "[I 2025-02-15 17:16:52,713] A new study created in memory with name: no-name-e56c0ac5-0a60-4921-be13-bdf31a5991fd\n",
      "[I 2025-02-15 17:16:52,886] Trial 0 finished with value: 12.176926242802775 and parameters: {'learning_rate': 0.0016278528454797823, 'num_leaves': 366, 'subsample': 0.5327367952412542, 'colsample_bytree': 0.622297268154041, 'min_data_in_leaf': 19}. Best is trial 0 with value: 12.176926242802775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2/5\n",
      "Model name: lgbm\n",
      "MAE: 7.60311944839308\n",
      "MSE: 91.25374364377954\n",
      "RMSE: 9.552682536532842\n",
      "PCC: 0.6566509988831946\n",
      "Spearman R: 0.6548195780545227\n",
      "R2 Score: 0.4280381668143587\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:16:52,974] Trial 1 finished with value: 9.378140184025971 and parameters: {'learning_rate': 0.07902969163491262, 'num_leaves': 806, 'subsample': 0.6655370900112086, 'colsample_bytree': 0.7816331538715336, 'min_data_in_leaf': 76}. Best is trial 1 with value: 9.378140184025971.\n",
      "[I 2025-02-15 17:16:53,046] Trial 2 finished with value: 9.41297126276443 and parameters: {'learning_rate': 0.022115164871828387, 'num_leaves': 636, 'subsample': 0.5797466290917482, 'colsample_bytree': 0.800978590746472, 'min_data_in_leaf': 78}. Best is trial 1 with value: 9.378140184025971.\n",
      "[I 2025-02-15 17:16:54,528] Trial 3 finished with value: 10.995378787976966 and parameters: {'learning_rate': 0.005035896241766604, 'num_leaves': 802, 'subsample': 0.8334982171146725, 'colsample_bytree': 0.8291780007183888, 'min_data_in_leaf': 2}. Best is trial 1 with value: 9.378140184025971.\n",
      "[I 2025-02-15 17:16:54,809] Trial 4 finished with value: 12.220733376833389 and parameters: {'learning_rate': 0.0012693551877256833, 'num_leaves': 876, 'subsample': 0.7124507336557698, 'colsample_bytree': 0.8024030431436469, 'min_data_in_leaf': 19}. Best is trial 1 with value: 9.378140184025971.\n",
      "[I 2025-02-15 17:16:54,934] Trial 5 finished with value: 9.386939004719101 and parameters: {'learning_rate': 0.03841782747364143, 'num_leaves': 307, 'subsample': 0.35188075195257107, 'colsample_bytree': 0.9634264378518581, 'min_data_in_leaf': 21}. Best is trial 1 with value: 9.378140184025971.\n",
      "[I 2025-02-15 17:16:54,980] Trial 6 finished with value: 9.37298551740878 and parameters: {'learning_rate': 0.09396722416295984, 'num_leaves': 205, 'subsample': 0.407316061726002, 'colsample_bytree': 0.393978808118918, 'min_data_in_leaf': 85}. Best is trial 6 with value: 9.37298551740878.\n",
      "[I 2025-02-15 17:16:55,250] Trial 7 finished with value: 10.99595411879721 and parameters: {'learning_rate': 0.009831524086242261, 'num_leaves': 186, 'subsample': 0.9343924448876255, 'colsample_bytree': 0.4006535957917938, 'min_data_in_leaf': 2}. Best is trial 6 with value: 9.37298551740878.\n",
      "[I 2025-02-15 17:16:55,407] Trial 8 finished with value: 9.506319577713157 and parameters: {'learning_rate': 0.03126686050251823, 'num_leaves': 153, 'subsample': 0.9421412749330232, 'colsample_bytree': 0.4976101384773316, 'min_data_in_leaf': 37}. Best is trial 6 with value: 9.37298551740878.\n",
      "[I 2025-02-15 17:16:55,557] Trial 9 finished with value: 12.311564170725546 and parameters: {'learning_rate': 0.0014725024717239894, 'num_leaves': 809, 'subsample': 0.9333293369370005, 'colsample_bytree': 0.4917669007604447, 'min_data_in_leaf': 48}. Best is trial 6 with value: 9.37298551740878.\n",
      "[I 2025-02-15 17:16:55,586] Trial 10 finished with value: 10.807867111793655 and parameters: {'learning_rate': 0.07785219708825343, 'num_leaves': 11, 'subsample': 0.13509860622883874, 'colsample_bytree': 0.11048346533221448, 'min_data_in_leaf': 99}. Best is trial 6 with value: 9.37298551740878.\n",
      "[I 2025-02-15 17:16:55,645] Trial 11 finished with value: 9.418438787756228 and parameters: {'learning_rate': 0.09417172321402108, 'num_leaves': 525, 'subsample': 0.3285623281030691, 'colsample_bytree': 0.24037194937170991, 'min_data_in_leaf': 75}. Best is trial 6 with value: 9.37298551740878.\n",
      "[I 2025-02-15 17:16:55,720] Trial 12 finished with value: 9.33662317511516 and parameters: {'learning_rate': 0.05525565056944889, 'num_leaves': 975, 'subsample': 0.36196488228384394, 'colsample_bytree': 0.649899428636106, 'min_data_in_leaf': 76}. Best is trial 12 with value: 9.33662317511516.\n",
      "[I 2025-02-15 17:16:55,774] Trial 13 finished with value: 10.768551048084245 and parameters: {'learning_rate': 0.013564258832865028, 'num_leaves': 578, 'subsample': 0.35580849520158697, 'colsample_bytree': 0.2980424680181033, 'min_data_in_leaf': 97}. Best is trial 12 with value: 9.33662317511516.\n",
      "[I 2025-02-15 17:16:55,820] Trial 14 finished with value: 9.290209047596507 and parameters: {'learning_rate': 0.05041378417887835, 'num_leaves': 392, 'subsample': 0.16565705428187674, 'colsample_bytree': 0.6518306286202368, 'min_data_in_leaf': 63}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:55,871] Trial 15 finished with value: 9.358406847795669 and parameters: {'learning_rate': 0.03945444587754702, 'num_leaves': 983, 'subsample': 0.07198501698208908, 'colsample_bytree': 0.632632602570832, 'min_data_in_leaf': 61}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:55,926] Trial 16 finished with value: 9.785524159421096 and parameters: {'learning_rate': 0.01617234378247271, 'num_leaves': 426, 'subsample': 0.20147372142034448, 'colsample_bytree': 0.6632590724301375, 'min_data_in_leaf': 61}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:55,984] Trial 17 finished with value: 10.611206126526183 and parameters: {'learning_rate': 0.006181437021617088, 'num_leaves': 688, 'subsample': 0.2287642398948875, 'colsample_bytree': 0.9610479958246567, 'min_data_in_leaf': 61}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,099] Trial 18 finished with value: 9.312929627907444 and parameters: {'learning_rate': 0.05332756927120745, 'num_leaves': 1016, 'subsample': 0.4500650794716663, 'colsample_bytree': 0.7011500716198141, 'min_data_in_leaf': 46}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,171] Trial 19 finished with value: 11.536140144044177 and parameters: {'learning_rate': 0.00355432939633084, 'num_leaves': 448, 'subsample': 0.22543935531346002, 'colsample_bytree': 0.7249990980015271, 'min_data_in_leaf': 40}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,267] Trial 20 finished with value: 9.309279874448004 and parameters: {'learning_rate': 0.05330018627167706, 'num_leaves': 682, 'subsample': 0.46063122894088226, 'colsample_bytree': 0.8892707775234019, 'min_data_in_leaf': 51}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,386] Trial 21 finished with value: 9.362508146613104 and parameters: {'learning_rate': 0.05162874242825806, 'num_leaves': 685, 'subsample': 0.6260800105304494, 'colsample_bytree': 0.8955188770487004, 'min_data_in_leaf': 50}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,509] Trial 22 finished with value: 9.453922903932066 and parameters: {'learning_rate': 0.022937467945885054, 'num_leaves': 1019, 'subsample': 0.44825911435711774, 'colsample_bytree': 0.7244956634570971, 'min_data_in_leaf': 38}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,592] Trial 23 finished with value: 9.298658219891061 and parameters: {'learning_rate': 0.050983778547140486, 'num_leaves': 297, 'subsample': 0.4809199127814908, 'colsample_bytree': 0.5740399842481095, 'min_data_in_leaf': 64}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,671] Trial 24 finished with value: 9.41843420896462 and parameters: {'learning_rate': 0.02832904504799447, 'num_leaves': 346, 'subsample': 0.5023103514492624, 'colsample_bytree': 0.5646235679134409, 'min_data_in_leaf': 66}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,762] Trial 25 finished with value: 9.971041884172347 and parameters: {'learning_rate': 0.014496255417762624, 'num_leaves': 244, 'subsample': 0.7472396240175179, 'colsample_bytree': 0.5616518007003621, 'min_data_in_leaf': 67}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,818] Trial 26 finished with value: 9.374281703448565 and parameters: {'learning_rate': 0.057824398614229354, 'num_leaves': 79, 'subsample': 0.2772041190124912, 'colsample_bytree': 0.8830087065157788, 'min_data_in_leaf': 56}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:56,858] Trial 27 finished with value: 9.518596223392043 and parameters: {'learning_rate': 0.040043598978385386, 'num_leaves': 486, 'subsample': 0.1059691339765286, 'colsample_bytree': 0.3884724214014402, 'min_data_in_leaf': 88}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:57,003] Trial 28 finished with value: 9.81316675030395 and parameters: {'learning_rate': 0.021225292040351642, 'num_leaves': 285, 'subsample': 0.5447750366375262, 'colsample_bytree': 0.4619644038264038, 'min_data_in_leaf': 28}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:57,049] Trial 29 finished with value: 9.33503369160154 and parameters: {'learning_rate': 0.06681110612927318, 'num_leaves': 390, 'subsample': 0.17546357552908204, 'colsample_bytree': 0.5792063652164267, 'min_data_in_leaf': 55}. Best is trial 14 with value: 9.290209047596507.\n",
      "[I 2025-02-15 17:16:57,168] A new study created in memory with name: no-name-ec50fe8d-1cd0-4ef6-8d76-5331f88f1d81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3/5\n",
      "Model name: lgbm\n",
      "MAE: 7.4854626676254385\n",
      "MSE: 87.04926244597897\n",
      "RMSE: 9.330019423665686\n",
      "PCC: 0.6843288241125911\n",
      "Spearman R: 0.6942068922683173\n",
      "R2 Score: 0.46627775802768\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:16:57,373] Trial 0 finished with value: 10.473559417353982 and parameters: {'learning_rate': 0.00712219475046953, 'num_leaves': 517, 'subsample': 0.9051004888297339, 'colsample_bytree': 0.7767630538587638, 'min_data_in_leaf': 32}. Best is trial 0 with value: 10.473559417353982.\n",
      "[I 2025-02-15 17:16:57,466] Trial 1 finished with value: 12.552744565635091 and parameters: {'learning_rate': 0.002577609564833178, 'num_leaves': 401, 'subsample': 0.40647493102835136, 'colsample_bytree': 0.07844585678935852, 'min_data_in_leaf': 36}. Best is trial 0 with value: 10.473559417353982.\n",
      "[I 2025-02-15 17:16:57,570] Trial 2 finished with value: 10.34760413892291 and parameters: {'learning_rate': 0.006889973122831439, 'num_leaves': 999, 'subsample': 0.32933019953997056, 'colsample_bytree': 0.9070475276388318, 'min_data_in_leaf': 35}. Best is trial 2 with value: 10.34760413892291.\n",
      "[I 2025-02-15 17:16:57,728] Trial 3 finished with value: 10.15008377721305 and parameters: {'learning_rate': 0.012253936157333074, 'num_leaves': 623, 'subsample': 0.619797243615531, 'colsample_bytree': 0.522512796150737, 'min_data_in_leaf': 29}. Best is trial 3 with value: 10.15008377721305.\n",
      "[I 2025-02-15 17:16:57,756] Trial 4 finished with value: 11.105589009672505 and parameters: {'learning_rate': 0.005774405077761212, 'num_leaves': 177, 'subsample': 0.05167967042642685, 'colsample_bytree': 0.9507127143587365, 'min_data_in_leaf': 99}. Best is trial 3 with value: 10.15008377721305.\n",
      "[I 2025-02-15 17:16:57,854] Trial 5 finished with value: 11.326623392569287 and parameters: {'learning_rate': 0.004222789662067434, 'num_leaves': 635, 'subsample': 0.45487559517778897, 'colsample_bytree': 0.5991486126139159, 'min_data_in_leaf': 47}. Best is trial 3 with value: 10.15008377721305.\n",
      "[I 2025-02-15 17:16:57,985] Trial 6 finished with value: 10.504116700098894 and parameters: {'learning_rate': 0.09987623157657907, 'num_leaves': 674, 'subsample': 0.7164402967240302, 'colsample_bytree': 0.10521882520619098, 'min_data_in_leaf': 44}. Best is trial 3 with value: 10.15008377721305.\n",
      "[I 2025-02-15 17:16:58,081] Trial 7 finished with value: 10.93730258429433 and parameters: {'learning_rate': 0.004470741400715895, 'num_leaves': 141, 'subsample': 0.1410467017743542, 'colsample_bytree': 0.8929840512000793, 'min_data_in_leaf': 10}. Best is trial 3 with value: 10.15008377721305.\n",
      "[I 2025-02-15 17:16:58,174] Trial 8 finished with value: 10.745115270924028 and parameters: {'learning_rate': 0.005858610444727453, 'num_leaves': 370, 'subsample': 0.9394824941967218, 'colsample_bytree': 0.7767151567675777, 'min_data_in_leaf': 95}. Best is trial 3 with value: 10.15008377721305.\n",
      "[I 2025-02-15 17:16:58,284] Trial 9 finished with value: 9.318579813276218 and parameters: {'learning_rate': 0.0388077424698841, 'num_leaves': 1010, 'subsample': 0.7843126127507618, 'colsample_bytree': 0.45546990098922296, 'min_data_in_leaf': 74}. Best is trial 9 with value: 9.318579813276218.\n",
      "[I 2025-02-15 17:16:58,387] Trial 10 finished with value: 9.403739153399437 and parameters: {'learning_rate': 0.042476873644268075, 'num_leaves': 1018, 'subsample': 0.6848424477916225, 'colsample_bytree': 0.3521796543957678, 'min_data_in_leaf': 73}. Best is trial 9 with value: 9.318579813276218.\n",
      "[I 2025-02-15 17:16:58,507] Trial 11 finished with value: 9.520783233587697 and parameters: {'learning_rate': 0.03576221994170102, 'num_leaves': 953, 'subsample': 0.765634102528223, 'colsample_bytree': 0.3171018789054618, 'min_data_in_leaf': 71}. Best is trial 9 with value: 9.318579813276218.\n",
      "[I 2025-02-15 17:16:58,616] Trial 12 finished with value: 9.746915701752158 and parameters: {'learning_rate': 0.025514094853346193, 'num_leaves': 848, 'subsample': 0.7852873201600971, 'colsample_bytree': 0.36102694069140895, 'min_data_in_leaf': 69}. Best is trial 9 with value: 9.318579813276218.\n",
      "[I 2025-02-15 17:16:58,702] Trial 13 finished with value: 9.323037111350345 and parameters: {'learning_rate': 0.07655749721359108, 'num_leaves': 826, 'subsample': 0.5711421260052844, 'colsample_bytree': 0.4104640200764136, 'min_data_in_leaf': 72}. Best is trial 9 with value: 9.318579813276218.\n",
      "[I 2025-02-15 17:16:58,780] Trial 14 finished with value: 9.212931996181128 and parameters: {'learning_rate': 0.07272952454726128, 'num_leaves': 806, 'subsample': 0.5678144172226118, 'colsample_bytree': 0.5156497543456737, 'min_data_in_leaf': 84}. Best is trial 14 with value: 9.212931996181128.\n",
      "[I 2025-02-15 17:16:58,842] Trial 15 finished with value: 12.332396799975763 and parameters: {'learning_rate': 0.0010153327528656933, 'num_leaves': 798, 'subsample': 0.29327126644502505, 'colsample_bytree': 0.5822501550462179, 'min_data_in_leaf': 87}. Best is trial 14 with value: 9.212931996181128.\n",
      "[I 2025-02-15 17:16:58,971] Trial 16 finished with value: 10.85874074941668 and parameters: {'learning_rate': 0.02176467589397332, 'num_leaves': 885, 'subsample': 0.8437131737124749, 'colsample_bytree': 0.2101963557722497, 'min_data_in_leaf': 58}. Best is trial 14 with value: 9.212931996181128.\n",
      "[I 2025-02-15 17:16:59,045] Trial 17 finished with value: 9.222892571780221 and parameters: {'learning_rate': 0.05886776558341736, 'num_leaves': 761, 'subsample': 0.5059604970545708, 'colsample_bytree': 0.46312889342490166, 'min_data_in_leaf': 84}. Best is trial 14 with value: 9.212931996181128.\n",
      "[I 2025-02-15 17:16:59,115] Trial 18 finished with value: 9.16072821625943 and parameters: {'learning_rate': 0.06170484975932405, 'num_leaves': 737, 'subsample': 0.5191715167799914, 'colsample_bytree': 0.6885819457582437, 'min_data_in_leaf': 88}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,176] Trial 19 finished with value: 9.725216683450245 and parameters: {'learning_rate': 0.014052350473948962, 'num_leaves': 503, 'subsample': 0.2597967668613194, 'colsample_bytree': 0.7216223184362547, 'min_data_in_leaf': 60}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,256] Trial 20 finished with value: 9.442700440757104 and parameters: {'learning_rate': 0.019769808834782385, 'num_leaves': 727, 'subsample': 0.5996584271956248, 'colsample_bytree': 0.686400484868533, 'min_data_in_leaf': 85}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,328] Trial 21 finished with value: 9.226788351322966 and parameters: {'learning_rate': 0.06596068716144052, 'num_leaves': 764, 'subsample': 0.4857151646040981, 'colsample_bytree': 0.53027881667333, 'min_data_in_leaf': 85}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,399] Trial 22 finished with value: 9.183654370144138 and parameters: {'learning_rate': 0.05131885335075195, 'num_leaves': 578, 'subsample': 0.524607739822122, 'colsample_bytree': 0.6568818810819079, 'min_data_in_leaf': 92}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,458] Trial 23 finished with value: 9.282977049694383 and parameters: {'learning_rate': 0.09825645271679521, 'num_leaves': 585, 'subsample': 0.38250419635801636, 'colsample_bytree': 0.6578853410656771, 'min_data_in_leaf': 93}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,542] Trial 24 finished with value: 9.172548477394484 and parameters: {'learning_rate': 0.04810158082553042, 'num_leaves': 379, 'subsample': 0.6687724293618724, 'colsample_bytree': 0.7869899976025897, 'min_data_in_leaf': 100}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,614] Trial 25 finished with value: 9.182801100426067 and parameters: {'learning_rate': 0.04996040829408572, 'num_leaves': 287, 'subsample': 0.6507544232972287, 'colsample_bytree': 0.8031598408159727, 'min_data_in_leaf': 96}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,688] Trial 26 finished with value: 9.212092030129948 and parameters: {'learning_rate': 0.02823789281388198, 'num_leaves': 259, 'subsample': 0.6661236137846633, 'colsample_bytree': 0.8060537670244656, 'min_data_in_leaf': 99}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,768] Trial 27 finished with value: 9.508932443099216 and parameters: {'learning_rate': 0.015891203042356337, 'num_leaves': 32, 'subsample': 0.8667216562308384, 'colsample_bytree': 0.8444477057698314, 'min_data_in_leaf': 79}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:16:59,862] Trial 28 finished with value: 9.229265112385287 and parameters: {'learning_rate': 0.03803522790295842, 'num_leaves': 359, 'subsample': 0.9975549771096639, 'colsample_bytree': 0.996620608673328, 'min_data_in_leaf': 100}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:17:00,625] Trial 29 finished with value: 9.50631889174673 and parameters: {'learning_rate': 0.0563659369610061, 'num_leaves': 469, 'subsample': 0.7236316604835065, 'colsample_bytree': 0.7579568118702533, 'min_data_in_leaf': 4}. Best is trial 18 with value: 9.16072821625943.\n",
      "[I 2025-02-15 17:17:00,724] A new study created in memory with name: no-name-bbb0ea6a-305a-4546-accc-1d90e105a961\n",
      "[I 2025-02-15 17:17:00,802] Trial 0 finished with value: 11.383842220436831 and parameters: {'learning_rate': 0.005002333630478229, 'num_leaves': 411, 'subsample': 0.949754412583725, 'colsample_bytree': 0.5219801719814429, 'min_data_in_leaf': 95}. Best is trial 0 with value: 11.383842220436831.\n",
      "[I 2025-02-15 17:17:00,844] Trial 1 finished with value: 10.779687025549263 and parameters: {'learning_rate': 0.007509951174430289, 'num_leaves': 115, 'subsample': 0.17765494026718293, 'colsample_bytree': 0.5934616485876494, 'min_data_in_leaf': 43}. Best is trial 1 with value: 10.779687025549263.\n",
      "[I 2025-02-15 17:17:00,933] Trial 2 finished with value: 10.364111376410529 and parameters: {'learning_rate': 0.011109765076063378, 'num_leaves': 794, 'subsample': 0.8389944233541817, 'colsample_bytree': 0.5186241433618674, 'min_data_in_leaf': 85}. Best is trial 2 with value: 10.364111376410529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4/5\n",
      "Model name: lgbm\n",
      "MAE: 7.36846870515466\n",
      "MSE: 86.48528725364643\n",
      "RMSE: 9.299746623088526\n",
      "PCC: 0.6799199968702488\n",
      "Spearman R: 0.6867490651363536\n",
      "R2 Score: 0.46219495481382655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 17:17:01,091] Trial 3 finished with value: 10.45461992006161 and parameters: {'learning_rate': 0.01640432153008423, 'num_leaves': 962, 'subsample': 0.7549998815152686, 'colsample_bytree': 0.32722982625594843, 'min_data_in_leaf': 37}. Best is trial 2 with value: 10.364111376410529.\n",
      "[I 2025-02-15 17:17:01,153] Trial 4 finished with value: 9.407242713348587 and parameters: {'learning_rate': 0.04936542615732432, 'num_leaves': 543, 'subsample': 0.147948042551582, 'colsample_bytree': 0.4922714887305508, 'min_data_in_leaf': 27}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:01,594] Trial 5 finished with value: 12.317921150349074 and parameters: {'learning_rate': 0.0012463408303853125, 'num_leaves': 337, 'subsample': 0.847322088681242, 'colsample_bytree': 0.5836573356657384, 'min_data_in_leaf': 10}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:02,250] Trial 6 finished with value: 11.664534374747136 and parameters: {'learning_rate': 0.0024576010625690457, 'num_leaves': 912, 'subsample': 0.8762906136367581, 'colsample_bytree': 0.8880339052637948, 'min_data_in_leaf': 10}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:02,347] Trial 7 finished with value: 12.40574591468669 and parameters: {'learning_rate': 0.0015514798682340339, 'num_leaves': 945, 'subsample': 0.7970456371032371, 'colsample_bytree': 0.38714671172076276, 'min_data_in_leaf': 80}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:02,419] Trial 8 finished with value: 9.856585686031163 and parameters: {'learning_rate': 0.01777847009864418, 'num_leaves': 241, 'subsample': 0.7621485812919606, 'colsample_bytree': 0.48950332260516444, 'min_data_in_leaf': 81}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:02,495] Trial 9 finished with value: 12.43968843071605 and parameters: {'learning_rate': 0.002391661598899127, 'num_leaves': 270, 'subsample': 0.8499726317500631, 'colsample_bytree': 0.18355070695145675, 'min_data_in_leaf': 77}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:02,540] Trial 10 finished with value: 9.596588041459805 and parameters: {'learning_rate': 0.08183708914032599, 'num_leaves': 612, 'subsample': 0.06777775622296152, 'colsample_bytree': 0.8526960136009405, 'min_data_in_leaf': 26}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:02,585] Trial 11 finished with value: 9.791855093361844 and parameters: {'learning_rate': 0.08988552304815352, 'num_leaves': 648, 'subsample': 0.07215555605109196, 'colsample_bytree': 0.8883797979021717, 'min_data_in_leaf': 28}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:02,706] Trial 12 finished with value: 9.76685030956903 and parameters: {'learning_rate': 0.09149222670755067, 'num_leaves': 592, 'subsample': 0.31105526873116496, 'colsample_bytree': 0.7563157307430632, 'min_data_in_leaf': 22}. Best is trial 4 with value: 9.407242713348587.\n",
      "[I 2025-02-15 17:17:02,786] Trial 13 finished with value: 9.26746052801606 and parameters: {'learning_rate': 0.039701107904660256, 'num_leaves': 487, 'subsample': 0.39789045489604574, 'colsample_bytree': 0.7393323794684735, 'min_data_in_leaf': 57}. Best is trial 13 with value: 9.26746052801606.\n",
      "[I 2025-02-15 17:17:02,898] Trial 14 finished with value: 9.253690432150908 and parameters: {'learning_rate': 0.0392782714315792, 'num_leaves': 453, 'subsample': 0.4460103498359861, 'colsample_bytree': 0.7194770267998163, 'min_data_in_leaf': 60}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:02,981] Trial 15 finished with value: 9.267576099062557 and parameters: {'learning_rate': 0.034707736506849794, 'num_leaves': 429, 'subsample': 0.48724903886818716, 'colsample_bytree': 0.7111549285866627, 'min_data_in_leaf': 60}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,081] Trial 16 finished with value: 9.253891159442698 and parameters: {'learning_rate': 0.02738349731034203, 'num_leaves': 755, 'subsample': 0.4693362296821886, 'colsample_bytree': 0.9789087043460895, 'min_data_in_leaf': 58}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,183] Trial 17 finished with value: 9.272132097141306 and parameters: {'learning_rate': 0.0283236970106231, 'num_leaves': 752, 'subsample': 0.6052384847906532, 'colsample_bytree': 0.8052294801903883, 'min_data_in_leaf': 66}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,305] Trial 18 finished with value: 9.314682593823482 and parameters: {'learning_rate': 0.02230423981827845, 'num_leaves': 732, 'subsample': 0.6278317754387753, 'colsample_bytree': 0.9777112781722251, 'min_data_in_leaf': 49}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,365] Trial 19 finished with value: 9.28690653770088 and parameters: {'learning_rate': 0.05801986740265646, 'num_leaves': 35, 'subsample': 0.3458846664511461, 'colsample_bytree': 0.9557679222272732, 'min_data_in_leaf': 68}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,435] Trial 20 finished with value: 10.089141079393332 and parameters: {'learning_rate': 0.011409907954379144, 'num_leaves': 810, 'subsample': 0.5000459927275915, 'colsample_bytree': 0.690890540020231, 'min_data_in_leaf': 99}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,517] Trial 21 finished with value: 9.259611600539634 and parameters: {'learning_rate': 0.04290692532056796, 'num_leaves': 469, 'subsample': 0.4027760033867696, 'colsample_bytree': 0.6602596463642447, 'min_data_in_leaf': 55}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,585] Trial 22 finished with value: 9.313453529304843 and parameters: {'learning_rate': 0.05571847284783818, 'num_leaves': 486, 'subsample': 0.2640079677215373, 'colsample_bytree': 0.6167349586944412, 'min_data_in_leaf': 51}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,659] Trial 23 finished with value: 9.386996863561944 and parameters: {'learning_rate': 0.024297788669858576, 'num_leaves': 347, 'subsample': 0.4312497724659436, 'colsample_bytree': 0.6558690399146339, 'min_data_in_leaf': 67}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,772] Trial 24 finished with value: 9.28736405467393 and parameters: {'learning_rate': 0.03891241537637962, 'num_leaves': 674, 'subsample': 0.6020726210562058, 'colsample_bytree': 0.822307537794393, 'min_data_in_leaf': 56}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,907] Trial 25 finished with value: 10.401392506689008 and parameters: {'learning_rate': 0.01518497233274842, 'num_leaves': 550, 'subsample': 0.6690926322574804, 'colsample_bytree': 0.3826699562761061, 'min_data_in_leaf': 39}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:03,984] Trial 26 finished with value: 12.481172857942651 and parameters: {'learning_rate': 0.0059337995317082755, 'num_leaves': 875, 'subsample': 0.43049555488612434, 'colsample_bytree': 0.07375311945241358, 'min_data_in_leaf': 72}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:04,080] Trial 27 finished with value: 9.33831647664894 and parameters: {'learning_rate': 0.06163885580580215, 'num_leaves': 254, 'subsample': 0.538577162109198, 'colsample_bytree': 0.9312307811823619, 'min_data_in_leaf': 50}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:04,142] Trial 28 finished with value: 9.27783214438003 and parameters: {'learning_rate': 0.02982062791920685, 'num_leaves': 425, 'subsample': 0.24974293768209646, 'colsample_bytree': 0.7931095070457417, 'min_data_in_leaf': 59}. Best is trial 14 with value: 9.253690432150908.\n",
      "[I 2025-02-15 17:17:04,204] Trial 29 finished with value: 9.346326944803073 and parameters: {'learning_rate': 0.020303210902441218, 'num_leaves': 349, 'subsample': 0.3415927937694445, 'colsample_bytree': 0.9957228781667057, 'min_data_in_leaf': 90}. Best is trial 14 with value: 9.253690432150908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5/5\n",
      "Model name: lgbm\n",
      "MAE: 7.428196092474504\n",
      "MSE: 86.66497509726683\n",
      "RMSE: 9.309402510218732\n",
      "PCC: 0.6879123552099282\n",
      "Spearman R: 0.6897365213814538\n",
      "R2 Score: 0.4696232604479347\n",
      "\n",
      "{'lgbm': defaultdict(<class 'list'>, {'mae': 7.499078320285818, 'mse': 88.78130311049844, 'rmse': 9.421422450044034, 'pcc': np.float64(0.677165239136527), 'spearman_r': np.float64(0.682101351406778), 'r2_score': np.float64(0.45625328675352933)})}\n"
     ]
    }
   ],
   "source": [
    "# Train + Validate models\n",
    "metrics = [\"mae\", \"mse\", \"rmse\", \"pcc\", \"spearman_r\", \"r2_score\"]\n",
    "model_scores = {model_name: defaultdict(list) for model_name in models.keys()}\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    fold_data = kfold_data[fold]\n",
    "     \n",
    "    # Extract data\n",
    "    train_data = fold_data[\"train\"]\n",
    "    val_data = fold_data[\"val\"]\n",
    "    test_data = kfold_data[fold][\"test\"]\n",
    "\n",
    "    train_y = train_data[\"outcome\"]\n",
    "    val_y = val_data[\"outcome\"]\n",
    "    test_y = test_data[\"outcome\"]\n",
    "\n",
    "    train_x = train_data.drop(columns=[\"outcome\"])\n",
    "    val_x = val_data.drop(columns=[\"outcome\"])\n",
    "    test_x = test_data.drop(columns=[\"outcome\"])\n",
    "\n",
    "    # print(f\"Fold {fold+1}/{NUM_FOLDS}\")\n",
    "    # print(f\"Train data shape: {train_x.shape} | Train target shape: {train_y.shape}\")\n",
    "    # print(f\"Val data shape: {val_x.shape} | Val target shape: {val_y.shape}\")\n",
    "    # print(f\"Test data shape: {test_x.shape} | Test target shape: {test_y.shape}\")\n",
    "\n",
    "    # Train model\n",
    "    for model_name, model in models.items():\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(lambda trial: objective(trial=trial, \n",
    "                                               model_type=model, \n",
    "                                               x_train=train_x, \n",
    "                                               y_train=train_y, \n",
    "                                               x_val=val_x, \n",
    "                                               y_val=val_y\n",
    "                                               ), n_trials=30)\n",
    "        \n",
    "        # Train model with best hyperparameters\n",
    "        best_fold_params = study.best_params\n",
    "        model = model(**best_fold_params)\n",
    "        model.fit(train_x, train_y)\n",
    "        preds = model.predict(val_x)\n",
    "\n",
    "        metrics = calculate_metrics(targets=val_y, preds=preds)\n",
    "        mae = metrics[\"mae\"]\n",
    "        mse = metrics[\"mse\"]\n",
    "        rmse = metrics[\"rmse\"]\n",
    "        pcc = metrics[\"pcc\"]\n",
    "        spearman_r = metrics[\"spearman_r\"]\n",
    "        r2_score = metrics[\"r2_score\"]\n",
    "\n",
    "        for metric in metrics:\n",
    "            model_scores[model_name][metric].append(metrics[metric])\n",
    "\n",
    "        print(f\"Fold: {fold+1}/{NUM_FOLDS}\")\n",
    "        print(f\"Model name: {model_name}\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"PCC: {pcc}\")\n",
    "        print(f\"Spearman R: {spearman_r}\")\n",
    "        print(f\"R2 Score: {r2_score}\")\n",
    "        print()\n",
    "    \n",
    "for model_name, model_metrics in model_scores.items():\n",
    "    for metric, scores in model_metrics.items():\n",
    "        model_scores[model_name][metric] = sum(scores) / len(scores)\n",
    "print(model_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
